{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of LLMs, tokens are the pieces of text that language models read and analyze. They can be as small as a single character or as long as a word, and in some sophisticated models, tokens can even represent entire phrases,\n",
    "Tokens are used to encode and decode input and output texts, and can vary in size and dimension\n",
    "\n",
    "If you would like to learn how to build your own tokenizer, you can watch this video\n",
    "https://www.youtube.com/watch?v=zduSFxRajkE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 29\n",
      "Tokens : [79207, 5377, 15836, 5475, 5825, 26487, 5446, 2680, 311, 5377, 15836, 596, 8147, 4221, 4211, 2737, 279, 480, 2898, 12, 19, 11, 480, 2898, 12, 19, 48275, 449, 31541]\n",
      "Words :  ['Azure', ' Open', 'AI', ' Service', ' provides', ' REST', ' API', ' access', ' to', ' Open', 'AI', \"'s\", ' powerful', ' language', ' models', ' including', ' the', ' G', 'PT', '-', '4', ',', ' G', 'PT', '-', '4', ' Turbo', ' with', ' Vision']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "  api_version=os.getenv(\"API_VERSION\")\n",
    ")\n",
    "\n",
    "CHAT_COMPLETIONS_MODEL = os.getenv('AZURE_OPENAI_MODEL')\n",
    "\n",
    "encoding=tiktoken.encoding_for_model(\"gpt-4\")\n",
    "prompt = \"Azure OpenAI Service provides REST API access to OpenAI's powerful language models including the GPT-4, GPT-4 Turbo with Vision\"\n",
    "tokens = encoding.encode(prompt)\n",
    "print('Total number of tokens:', len(tokens))\n",
    "print('Tokens :', tokens)\n",
    "print('Words : ', [encoding.decode([t]) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=CHAT_COMPLETIONS_MODEL,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\": prompt}],\n",
    "    max_tokens=100,\n",
    "    n=2,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show 2 returned results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== ANSWER #1 ==============================\n",
      "As of my last update in early 2023, Azure OpenAI Service does provide REST API access to OpenAI's language models, which includes versions like GPT-3. However, specifics about GPT-4, GPT-4 Turbo, or GPT-4 Turbo with Vision are hypothetical developments that may or may not have been released or officially announced by OpenAI or supported through Azure's service afterward.\n",
      "\n",
      "Azure OpenAI Service offers developers a way to integrate OpenAI's advanced AI models\n",
      "============================== ANSWER #2 ==============================\n",
      "As of my knowledge cutoff date in March 2023, Microsoft Azure did provide access to OpenAI's models through their Azure OpenAI Service, which allowed developers to integrate OpenAIâ€™s powerful language models into their applications through REST API. The service originally featured access to models such as GPT-3 and Codex, offering capabilities for a wide range of applications, from natural language understanding to code generation.\n",
      "\n",
      "However, as for GPT-4 and GPT-4 Turbo with Vision, I cannot\n"
     ]
    }
   ],
   "source": [
    "print('='*30, 'ANSWER #1', '='*30)\n",
    "print(response.choices[0].message.content)\n",
    "print('='*30, 'ANSWER #2', '='*30)\n",
    "print(response.choices[1].message.content)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=200, prompt_tokens=46, total_tokens=246)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
