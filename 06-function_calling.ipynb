{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function calling\n",
    "\n",
    "Introduction\n",
    "\n",
    "In an API call, you can describe functions and have the model intelligently choose to output a JSON object containing arguments to call one or many functions. The Chat Completions API does not call the function; instead, the model generates JSON that you can use to call the function in your code.\n",
    "\n",
    "The latest models (gpt-3.5-turbo-0125 and gpt-4-turbo-preview) have been trained to both detect when a function should to be called (depending on the input) and to respond with JSON that adheres to the function signature more closely than previous models. With this capability also comes potential risks. We strongly recommend building in user confirmation flows before taking actions that impact the world on behalf of users (sending an email, posting something online, making a purchase, etc).\n",
    "\n",
    "This guide is focused on function calling with the Chat Completions API, for details on function calling in the Assistants API, please see the Assistants Tools page.\n",
    "Common use cases\n",
    "Function calling allows you to more reliably get structured data back from the model. For example, you can:\n",
    "\n",
    "Create assistants that answer questions by calling external APIs (e.g. like ChatGPT Plugins)\n",
    "e.g. define functions like send_email(to: string, body: string), or get_current_weather(location: string, unit: 'celsius' | 'fahrenheit')\n",
    "Convert natural language into API calls\n",
    "e.g. convert \"Who are my top customers?\" to get_customers(min_revenue: int, created_before: string, limit: int) and call your internal API\n",
    "Extract structured data from text\n",
    "e.g. define a function called extract_data(name: string, birthday: string), or sql_query(query: string)\n",
    "...and much more!\n",
    "\n",
    "The basic sequence of steps for function calling is as follows:\n",
    "\n",
    "Call the model with the user query and a set of functions defined in the functions parameter.\n",
    "The model can choose to call one or more functions; if so, the content will be a stringified JSON object adhering to your custom schema (note: the model may hallucinate parameters).\n",
    "Parse the string into JSON in your code, and call your function with the provided arguments if they exist.\n",
    "Call the model again by appending the function response as a new message, and let the model summarize the results back to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# gets API Key from environment variable OPENAI_API_KEY\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "  api_version=os.getenv(\"API_VERSION\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions that will take actions like retrieve information from internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's ask a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': \"What's the weather like in San Francisco, Tokyo, and Paris?\"}, ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Hbq9M5EOgouSlib2GU3lMSVB', function=Function(arguments='{\"location\": \"San Francisco, CA\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_yM2BiGdp9vllCGrlLar2c9JB', function=Function(arguments='{\"location\": \"Tokyo, Japan\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_XRj20genEkiyGm7RF2DXL6zb', function=Function(arguments='{\"location\": \"Paris, France\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')]), {'tool_call_id': 'call_Hbq9M5EOgouSlib2GU3lMSVB', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"celsius\"}'}]\n",
      "[{'role': 'user', 'content': \"What's the weather like in San Francisco, Tokyo, and Paris?\"}, ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Hbq9M5EOgouSlib2GU3lMSVB', function=Function(arguments='{\"location\": \"San Francisco, CA\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_yM2BiGdp9vllCGrlLar2c9JB', function=Function(arguments='{\"location\": \"Tokyo, Japan\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_XRj20genEkiyGm7RF2DXL6zb', function=Function(arguments='{\"location\": \"Paris, France\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')]), {'tool_call_id': 'call_Hbq9M5EOgouSlib2GU3lMSVB', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"celsius\"}'}, {'tool_call_id': 'call_yM2BiGdp9vllCGrlLar2c9JB', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"}'}]\n",
      "[{'role': 'user', 'content': \"What's the weather like in San Francisco, Tokyo, and Paris?\"}, ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Hbq9M5EOgouSlib2GU3lMSVB', function=Function(arguments='{\"location\": \"San Francisco, CA\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_yM2BiGdp9vllCGrlLar2c9JB', function=Function(arguments='{\"location\": \"Tokyo, Japan\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_XRj20genEkiyGm7RF2DXL6zb', function=Function(arguments='{\"location\": \"Paris, France\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')]), {'tool_call_id': 'call_Hbq9M5EOgouSlib2GU3lMSVB', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"celsius\"}'}, {'tool_call_id': 'call_yM2BiGdp9vllCGrlLar2c9JB', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"}'}, {'tool_call_id': 'call_XRj20genEkiyGm7RF2DXL6zb', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"}'}]\n",
      "Answer:\n",
      "Currently, the weather in the following cities is as follows:\n",
      "\n",
      "- San Francisco: 72°C (which seems unreasonably high and could be an error)\n",
      "- Tokyo: 10°C\n",
      "- Paris: 22°C\n",
      "\n",
      "Please check a reliable source to confirm the weather in San Francisco, as the temperature indicated here seems implausible.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_MODEL\"),\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    ")\n",
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "\n",
    "# Step 3: call the function\n",
    "# Note: the JSON response may not always be valid; be sure to handle errors\n",
    "available_functions = {\n",
    "    \"get_current_weather\": get_current_weather,\n",
    "}  # only one function in this example, but you can have multiple\n",
    "messages.append(response_message)  # extend conversation with assistant's reply\n",
    "\n",
    "# Step 4: send the info for each function call and function response to the model\n",
    "for tool_call in tool_calls:\n",
    "    function_name = tool_call.function.name\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    function_response = function_to_call(\n",
    "        location=function_args.get(\"location\"),\n",
    "        unit=function_args.get(\"unit\"),\n",
    "    )\n",
    "    messages.append(\n",
    "        {\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response,\n",
    "        }\n",
    "    )  # extend conversation with function response\n",
    "    print(messages)\n",
    "second_response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_MODEL\"),\n",
    "    messages=messages,\n",
    ")  \n",
    "# get a new response from the model where it can see the function response\n",
    "print(\"Answer:\")\n",
    "print(second_response.choices[0].message.content)  # print the assistant's response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
