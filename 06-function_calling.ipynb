{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# gets API Key from environment variable OPENAI_API_KEY\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "  api_version=\"2024-02-15-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions that will take actions like retrieve information from internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's ask a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': \"What's the weather like in San Francisco, Tokyo, and Paris?\"}, ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kwn1P6D4Ishflt1S5dUPjU67', function=Function(arguments='{\"location\": \"San Francisco, CA\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_WKHZFi7eO387iglL39Rrz6QL', function=Function(arguments='{\"location\": \"Tokyo, Japan\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_Rd4lGax6KSFM56Drmcg5EpVh', function=Function(arguments='{\"location\": \"Paris, France\"}', name='get_current_weather'), type='function')]), {'tool_call_id': 'call_kwn1P6D4Ishflt1S5dUPjU67', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": null}'}]\n",
      "[{'role': 'user', 'content': \"What's the weather like in San Francisco, Tokyo, and Paris?\"}, ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kwn1P6D4Ishflt1S5dUPjU67', function=Function(arguments='{\"location\": \"San Francisco, CA\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_WKHZFi7eO387iglL39Rrz6QL', function=Function(arguments='{\"location\": \"Tokyo, Japan\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_Rd4lGax6KSFM56Drmcg5EpVh', function=Function(arguments='{\"location\": \"Paris, France\"}', name='get_current_weather'), type='function')]), {'tool_call_id': 'call_kwn1P6D4Ishflt1S5dUPjU67', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": null}'}, {'tool_call_id': 'call_WKHZFi7eO387iglL39Rrz6QL', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": null}'}]\n",
      "[{'role': 'user', 'content': \"What's the weather like in San Francisco, Tokyo, and Paris?\"}, ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kwn1P6D4Ishflt1S5dUPjU67', function=Function(arguments='{\"location\": \"San Francisco, CA\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_WKHZFi7eO387iglL39Rrz6QL', function=Function(arguments='{\"location\": \"Tokyo, Japan\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_Rd4lGax6KSFM56Drmcg5EpVh', function=Function(arguments='{\"location\": \"Paris, France\"}', name='get_current_weather'), type='function')]), {'tool_call_id': 'call_kwn1P6D4Ishflt1S5dUPjU67', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": null}'}, {'tool_call_id': 'call_WKHZFi7eO387iglL39Rrz6QL', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": null}'}, {'tool_call_id': 'call_Rd4lGax6KSFM56Drmcg5EpVh', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": null}'}]\n",
      "Answer:\n",
      "Here is the current weather in each city:\n",
      "\n",
      "- San Francisco: 72°F\n",
      "- Tokyo: 10°C\n",
      "- Paris: 22°C\n",
      "\n",
      "Please note that the units for temperature are Fahrenheit for San Francisco and Celsius for Tokyo and Paris. Keep in mind that weather conditions can quickly change, and for the most accurate and up-to-date information, it is recommended to check a reliable local weather service or app.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_MODEL\"),\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    ")\n",
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "# Step 3: call the function\n",
    "# Note: the JSON response may not always be valid; be sure to handle errors\n",
    "available_functions = {\n",
    "    \"get_current_weather\": get_current_weather,\n",
    "}  # only one function in this example, but you can have multiple\n",
    "messages.append(response_message)  # extend conversation with assistant's reply\n",
    "# Step 4: send the info for each function call and function response to the model\n",
    "for tool_call in tool_calls:\n",
    "    function_name = tool_call.function.name\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    function_response = function_to_call(\n",
    "        location=function_args.get(\"location\"),\n",
    "        unit=function_args.get(\"unit\"),\n",
    "    )\n",
    "    messages.append(\n",
    "        {\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response,\n",
    "        }\n",
    "    )  # extend conversation with function response\n",
    "    print(messages)\n",
    "second_response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_MODEL\"),\n",
    "    messages=messages,\n",
    ")  # get a new response from the model where it can see the function response\n",
    "print(\"Answer:\")\n",
    "print(second_response.choices[0].message.content)  # print the assistant's response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
