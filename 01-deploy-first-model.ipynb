{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bbda02b",
   "metadata": {},
   "source": [
    "# Workshop 1: Deploy Your First Model\n",
    "\n",
    "Welcome to the Azure OpenAI Workshop! In this first notebook, you'll learn how to connect to Azure OpenAI and make your first API request.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Environment Setup** - Verify your Python environment and packages\n",
    "2. **Azure OpenAI Connection** - Connect to your deployed Azure OpenAI resource\n",
    "3. **First API Request** - Make a basic chat completion request\n",
    "4. **Understanding Responses** - Explore the API response structure\n",
    "5. **Token Usage** - Monitor and understand token consumption\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Azure OpenAI resource deployed (via infrastructure scripts)\n",
    "- Environment variables configured in `.env` file\n",
    "- Python environment set up with required packages\n",
    "\n",
    "## Quick Setup\n",
    "\n",
    "If you haven't set up the environment yet:\n",
    "\n",
    "```bash\n",
    "# Install dependencies\n",
    "uv sync\n",
    "\n",
    "# Activate environment (optional - uv run handles this automatically)\n",
    "source .venv/bin/activate\n",
    "\n",
    "# Start Jupyter\n",
    "uv run jupyter lab\n",
    "```\n",
    "\n",
    "Let's start by verifying your environment setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify environment setup\n",
    "try:\n",
    "    import openai\n",
    "    import azure.ai.projects\n",
    "    import azure.ai.inference\n",
    "    import azure.identity\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"✅ Environment Setup Successful!\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"📦 OpenAI SDK: {openai.__version__}\")\n",
    "    print(f\"📦 Pandas: {pd.__version__}\")\n",
    "    print(f\"📦 NumPy: {np.__version__}\")\n",
    "    print(\"\\n🚀 Ready to proceed with the workshop!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import error: {e}\")\n",
    "    print(\"\\n💡 Setup required:\")\n",
    "    print(\"1. Run: uv sync\")\n",
    "    print(\"2. Make sure you're using the correct kernel\")\n",
    "    print(\"3. Restart this notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6fb81c",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Verification\n",
    "\n",
    "Let's verify that all required packages are installed and your environment is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb7de22",
   "metadata": {},
   "source": [
    "## 2. Environment Variables Check\n",
    "\n",
    "Let's verify that your environment variables are properly configured for Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a4fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"🔧 Azure OpenAI Environment Check:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Check required environment variables\n",
    "required_vars = {\n",
    "    'AZURE_OPENAI_ENDPOINT': 'Azure OpenAI service endpoint',\n",
    "    'AZURE_OPENAI_DEPLOYMENT_NAME': 'Model deployment name (e.g., gpt-4o)',\n",
    "    'AZURE_OPENAI_API_VERSION': 'API version'\n",
    "}\n",
    "\n",
    "all_set = True\n",
    "for var, description in required_vars.items():\n",
    "    value = os.getenv(var)\n",
    "    if value:\n",
    "        # Show only first 50 chars of endpoint for security\n",
    "        display_value = value[:50] + \"...\" if var == 'AZURE_OPENAI_ENDPOINT' and len(value) > 50 else value\n",
    "        print(f\"✅ {var}: {display_value}\")\n",
    "    else:\n",
    "        print(f\"❌ {var}: Not set\")\n",
    "        print(f\"   📝 {description}\")\n",
    "        all_set = False\n",
    "\n",
    "# Check optional API key (if not using Entra ID)\n",
    "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "if api_key:\n",
    "    print(f\"🔑 AZURE_OPENAI_API_KEY: {'*' * 10}...{api_key[-4:]} (Key-based auth)\")\n",
    "else:\n",
    "    print(\"🔐 AZURE_OPENAI_API_KEY: Not set (Using Entra ID auth)\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "if all_set:\n",
    "    print(\"🚀 Environment configuration looks good!\")\n",
    "else:\n",
    "    print(\"⚠️  Please set missing environment variables in your .env file\")\n",
    "    print(\"💡 Check the README.md for setup instructions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf166e0",
   "metadata": {},
   "source": [
    "## 3. Connect to Azure OpenAI\n",
    "\n",
    "Now let's create an Azure OpenAI client and connect to your deployed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a0a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "print(\"🔗 Connecting to Azure OpenAI...\")\n",
    "\n",
    "# Get configuration from environment variables\n",
    "endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "api_version = os.getenv('AZURE_OPENAI_API_VERSION', '2024-10-21')\n",
    "deployment_name = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')\n",
    "\n",
    "# Check if we have an API key or should use Entra ID\n",
    "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "\n",
    "try:\n",
    "    if api_key:\n",
    "        # Use API key authentication\n",
    "        print(\"🔑 Using API key authentication\")\n",
    "        client = AzureOpenAI(\n",
    "            api_key=api_key,\n",
    "            api_version=api_version,\n",
    "            azure_endpoint=endpoint\n",
    "        )\n",
    "    else:\n",
    "        # Use Entra ID authentication (recommended)\n",
    "        print(\"🔐 Using Entra ID authentication\")\n",
    "        credential = DefaultAzureCredential()\n",
    "        \n",
    "        client = AzureOpenAI(\n",
    "            api_version=api_version,\n",
    "            azure_endpoint=endpoint,\n",
    "            azure_ad_token_provider=lambda: credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "        )\n",
    "    \n",
    "    print(\"✅ Azure OpenAI client created successfully!\")\n",
    "    print(f\"📍 Endpoint: {endpoint}\")\n",
    "    print(f\"🤖 Model Deployment: {deployment_name}\")\n",
    "    print(f\"📅 API Version: {api_version}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to create Azure OpenAI client: {e}\")\n",
    "    print(\"💡 Check your environment variables and Azure permissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912dffe4",
   "metadata": {},
   "source": [
    "## 4. Your First Azure OpenAI API Request\n",
    "\n",
    "Let's make a basic chat completion request to test the connection and see the API in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"🚀 Making your first Azure OpenAI API request...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Define the messages for the chat\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": \"You are a helpful AI assistant. Be concise and friendly in your responses.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Hello! Please introduce yourself and explain what you can do in 2-3 sentences.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Record start time for performance measurement\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Make the API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=messages,\n",
    "        max_tokens=150,\n",
    "        temperature=0.7,\n",
    "        top_p=1.0\n",
    "    )\n",
    "    \n",
    "    # Record end time\n",
    "    end_time = datetime.now()\n",
    "    response_time = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    print(\"✅ API Request Successful!\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Extract the response content\n",
    "    assistant_message = response.choices[0].message.content\n",
    "    \n",
    "    print(\"🤖 AI Assistant Response:\")\n",
    "    print(f\"   {assistant_message}\")\n",
    "    print()\n",
    "    \n",
    "    # Display usage information\n",
    "    usage = response.usage\n",
    "    print(\"📊 Request Details:\")\n",
    "    print(f\"   ⏱️  Response Time: {response_time:.2f} seconds\")\n",
    "    print(f\"   🔤 Prompt Tokens: {usage.prompt_tokens}\")\n",
    "    print(f\"   🔤 Completion Tokens: {usage.completion_tokens}\")\n",
    "    print(f\"   🔤 Total Tokens: {usage.total_tokens}\")\n",
    "    print(f\"   🏷️  Model Used: {response.model}\")\n",
    "    print(f\"   🎯 Finish Reason: {response.choices[0].finish_reason}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(\"🎉 Congratulations! You've successfully made your first Azure OpenAI API call!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ API request failed: {e}\")\n",
    "    print(\"💡 Troubleshooting tips:\")\n",
    "    print(\"   • Check your environment variables\")\n",
    "    print(\"   • Verify your Azure OpenAI deployment is active\")\n",
    "    print(\"   • Ensure you have proper permissions\")\n",
    "    print(\"   • Try running 'az login' if using Entra ID auth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea30a42",
   "metadata": {},
   "source": [
    "## 5. Understanding the API Response\n",
    "\n",
    "Let's explore the structure of the response object to understand what Azure OpenAI returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25568f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the response object structure in detail\n",
    "if 'response' in locals():\n",
    "    print(\"🔍 Detailed Response Analysis:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Response metadata\n",
    "    print(\"📋 Response Metadata:\")\n",
    "    print(f\"   🆔 Response ID: {response.id}\")\n",
    "    print(f\"   📅 Created: {datetime.fromtimestamp(response.created)}\")\n",
    "    print(f\"   🏷️  Model: {response.model}\")\n",
    "    print(f\"   🎯 Object Type: {response.object}\")\n",
    "    \n",
    "    # Choices analysis\n",
    "    print(f\"\\n🎲 Choices (Available: {len(response.choices)}):\")\n",
    "    for i, choice in enumerate(response.choices):\n",
    "        print(f\"   Choice {i}:\")\n",
    "        print(f\"     🔤 Content: {choice.message.content[:100]}...\")\n",
    "        print(f\"     👤 Role: {choice.message.role}\")\n",
    "        print(f\"     🏁 Finish Reason: {choice.finish_reason}\")\n",
    "        print(f\"     📊 Index: {choice.index}\")\n",
    "    \n",
    "    # Usage statistics breakdown\n",
    "    print(f\"\\n📊 Token Usage Breakdown:\")\n",
    "    print(f\"   📝 Prompt Tokens: {usage.prompt_tokens} (input)\")\n",
    "    print(f\"   🤖 Completion Tokens: {usage.completion_tokens} (output)\")\n",
    "    print(f\"   📈 Total Tokens: {usage.total_tokens} (prompt + completion)\")\n",
    "    \n",
    "    # Estimate cost (approximate, varies by model and region)\n",
    "    # Note: These are example rates and may not reflect current pricing\n",
    "    prompt_cost_per_1k = 0.0015  # Example rate for GPT-4\n",
    "    completion_cost_per_1k = 0.002\n",
    "    \n",
    "    estimated_cost = (usage.prompt_tokens * prompt_cost_per_1k / 1000) + \\\n",
    "                    (usage.completion_tokens * completion_cost_per_1k / 1000)\n",
    "    \n",
    "    print(f\"\\n💰 Estimated Cost (Example Rates):\")\n",
    "    print(f\"   💸 This Request: ~${estimated_cost:.6f}\")\n",
    "    print(f\"   📝 Prompt Cost: ~${usage.prompt_tokens * prompt_cost_per_1k / 1000:.6f}\")\n",
    "    print(f\"   🤖 Completion Cost: ~${usage.completion_tokens * completion_cost_per_1k / 1000:.6f}\")\n",
    "    print(f\"   ⚠️  Note: Actual costs vary by model and region\")\n",
    "    \n",
    "    # Response timing\n",
    "    print(f\"\\n⏱️  Performance Metrics:\")\n",
    "    print(f\"   🚀 Response Time: {response_time:.2f} seconds\")\n",
    "    print(f\"   📈 Tokens/Second: {usage.total_tokens / response_time:.1f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No response object found. Please run the previous cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9d283",
   "metadata": {},
   "source": [
    "## 6. Try Your Own Request\n",
    "\n",
    "Now it's your turn! Modify the message below and experiment with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557baec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✏️ Customize this request - try changing the message, temperature, or max_tokens!\n",
    "\n",
    "# Your custom message - modify this!\n",
    "your_message = \"Explain the concept of artificial intelligence in simple terms that a 10-year-old could understand.\"\n",
    "\n",
    "# Experiment with these parameters:\n",
    "custom_temperature = 0.7    # Try values between 0.0 (focused) and 1.0 (creative)\n",
    "custom_max_tokens = 200     # Adjust response length\n",
    "custom_top_p = 1.0         # Try values between 0.1 and 1.0\n",
    "\n",
    "print(f\"🎯 Your Custom Request:\")\n",
    "print(f\"📝 Message: {your_message}\")\n",
    "print(f\"🌡️  Temperature: {custom_temperature}\")\n",
    "print(f\"📏 Max Tokens: {custom_max_tokens}\")\n",
    "print(f\"🎲 Top P: {custom_top_p}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "try:\n",
    "    # Make your custom request\n",
    "    custom_response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful and educational AI assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": your_message}\n",
    "        ],\n",
    "        max_tokens=custom_max_tokens,\n",
    "        temperature=custom_temperature,\n",
    "        top_p=custom_top_p\n",
    "    )\n",
    "    \n",
    "    # Display the result\n",
    "    print(\"🤖 AI Response:\")\n",
    "    print(f\"   {custom_response.choices[0].message.content}\")\n",
    "    print()\n",
    "    \n",
    "    # Quick stats\n",
    "    custom_usage = custom_response.usage\n",
    "    print(\"📊 Quick Stats:\")\n",
    "    print(f\"   🔤 Total Tokens: {custom_usage.total_tokens}\")\n",
    "    print(f\"   🏁 Finish Reason: {custom_response.choices[0].finish_reason}\")\n",
    "    \n",
    "    print(\"\\n💡 Try This Next:\")\n",
    "    print(\"   • Change the temperature (0.0 = focused, 1.0 = creative)\")\n",
    "    print(\"   • Modify the message to ask something different\")\n",
    "    print(\"   • Adjust max_tokens to control response length\")\n",
    "    print(\"   • Experiment with different system prompts\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Request failed: {e}\")\n",
    "    print(\"💡 Double-check your parameters and try again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b89c4a2",
   "metadata": {},
   "source": [
    "## Workshop 1 Summary\n",
    "\n",
    "🎉 **Congratulations!** You've successfully completed Workshop 1!\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "✅ **Environment Setup** - Verified Python packages and dependencies  \n",
    "✅ **Configuration** - Checked Azure OpenAI environment variables  \n",
    "✅ **Connection** - Connected to Azure OpenAI service  \n",
    "✅ **First API Call** - Made a successful chat completion request  \n",
    "✅ **Response Analysis** - Understood the API response structure  \n",
    "✅ **Experimentation** - Tried custom requests with different parameters  \n",
    "\n",
    "### Key Concepts Learned\n",
    "\n",
    "- **Azure OpenAI Client**: How to authenticate and connect\n",
    "- **Chat Completions**: The main API for conversational AI\n",
    "- **Token Usage**: Understanding input/output tokens and costs\n",
    "- **Parameters**: Temperature, max_tokens, and top_p controls\n",
    "- **Response Structure**: Choices, usage, and metadata\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "🚀 **Ready for Workshop 2: Tracing and Observability**\n",
    "- Learn to monitor and trace your AI applications\n",
    "- Set up Application Insights integration\n",
    "- Understand performance metrics and debugging\n",
    "\n",
    "### Common Parameters to Remember\n",
    "\n",
    "| Parameter | Purpose | Typical Range |\n",
    "|-----------|---------|---------------|\n",
    "| `temperature` | Controls randomness/creativity | 0.0 - 1.0 |\n",
    "| `max_tokens` | Limits response length | 1 - 4096+ |\n",
    "| `top_p` | Controls diversity via nucleus sampling | 0.1 - 1.0 |\n",
    "| `frequency_penalty` | Reduces repetition | -2.0 - 2.0 |\n",
    "| `presence_penalty` | Encourages new topics | -2.0 - 2.0 |\n",
    "\n",
    "### 💡 Pro Tips\n",
    "\n",
    "- **Monitor token usage** to control costs\n",
    "- **Use system prompts** to set consistent behavior\n",
    "- **Experiment with temperature** for different use cases\n",
    "- **Set reasonable max_tokens** to avoid runaway responses\n",
    "- **Use Entra ID authentication** for production applications\n",
    "\n",
    "Keep experimenting and have fun building with Azure OpenAI! 🤖✨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-openai-workshop (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
