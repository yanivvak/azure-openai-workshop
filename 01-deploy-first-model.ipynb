{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bbda02b",
   "metadata": {},
   "source": [
    "# Workshop 1: Deploy Your First Model\n",
    "\n",
    "Welcome to the Azure OpenAI Workshop! In this first notebook, you'll learn how to connect to Azure OpenAI and make your first API request.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Environment Setup** - Verify your Python environment and packages\n",
    "2. **Azure OpenAI Connection** - Connect to your deployed Azure OpenAI resource\n",
    "3. **First API Request** - Make a basic chat completion request\n",
    "4. **Understanding Responses** - Explore the API response structure\n",
    "5. **Token Usage** - Monitor and understand token consumption\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Azure OpenAI resource deployed (via infrastructure scripts)\n",
    "- Environment variables configured in `.env` file\n",
    "- Python environment set up with required packages\n",
    "\n",
    "## Quick Setup\n",
    "\n",
    "If you haven't set up the environment yet:\n",
    "\n",
    "```bash\n",
    "# Install dependencies\n",
    "uv sync\n",
    "\n",
    "# Activate environment (optional - uv run handles this automatically)\n",
    "source .venv/bin/activate\n",
    "\n",
    "# Start Jupyter\n",
    "uv run jupyter lab\n",
    "```\n",
    "\n",
    "Let's start by verifying your environment setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify environment setup\n",
    "try:\n",
    "    import openai\n",
    "    import azure.ai.projects\n",
    "    import azure.ai.inference\n",
    "    import azure.identity\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"âœ… Environment Setup Successful!\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"ğŸ“¦ OpenAI SDK: {openai.__version__}\")\n",
    "    print(f\"ğŸ“¦ Pandas: {pd.__version__}\")\n",
    "    print(f\"ğŸ“¦ NumPy: {np.__version__}\")\n",
    "    print(\"\\nğŸš€ Ready to proceed with the workshop!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"\\nğŸ’¡ Setup required:\")\n",
    "    print(\"1. Run: uv sync\")\n",
    "    print(\"2. Make sure you're using the correct kernel\")\n",
    "    print(\"3. Restart this notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6fb81c",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Verification\n",
    "\n",
    "Let's verify that all required packages are installed and your environment is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb7de22",
   "metadata": {},
   "source": [
    "## 2. Environment Variables Check\n",
    "\n",
    "Let's verify that your environment variables are properly configured for Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a4fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”§ Azure OpenAI Environment Check:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Check required environment variables\n",
    "required_vars = {\n",
    "    'AZURE_OPENAI_ENDPOINT': 'Azure OpenAI service endpoint',\n",
    "    'AZURE_OPENAI_DEPLOYMENT_NAME': 'Model deployment name (e.g., gpt-4o)',\n",
    "    'AZURE_OPENAI_API_VERSION': 'API version'\n",
    "}\n",
    "\n",
    "all_set = True\n",
    "for var, description in required_vars.items():\n",
    "    value = os.getenv(var)\n",
    "    if value:\n",
    "        # Show only first 50 chars of endpoint for security\n",
    "        display_value = value[:50] + \"...\" if var == 'AZURE_OPENAI_ENDPOINT' and len(value) > 50 else value\n",
    "        print(f\"âœ… {var}: {display_value}\")\n",
    "    else:\n",
    "        print(f\"âŒ {var}: Not set\")\n",
    "        print(f\"   ğŸ“ {description}\")\n",
    "        all_set = False\n",
    "\n",
    "# Check optional API key (if not using Entra ID)\n",
    "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "if api_key:\n",
    "    print(f\"ğŸ”‘ AZURE_OPENAI_API_KEY: {'*' * 10}...{api_key[-4:]} (Key-based auth)\")\n",
    "else:\n",
    "    print(\"ğŸ” AZURE_OPENAI_API_KEY: Not set (Using Entra ID auth)\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "if all_set:\n",
    "    print(\"ğŸš€ Environment configuration looks good!\")\n",
    "else:\n",
    "    print(\"âš ï¸  Please set missing environment variables in your .env file\")\n",
    "    print(\"ğŸ’¡ Check the README.md for setup instructions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf166e0",
   "metadata": {},
   "source": [
    "## 3. Connect to Azure OpenAI\n",
    "\n",
    "Now let's create an Azure OpenAI client and connect to your deployed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a0a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "print(\"ğŸ”— Connecting to Azure OpenAI...\")\n",
    "\n",
    "# Get configuration from environment variables\n",
    "endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "api_version = os.getenv('AZURE_OPENAI_API_VERSION', '2024-10-21')\n",
    "deployment_name = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')\n",
    "\n",
    "# Check if we have an API key or should use Entra ID\n",
    "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "\n",
    "try:\n",
    "    if api_key:\n",
    "        # Use API key authentication\n",
    "        print(\"ğŸ”‘ Using API key authentication\")\n",
    "        client = AzureOpenAI(\n",
    "            api_key=api_key,\n",
    "            api_version=api_version,\n",
    "            azure_endpoint=endpoint\n",
    "        )\n",
    "    else:\n",
    "        # Use Entra ID authentication (recommended)\n",
    "        print(\"ğŸ” Using Entra ID authentication\")\n",
    "        credential = DefaultAzureCredential()\n",
    "        \n",
    "        client = AzureOpenAI(\n",
    "            api_version=api_version,\n",
    "            azure_endpoint=endpoint,\n",
    "            azure_ad_token_provider=lambda: credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "        )\n",
    "    \n",
    "    print(\"âœ… Azure OpenAI client created successfully!\")\n",
    "    print(f\"ğŸ“ Endpoint: {endpoint}\")\n",
    "    print(f\"ğŸ¤– Model Deployment: {deployment_name}\")\n",
    "    print(f\"ğŸ“… API Version: {api_version}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to create Azure OpenAI client: {e}\")\n",
    "    print(\"ğŸ’¡ Check your environment variables and Azure permissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912dffe4",
   "metadata": {},
   "source": [
    "## 4. Your First Azure OpenAI API Request\n",
    "\n",
    "Let's make a basic chat completion request to test the connection and see the API in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ğŸš€ Making your first Azure OpenAI API request...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Define the messages for the chat\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": \"You are a helpful AI assistant. Be concise and friendly in your responses.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Hello! Please introduce yourself and explain what you can do in 2-3 sentences.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Record start time for performance measurement\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Make the API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=messages,\n",
    "        max_tokens=150,\n",
    "        temperature=0.7,\n",
    "        top_p=1.0\n",
    "    )\n",
    "    \n",
    "    # Record end time\n",
    "    end_time = datetime.now()\n",
    "    response_time = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    print(\"âœ… API Request Successful!\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Extract the response content\n",
    "    assistant_message = response.choices[0].message.content\n",
    "    \n",
    "    print(\"ğŸ¤– AI Assistant Response:\")\n",
    "    print(f\"   {assistant_message}\")\n",
    "    print()\n",
    "    \n",
    "    # Display usage information\n",
    "    usage = response.usage\n",
    "    print(\"ğŸ“Š Request Details:\")\n",
    "    print(f\"   â±ï¸  Response Time: {response_time:.2f} seconds\")\n",
    "    print(f\"   ğŸ”¤ Prompt Tokens: {usage.prompt_tokens}\")\n",
    "    print(f\"   ğŸ”¤ Completion Tokens: {usage.completion_tokens}\")\n",
    "    print(f\"   ğŸ”¤ Total Tokens: {usage.total_tokens}\")\n",
    "    print(f\"   ğŸ·ï¸  Model Used: {response.model}\")\n",
    "    print(f\"   ğŸ¯ Finish Reason: {response.choices[0].finish_reason}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(\"ğŸ‰ Congratulations! You've successfully made your first Azure OpenAI API call!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ API request failed: {e}\")\n",
    "    print(\"ğŸ’¡ Troubleshooting tips:\")\n",
    "    print(\"   â€¢ Check your environment variables\")\n",
    "    print(\"   â€¢ Verify your Azure OpenAI deployment is active\")\n",
    "    print(\"   â€¢ Ensure you have proper permissions\")\n",
    "    print(\"   â€¢ Try running 'az login' if using Entra ID auth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea30a42",
   "metadata": {},
   "source": [
    "## 5. Understanding the API Response\n",
    "\n",
    "Let's explore the structure of the response object to understand what Azure OpenAI returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25568f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the response object structure in detail\n",
    "if 'response' in locals():\n",
    "    print(\"ğŸ” Detailed Response Analysis:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Response metadata\n",
    "    print(\"ğŸ“‹ Response Metadata:\")\n",
    "    print(f\"   ğŸ†” Response ID: {response.id}\")\n",
    "    print(f\"   ğŸ“… Created: {datetime.fromtimestamp(response.created)}\")\n",
    "    print(f\"   ğŸ·ï¸  Model: {response.model}\")\n",
    "    print(f\"   ğŸ¯ Object Type: {response.object}\")\n",
    "    \n",
    "    # Choices analysis\n",
    "    print(f\"\\nğŸ² Choices (Available: {len(response.choices)}):\")\n",
    "    for i, choice in enumerate(response.choices):\n",
    "        print(f\"   Choice {i}:\")\n",
    "        print(f\"     ğŸ”¤ Content: {choice.message.content[:100]}...\")\n",
    "        print(f\"     ğŸ‘¤ Role: {choice.message.role}\")\n",
    "        print(f\"     ğŸ Finish Reason: {choice.finish_reason}\")\n",
    "        print(f\"     ğŸ“Š Index: {choice.index}\")\n",
    "    \n",
    "    # Usage statistics breakdown\n",
    "    print(f\"\\nğŸ“Š Token Usage Breakdown:\")\n",
    "    print(f\"   ğŸ“ Prompt Tokens: {usage.prompt_tokens} (input)\")\n",
    "    print(f\"   ğŸ¤– Completion Tokens: {usage.completion_tokens} (output)\")\n",
    "    print(f\"   ğŸ“ˆ Total Tokens: {usage.total_tokens} (prompt + completion)\")\n",
    "    \n",
    "    # Estimate cost (approximate, varies by model and region)\n",
    "    # Note: These are example rates and may not reflect current pricing\n",
    "    prompt_cost_per_1k = 0.0015  # Example rate for GPT-4\n",
    "    completion_cost_per_1k = 0.002\n",
    "    \n",
    "    estimated_cost = (usage.prompt_tokens * prompt_cost_per_1k / 1000) + \\\n",
    "                    (usage.completion_tokens * completion_cost_per_1k / 1000)\n",
    "    \n",
    "    print(f\"\\nğŸ’° Estimated Cost (Example Rates):\")\n",
    "    print(f\"   ğŸ’¸ This Request: ~${estimated_cost:.6f}\")\n",
    "    print(f\"   ğŸ“ Prompt Cost: ~${usage.prompt_tokens * prompt_cost_per_1k / 1000:.6f}\")\n",
    "    print(f\"   ğŸ¤– Completion Cost: ~${usage.completion_tokens * completion_cost_per_1k / 1000:.6f}\")\n",
    "    print(f\"   âš ï¸  Note: Actual costs vary by model and region\")\n",
    "    \n",
    "    # Response timing\n",
    "    print(f\"\\nâ±ï¸  Performance Metrics:\")\n",
    "    print(f\"   ğŸš€ Response Time: {response_time:.2f} seconds\")\n",
    "    print(f\"   ğŸ“ˆ Tokens/Second: {usage.total_tokens / response_time:.1f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No response object found. Please run the previous cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9d283",
   "metadata": {},
   "source": [
    "## 6. Try Your Own Request\n",
    "\n",
    "Now it's your turn! Modify the message below and experiment with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557baec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœï¸ Customize this request - try changing the message, temperature, or max_tokens!\n",
    "\n",
    "# Your custom message - modify this!\n",
    "your_message = \"Explain the concept of artificial intelligence in simple terms that a 10-year-old could understand.\"\n",
    "\n",
    "# Experiment with these parameters:\n",
    "custom_temperature = 0.7    # Try values between 0.0 (focused) and 1.0 (creative)\n",
    "custom_max_tokens = 200     # Adjust response length\n",
    "custom_top_p = 1.0         # Try values between 0.1 and 1.0\n",
    "\n",
    "print(f\"ğŸ¯ Your Custom Request:\")\n",
    "print(f\"ğŸ“ Message: {your_message}\")\n",
    "print(f\"ğŸŒ¡ï¸  Temperature: {custom_temperature}\")\n",
    "print(f\"ğŸ“ Max Tokens: {custom_max_tokens}\")\n",
    "print(f\"ğŸ² Top P: {custom_top_p}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "try:\n",
    "    # Make your custom request\n",
    "    custom_response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful and educational AI assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": your_message}\n",
    "        ],\n",
    "        max_tokens=custom_max_tokens,\n",
    "        temperature=custom_temperature,\n",
    "        top_p=custom_top_p\n",
    "    )\n",
    "    \n",
    "    # Display the result\n",
    "    print(\"ğŸ¤– AI Response:\")\n",
    "    print(f\"   {custom_response.choices[0].message.content}\")\n",
    "    print()\n",
    "    \n",
    "    # Quick stats\n",
    "    custom_usage = custom_response.usage\n",
    "    print(\"ğŸ“Š Quick Stats:\")\n",
    "    print(f\"   ğŸ”¤ Total Tokens: {custom_usage.total_tokens}\")\n",
    "    print(f\"   ğŸ Finish Reason: {custom_response.choices[0].finish_reason}\")\n",
    "    \n",
    "    print(\"\\nğŸ’¡ Try This Next:\")\n",
    "    print(\"   â€¢ Change the temperature (0.0 = focused, 1.0 = creative)\")\n",
    "    print(\"   â€¢ Modify the message to ask something different\")\n",
    "    print(\"   â€¢ Adjust max_tokens to control response length\")\n",
    "    print(\"   â€¢ Experiment with different system prompts\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Request failed: {e}\")\n",
    "    print(\"ğŸ’¡ Double-check your parameters and try again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b89c4a2",
   "metadata": {},
   "source": [
    "## Workshop 1 Summary\n",
    "\n",
    "ğŸ‰ **Congratulations!** You've successfully completed Workshop 1!\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "âœ… **Environment Setup** - Verified Python packages and dependencies  \n",
    "âœ… **Configuration** - Checked Azure OpenAI environment variables  \n",
    "âœ… **Connection** - Connected to Azure OpenAI service  \n",
    "âœ… **First API Call** - Made a successful chat completion request  \n",
    "âœ… **Response Analysis** - Understood the API response structure  \n",
    "âœ… **Experimentation** - Tried custom requests with different parameters  \n",
    "\n",
    "### Key Concepts Learned\n",
    "\n",
    "- **Azure OpenAI Client**: How to authenticate and connect\n",
    "- **Chat Completions**: The main API for conversational AI\n",
    "- **Token Usage**: Understanding input/output tokens and costs\n",
    "- **Parameters**: Temperature, max_tokens, and top_p controls\n",
    "- **Response Structure**: Choices, usage, and metadata\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "ğŸš€ **Ready for Workshop 2: Tracing and Observability**\n",
    "- Learn to monitor and trace your AI applications\n",
    "- Set up Application Insights integration\n",
    "- Understand performance metrics and debugging\n",
    "\n",
    "### Common Parameters to Remember\n",
    "\n",
    "| Parameter | Purpose | Typical Range |\n",
    "|-----------|---------|---------------|\n",
    "| `temperature` | Controls randomness/creativity | 0.0 - 1.0 |\n",
    "| `max_tokens` | Limits response length | 1 - 4096+ |\n",
    "| `top_p` | Controls diversity via nucleus sampling | 0.1 - 1.0 |\n",
    "| `frequency_penalty` | Reduces repetition | -2.0 - 2.0 |\n",
    "| `presence_penalty` | Encourages new topics | -2.0 - 2.0 |\n",
    "\n",
    "### ğŸ’¡ Pro Tips\n",
    "\n",
    "- **Monitor token usage** to control costs\n",
    "- **Use system prompts** to set consistent behavior\n",
    "- **Experiment with temperature** for different use cases\n",
    "- **Set reasonable max_tokens** to avoid runaway responses\n",
    "- **Use Entra ID authentication** for production applications\n",
    "\n",
    "Keep experimenting and have fun building with Azure OpenAI! ğŸ¤–âœ¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-openai-workshop (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
