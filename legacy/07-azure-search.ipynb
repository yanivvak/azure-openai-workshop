{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Search integrated vectorization sample\n",
    "\n",
    "This Python notebook demonstrates the [integrated vectorization](https://learn.microsoft.com/azure/search/vector-search-integrated-vectorization) features of Azure AI Search that are currently in public preview. \n",
    "\n",
    "Integrated vectorization takes a dependency on indexers and skillsets, using the Text Split skill for data chunking, and the AzureOpenAIEmbedding skill and your Azure OpenAI resorce for embedding.\n",
    "\n",
    "This example uses PDFs from the `data/documents` folder for chunking, embedding, indexing, and queries.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "+ An Azure subscription, with [access to Azure OpenAI](https://aka.ms/oai/access).\n",
    " \n",
    "+ Azure AI Search, any tier, but we recommend Basic or higher for this workload. [Enable semantic ranker](https://learn.microsoft.com/azure/search/semantic-how-to-enable-disable) if you want to run a hybrid query with semantic ranking.\n",
    "\n",
    "+ A deployment of the `text-embedding-ada-002` model on Azure OpenAI.\n",
    "\n",
    "+ Azure Blob Storage. This notebook connects to your storage account and loads a container with the sample PDFs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# Variables not used here do not need to be updated in your .env file\n",
    "endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) if len(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) > 0 else DefaultAzureCredential()\n",
    "index_name = os.environ[\"AZURE_SEARCH_INDEX\"]\n",
    "blob_connection_string = os.environ[\"BLOB_CONNECTION_STRING\"]\n",
    "blob_container_name = os.environ[\"BLOB_CONTAINER_NAME\"]\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"] if len(os.environ[\"AZURE_OPENAI_KEY\"]) > 0 else None\n",
    "azure_openai_embedding_deployment = os.environ[\"EMBEDDING_MODEL_NAME\"]\n",
    "\n",
    "# Extract storage account name from connection string for Azure AD authentication\n",
    "storage_account_name = None\n",
    "if \"AccountName=\" in blob_connection_string:\n",
    "    storage_account_name = blob_connection_string.split(\"AccountName=\")[1].split(\";\")[0]\n",
    "else:\n",
    "    # Alternative: set AZURE_STORAGE_ACCOUNT_NAME in your .env file\n",
    "    storage_account_name = os.environ.get(\"AZURE_STORAGE_ACCOUNT_NAME\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug Azure OpenAI configuration\n",
    "print(\"=== Azure OpenAI Configuration Debug ===\")\n",
    "print(f\"Azure OpenAI endpoint: {azure_openai_endpoint}\")\n",
    "print(f\"Azure OpenAI key: {'***' + azure_openai_key[-4:] if azure_openai_key and len(azure_openai_key) > 4 else 'Not set'}\")\n",
    "print(f\"Embedding deployment: {azure_openai_embedding_deployment}\")\n",
    "print(f\"Search endpoint: {endpoint}\")\n",
    "print(f\"Search index: {index_name}\")\n",
    "print(\"===========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Azure OpenAI endpoint URL (remove trailing slash if present)\n",
    "if azure_openai_endpoint.endswith('/'):\n",
    "    azure_openai_endpoint = azure_openai_endpoint.rstrip('/')\n",
    "    print(f\"Fixed Azure OpenAI endpoint: {azure_openai_endpoint}\")\n",
    "\n",
    "# Test Azure OpenAI connection\n",
    "try:\n",
    "    from openai import AzureOpenAI\n",
    "    client = AzureOpenAI(\n",
    "        api_key=azure_openai_key,\n",
    "        api_version=\"2024-02-01\",\n",
    "        azure_endpoint=azure_openai_endpoint\n",
    "    )\n",
    "    \n",
    "    # Test embedding\n",
    "    response = client.embeddings.create(\n",
    "        input=\"test\",\n",
    "        model=azure_openai_embedding_deployment\n",
    "    )\n",
    "    print(\"‚úÖ Azure OpenAI connection test successful\")\n",
    "    print(f\"Embedding dimensions: {len(response.data[0].embedding)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Azure OpenAI connection test failed: {e}\")\n",
    "    print(\"This might explain why the indexer is failing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check all Azure OpenAI related environment variables\n",
    "print(\"=== All Azure OpenAI Environment Variables ===\")\n",
    "for key, value in os.environ.items():\n",
    "    if any(keyword in key.upper() for keyword in ['OPENAI', 'EMBEDDING', 'MODEL', 'DEPLOYMENT']):\n",
    "        if 'KEY' in key.upper() or 'SECRET' in key.upper():\n",
    "            print(f\"{key}: {'***' + value[-4:] if value and len(value) > 4 else 'Not set'}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\n=== Testing different possible deployment names ===\")\n",
    "# Common embedding deployment names to try\n",
    "possible_names = [\n",
    "    azure_openai_embedding_deployment,\n",
    "    \"text-embedding-ada-002\", \n",
    "    \"embedding\",\n",
    "    \"embeddings\",\n",
    "    \"text-embedding-3-small\",\n",
    "    \"text-embedding-3-large\"\n",
    "]\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=azure_openai_key,\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=azure_openai_endpoint\n",
    ")\n",
    "\n",
    "for deployment_name in possible_names:\n",
    "    if deployment_name:\n",
    "        try:\n",
    "            response = client.embeddings.create(\n",
    "                input=\"test\",\n",
    "                model=deployment_name\n",
    "            )\n",
    "            print(f\"‚úÖ {deployment_name} - WORKS! (dimensions: {len(response.data[0].embedding)})\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {deployment_name} - {str(e)[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Storage account name: {storage_account_name}\")\n",
    "print(f\"Blob container name: {blob_container_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Blob Storage and load documents\n",
    "\n",
    "Retrieve documents from Blob Storage. You can use the sample documents in the data/documents folder.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure Storage Authentication\n",
    "\n",
    "If you're getting a \"Key based authentication is not permitted\" error, your storage account requires Azure AD authentication. You have two options:\n",
    "\n",
    "1. **Azure AD Authentication (Recommended)**: Use your Azure credentials\n",
    "2. **Connection String**: If your storage account allows it\n",
    "\n",
    "For Azure AD authentication, make sure you're logged in to Azure:\n",
    "- Run `az login` in terminal, or\n",
    "- Use VS Code Azure extension to sign in, or  \n",
    "- Set up service principal credentials\n",
    "\n",
    "You may also need to add your user/service principal to the storage account's access control (IAM) with \"Storage Blob Data Contributor\" role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Permission Required: Storage Blob Data Contributor\n",
    "\n",
    "Your authentication is working, but you need upload permissions. Follow these steps:\n",
    "\n",
    "#### Option 1: Azure Portal (Recommended)\n",
    "1. Go to [Azure Portal](https://portal.azure.com)\n",
    "2. Navigate to **Storage accounts** ‚Üí **discoun** \n",
    "3. Click **Access Control (IAM)** in the left menu\n",
    "4. Click **+ Add** ‚Üí **Add role assignment**\n",
    "5. Select **Storage Blob Data Contributor** role\n",
    "6. Click **Next**\n",
    "7. Select **User, group, or service principal**\n",
    "8. Click **+ Select members**\n",
    "9. Search for and select: **yanivvaknin@microsoft.com**\n",
    "10. Click **Review + assign**\n",
    "\n",
    "#### Option 2: Azure CLI (if user lookup works)\n",
    "```bash\n",
    "# Get your object ID first\n",
    "USER_ID=$(az ad user show --id yanivvaknin@microsoft.com --query id -o tsv)\n",
    "\n",
    "# Assign the role\n",
    "az role assignment create \\\n",
    "  --role \"Storage Blob Data Contributor\" \\\n",
    "  --assignee $USER_ID \\\n",
    "  --scope \"/subscriptions/0ac2cbd1-7fd2-435c-a854-3a3335dcb184/resourceGroups/aisw/providers/Microsoft.Storage/storageAccounts/discoun\"\n",
    "```\n",
    "\n",
    "After assigning permissions, re-run the cell above. The upload should work! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient  \n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "# Connect to Blob Storage using Azure AD authentication\n",
    "try:\n",
    "    if not storage_account_name:\n",
    "        raise ValueError(\"Storage account name not found. Please check your BLOB_CONNECTION_STRING or set AZURE_STORAGE_ACCOUNT_NAME.\")\n",
    "    \n",
    "    # Use Azure AD authentication\n",
    "    credential_ad = DefaultAzureCredential()\n",
    "    account_url = f\"https://{storage_account_name}.blob.core.windows.net\"\n",
    "    blob_service_client = BlobServiceClient(account_url=account_url, credential=credential_ad)\n",
    "    \n",
    "    print(f\"Using Azure AD authentication for storage account: {storage_account_name}\")\n",
    "    \n",
    "    # Test authentication by listing containers (requires minimal permissions)\n",
    "    try:\n",
    "        containers = list(blob_service_client.list_containers())\n",
    "        print(f\"Successfully authenticated. Found {len(containers)} containers.\")\n",
    "    except HttpResponseError as auth_error:\n",
    "        if \"AuthorizationPermissionMismatch\" in str(auth_error):\n",
    "            print(\"‚ùå Permission Error: You need 'Storage Blob Data Contributor' role on this storage account.\")\n",
    "            print(f\"Please run this command in Azure CLI:\")\n",
    "            print(f\"az role assignment create --role 'Storage Blob Data Contributor' --assignee $(az account show --query user.name -o tsv) --resource-group aisw --scope '/subscriptions/0ac2cbd1-7fd2-435c-a854-3a3335dcb184/resourceGroups/aisw/providers/Microsoft.Storage/storageAccounts/{storage_account_name}'\")\n",
    "            print(\"\\nAlternatively, you can:\")\n",
    "            print(\"1. Go to Azure Portal\")\n",
    "            print(f\"2. Navigate to Storage Account: {storage_account_name}\")\n",
    "            print(\"3. Go to Access Control (IAM)\")\n",
    "            print(\"4. Add role assignment: 'Storage Blob Data Contributor'\")\n",
    "            print(\"5. Add your user account\")\n",
    "            raise\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Azure AD authentication failed: {e}\")\n",
    "    print(\"Make sure you're logged in to Azure (run 'az login') and have proper permissions.\")\n",
    "    raise\n",
    "\n",
    "# Only proceed if authentication was successful\n",
    "container_client = blob_service_client.get_container_client(blob_container_name)\n",
    "if not container_client.exists():\n",
    "    try:\n",
    "        container_client.create_container()\n",
    "        print(f\"Created container: {blob_container_name}\")\n",
    "    except HttpResponseError as e:\n",
    "        if \"AuthorizationPermissionMismatch\" in str(e):\n",
    "            print(f\"‚ùå Cannot create container. Need 'Storage Blob Data Contributor' role.\")\n",
    "            raise\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "documents_directory = os.path.join(\"data\", \"documents1\")\n",
    "uploaded_count = 0\n",
    "for file in os.listdir(documents_directory):\n",
    "    try:\n",
    "        with open(os.path.join(documents_directory, file), \"rb\") as data:\n",
    "            name = os.path.basename(file)\n",
    "            blob_client = container_client.get_blob_client(name)\n",
    "            \n",
    "            # Check if blob exists\n",
    "            try:\n",
    "                if not blob_client.exists():\n",
    "                    blob_client.upload_blob(data=data, overwrite=True)\n",
    "                    uploaded_count += 1\n",
    "                    print(f\"‚úÖ Uploaded: {name}\")\n",
    "                else:\n",
    "                    print(f\"‚è≠Ô∏è  Already exists: {name}\")\n",
    "            except HttpResponseError as upload_error:\n",
    "                if \"AuthorizationPermissionMismatch\" in str(upload_error):\n",
    "                    print(f\"‚ùå Cannot upload {name}. Need proper permissions.\")\n",
    "                    raise\n",
    "                else:\n",
    "                    raise\n",
    "    except Exception as file_error:\n",
    "        print(f\"‚ùå Error processing {file}: {file_error}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nüéâ Setup complete! Uploaded {uploaded_count} new files to container '{blob_container_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a blob data source connector on Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection\n",
    ")\n",
    "\n",
    "# Create a data source using Azure AD authentication with ResourceId format\n",
    "indexer_client = SearchIndexerClient(endpoint, credential)\n",
    "container = SearchIndexerDataContainer(name=blob_container_name)\n",
    "\n",
    "# For Azure AD authentication, use ResourceId format (replace with your actual values)\n",
    "# Format: ResourceId=/subscriptions/{subscription-id}/resourceGroups/{resource-group}/providers/Microsoft.Storage/storageAccounts/{storage-account-name};\n",
    "resource_id_connection_string = f\"ResourceId=/subscriptions/0ac2cbd1-7fd2-435c-a854-3a3335dcb184/resourceGroups/aisw/providers/Microsoft.Storage/storageAccounts/{storage_account_name};\"\n",
    "\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-blob\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=resource_id_connection_string,\n",
    "    container=container\n",
    ")\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated using Azure AD authentication with ResourceId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a search index\n",
    "\n",
    "Vector and nonvector content is stored in a search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    SemanticConfiguration,\n",
    "    SemanticSearch,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchIndex\n",
    ")\n",
    "\n",
    "# Create a search index  \n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)  \n",
    "fields = [  \n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),  \n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String),  \n",
    "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),  \n",
    "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),  \n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=3072, vector_search_profile_name=\"myHnswProfile\"),  \n",
    "]  \n",
    "  \n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(  \n",
    "            name=\"myHnsw\",  \n",
    "            parameters=HnswParameters(  \n",
    "                m=8,  \n",
    "                ef_construction=256,  \n",
    "                ef_search=256,  \n",
    "                metric=VectorSearchAlgorithmMetric.dot_product,  \n",
    "            ),  \n",
    "        ),  \n",
    "        ExhaustiveKnnAlgorithmConfiguration(  \n",
    "            name=\"myExhaustiveKnn\",  \n",
    "            parameters=ExhaustiveKnnParameters(  \n",
    "                metric=VectorSearchAlgorithmMetric.dot_product,  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "        ),  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myExhaustiveKnnProfile\",  \n",
    "            algorithm_configuration_name=\"myExhaustiveKnn\",  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "        ),  \n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "            parameters=AzureOpenAIVectorizerParameters(  \n",
    "                resource_url=azure_openai_endpoint,  \n",
    "                deployment_name=azure_openai_embedding_deployment,  \n",
    "                api_key=azure_openai_key,  \n",
    "                model_name=\"text-embedding-3-large\",  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "semantic_config = SemanticConfiguration(  \n",
    "    name=\"my-semantic-config\",  \n",
    "    prioritized_fields=SemanticPrioritizedFields(  \n",
    "        content_fields=[SemanticField(field_name=\"chunk\")]  \n",
    "    ),  \n",
    ")  \n",
    "  \n",
    "# Create the semantic search with the configuration  \n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])  \n",
    "  \n",
    "# Create the search index\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a skillset\n",
    "\n",
    "Skills drive integrated vectorization. [Text Split](https://learn.microsoft.com/azure/search/cognitive-search-skill-textsplit) provides data chunking. [AzureOpenAIEmbedding](https://learn.microsoft.com/azure/search/cognitive-search-skill-azure-openai-embedding) handles calls to Azure OpenAI, using the connection information you provide in the environment variables. An [indexer projection](https://learn.microsoft.com/azure/search/index-projections-concept-intro) specifies secondary indexes used for chunked data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SplitSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    SearchIndexerIndexProjection,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    SearchIndexerSkillset\n",
    ")\n",
    "\n",
    "# Create a skillset  \n",
    "skillset_name = f\"{index_name}-skillset\"  \n",
    "  \n",
    "split_skill = SplitSkill(  \n",
    "    description=\"Split skill to chunk documents\",  \n",
    "    text_split_mode=\"pages\",  \n",
    "    context=\"/document\",  \n",
    "    maximum_page_length=1000,  \n",
    "    page_overlap_length=400,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "    context=\"/document/pages/*\",  \n",
    "    resource_url=azure_openai_endpoint,  \n",
    "    deployment_name=azure_openai_embedding_deployment,  \n",
    "    model_name=\"text-embedding-3-large\",  \n",
    "    api_key=azure_openai_key,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "index_projections = SearchIndexerIndexProjection(  \n",
    "    selectors=[  \n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index_name,  \n",
    "            parent_key_field_name=\"parent_id\",  \n",
    "            source_context=\"/document/pages/*\",  \n",
    "            mappings=[  \n",
    "                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),  \n",
    "                InputFieldMappingEntry(name=\"vector\", source=\"/document/pages/*/vector\"),  \n",
    "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),  \n",
    "            ],  \n",
    "        ),  \n",
    "    ],  \n",
    "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "    ),  \n",
    ")  \n",
    "  \n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "    skills=[split_skill, embedding_skill],  \n",
    "    index_projection=index_projections,  \n",
    ")  \n",
    "  \n",
    "client = SearchIndexerClient(endpoint, credential)  \n",
    "client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    FieldMapping\n",
    ")\n",
    "\n",
    "# Create an indexer  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "  \n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,  \n",
    "    # Map the metadata_storage_name field to the title field in the index to display the PDF title in the search results  \n",
    "    field_mappings=[FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"title\")]  \n",
    ")  \n",
    "  \n",
    "indexer_client = SearchIndexerClient(endpoint, credential)  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "# Run the indexer  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f' {indexer_name} is created and running. If queries return no results, please wait a bit and try again.')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer_status = indexer_client.get_indexer_status(indexer_name)\n",
    "if indexer_status.last_result.status == \"success\":\n",
    "    print(\"Indexer completed successfully\")\n",
    "else:\n",
    "    print(\"‚ùå Indexer has issues or is still running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed indexer status and error information\n",
    "indexer_status = indexer_client.get_indexer_status(indexer_name)\n",
    "print(f\"Indexer Status: {indexer_status.last_result.status}\")\n",
    "print(f\"Items processed: {indexer_status.last_result.item_count}\")\n",
    "print(f\"Items failed: {indexer_status.last_result.failed_item_count}\")\n",
    "\n",
    "if indexer_status.last_result.errors:\n",
    "    print(\"\\n=== INDEXER ERRORS ===\")\n",
    "    for error in indexer_status.last_result.errors:\n",
    "        print(f\"Error: {error.error_message}\")\n",
    "        print(f\"Key: {error.key}\")\n",
    "        print(f\"Name: {error.name}\")\n",
    "        print(\"---\")\n",
    "\n",
    "if indexer_status.last_result.warnings:\n",
    "    print(\"\\n=== INDEXER WARNINGS ===\")\n",
    "    for warning in indexer_status.last_result.warnings:\n",
    "        print(f\"Warning: {warning.message}\")\n",
    "        print(f\"Key: {warning.key}\")\n",
    "        print(f\"Name: {warning.name}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait a bit for indexing to complete\n",
    "import time\n",
    "print(\"Waiting for indexing to complete...\")\n",
    "time.sleep(10)\n",
    "\n",
    "# Check status again\n",
    "indexer_status = indexer_client.get_indexer_status(indexer_name)\n",
    "print(f\"Indexer Status: {indexer_status.last_result.status}\")\n",
    "print(f\"Items processed: {indexer_status.last_result.item_count}\")\n",
    "print(f\"Items failed: {indexer_status.last_result.failed_item_count}\")\n",
    "\n",
    "# Check if there are any documents in the index\n",
    "from azure.search.documents import SearchClient\n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "results = search_client.search(search_text=\"*\", top=1)\n",
    "doc_count = 0\n",
    "for result in results:\n",
    "    doc_count += 1\n",
    "    break\n",
    "    \n",
    "print(f\"Documents in index: {doc_count} (sample check)\")\n",
    "\n",
    "# Get actual count\n",
    "try:\n",
    "    from azure.search.documents.indexes import SearchIndexClient\n",
    "    index_client = SearchIndexClient(endpoint, credential)\n",
    "    stats = index_client.get_index_statistics(index_name)\n",
    "    print(f\"Total documents in index: {stats.document_count}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not get index statistics: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what's currently in the index\n",
    "print(\"=== Current Index Contents ===\")\n",
    "results = search_client.search(search_text=\"*\", top=10)\n",
    "doc_count = 0\n",
    "for result in results:\n",
    "    doc_count += 1\n",
    "    print(f\"Doc {doc_count}: {result.get('title', 'No title')} (ID: {result.get('chunk_id', 'No ID')})\")\n",
    "    print(f\"  Content preview: {str(result.get('chunk', ''))[:100]}...\")\n",
    "    print()\n",
    "\n",
    "print(f\"Total documents found: {doc_count}\")\n",
    "\n",
    "# Now try the original vector search to see if it works\n",
    "print(\"\\n=== Testing Vector Search ===\")\n",
    "try:\n",
    "    from azure.search.documents.models import VectorizableTextQuery\n",
    "    \n",
    "    # Pure Vector Search\n",
    "    query = \"◊û◊î ◊î◊©◊§◊ï◊™ ◊©◊†◊™◊û◊õ◊ï◊™ ◊ë◊ê◊ô◊©◊ï◊® ◊†◊ô◊î◊ï◊ú ◊ó◊©◊ë◊ï◊ü\"  \n",
    "    \n",
    "    vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=3, fields=\"vector\", exhaustive=True)\n",
    "    \n",
    "    results = search_client.search(  \n",
    "        search_text=None,  \n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "        top=3\n",
    "    )  \n",
    "    \n",
    "    result_count = 0\n",
    "    for result in results:  \n",
    "        result_count += 1\n",
    "        print(f\"Result {result_count}:\")\n",
    "        print(f\"  parent_id: {result['parent_id']}\")  \n",
    "        print(f\"  chunk_id: {result['chunk_id']}\")  \n",
    "        print(f\"  Score: {result['@search.score']}\")  \n",
    "        print(f\"  Content: {result['chunk'][:200]}...\")\n",
    "        print()\n",
    "        \n",
    "    if result_count == 0:\n",
    "        print(\"No results found. The index might still be processing.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Vector search failed: {e}\")\n",
    "    print(\"This might be because the vectorizer configuration is still not fully set up.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows a pure vector search using the vectorizable text query, all you need to do is pass in text and your vectorizer will handle the query vectorization.\n",
    "\n",
    "If you indexed the health plan PDF file, send queries that ask plan-related questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "# Pure Vector Search\n",
    "query = \"◊û◊î ◊î◊©◊§◊ï◊™ ◊©◊†◊™◊û◊õ◊ï◊™ ◊ë◊ê◊ô◊©◊ï◊® ◊†◊ô◊î◊ï◊ú ◊ó◊©◊ë◊ï◊ü\"  \n",
    "  \n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=5, fields=\"vector\", exhaustive=True)\n",
    "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
    "# vector_query = RawVectorQuery(vector=generate_embeddings(query), k_nearest_neighbors=3, fields=\"vector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "    top=1\n",
    ")  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Search\n",
    "query = \"Which is more comprehensive, Northwind Health Plus vs Northwind Standard?\"  \n",
    "  \n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search + semantic reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    QueryCaptionType,\n",
    "    QueryAnswerType,\n",
    "    VectorizableTextQuery  # Add this line\n",
    ")\n",
    "# Semantic Hybrid Search\n",
    "query = \"Which is more comprehensive, Northwind Health Plus vs Northwind Standard?\"\n",
    "\n",
    "search_client = SearchClient(endpoint, index_name, credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name='my-semantic-config',\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=1\n",
    ")\n",
    "semantic_answers = results.get_answers()\n",
    "if semantic_answers:\n",
    "    for answer in semantic_answers:\n",
    "        if answer.highlights:\n",
    "            print(f\"Semantic Answer: {answer.highlights}\")\n",
    "        else:\n",
    "            print(f\"Semantic Answer: {answer.text}\")\n",
    "        print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['chunk']}\")  \n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a comprehensive answer using Azure OpenAI\n",
    "\n",
    "Now let's use Azure OpenAI to generate a comprehensive answer based on the retrieved context from our similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import os\n",
    "\n",
    "# Set up Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key,\n",
    "    api_version=\"2024-10-21\"\n",
    ")\n",
    "\n",
    "# Get the deployment name for chat completions\n",
    "deployment_name = os.getenv('AZURE_OPENAI_MODEL')\n",
    "\n",
    "def generate_answer_with_context(user_query, search_results):\n",
    "    \"\"\"Generate a comprehensive answer using Azure OpenAI based on search results.\"\"\"\n",
    "    \n",
    "    # Collect context from search results\n",
    "    context_chunks = []\n",
    "    for result in search_results:\n",
    "        context_chunks.append(result.get('chunk', ''))\n",
    "    \n",
    "    # Combine all context\n",
    "    combined_context = \"\\n\\n\".join(context_chunks[:3])  # Use top 3 results\n",
    "    \n",
    "    # Create the system message\n",
    "    system_message = \"\"\"You are a helpful assistant that answers questions based on the provided context. \n",
    "    Use the context to provide accurate, comprehensive answers. If the context doesn't contain enough \n",
    "    information to fully answer the question, indicate what information is available and what might be missing.\n",
    "    \n",
    "    Always cite specific information from the context when possible.\"\"\"\n",
    "    \n",
    "    # Create the user message with context\n",
    "    user_message = f\"\"\"Based on the following context, please answer this question: {user_query}\n",
    "    \n",
    "    Context:\n",
    "    {combined_context}\n",
    "    \n",
    "    Please provide a comprehensive answer based on the context above.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            max_tokens=1000,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error generating answer: {str(e)}\"\n",
    "\n",
    "# Use the same query from the search above\n",
    "user_query = \"Which is more comprehensive, Northwind Health Plus vs Northwind Standard?\"\n",
    "\n",
    "# Collect the search results (re-run the search to get fresh results)\n",
    "search_client = SearchClient(endpoint, index_name, credential)\n",
    "vector_query = VectorizableTextQuery(text=user_query, k_nearest_neighbors=3, fields=\"vector\", exhaustive=True)\n",
    "\n",
    "# Use a simpler search without semantic search (since it's not enabled)\n",
    "search_results = search_client.search(  \n",
    "    search_text=user_query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "    top=3\n",
    ")\n",
    "\n",
    "# Convert search results to list for reuse\n",
    "search_results_list = list(search_results)\n",
    "\n",
    "# Generate the AI-powered answer\n",
    "print(\"=\" * 80)\n",
    "print(\"ü§ñ AI-GENERATED COMPREHENSIVE ANSWER\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "ai_answer = generate_answer_with_context(user_query, search_results_list)\n",
    "print(ai_answer)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìÑ SUPPORTING CONTEXT FROM SEARCH\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Show the supporting evidence\n",
    "for i, result in enumerate(search_results_list, 1):\n",
    "    print(f\"\\n--- Context Chunk {i} ---\")\n",
    "    print(f\"Document: {result['parent_id']}\")\n",
    "    print(f\"Chunk ID: {result['chunk_id']}\")\n",
    "    print(f\"Search Score: {result.get('@search.score', 'N/A')}\")\n",
    "    print(f\"Content: {result['chunk'][:500]}...\")  # Truncate for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = index_client.delete_index(index_name)\n",
    "    print ('Index', index_name, 'Deleted')\n",
    "except Exception as ex:\n",
    "    print (ex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-openai-workshop (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
