{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Search integrated vectorization sample\n",
    "\n",
    "This Python notebook demonstrates the [integrated vectorization](https://learn.microsoft.com/azure/search/vector-search-integrated-vectorization) features of Azure AI Search that are currently in public preview. \n",
    "\n",
    "Integrated vectorization takes a dependency on indexers and skillsets, using the Text Split skill for data chunking, and the AzureOpenAIEmbedding skill and your Azure OpenAI resorce for embedding.\n",
    "\n",
    "This example uses PDFs from the `data/documents` folder for chunking, embedding, indexing, and queries.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "+ An Azure subscription, with [access to Azure OpenAI](https://aka.ms/oai/access).\n",
    " \n",
    "+ Azure AI Search, any tier, but we recommend Basic or higher for this workload. [Enable semantic ranker](https://learn.microsoft.com/azure/search/semantic-how-to-enable-disable) if you want to run a hybrid query with semantic ranking.\n",
    "\n",
    "+ A deployment of the `text-embedding-ada-002` model on Azure OpenAI.\n",
    "\n",
    "+ Azure Blob Storage. This notebook connects to your storage account and loads a container with the sample PDFs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# Variables not used here do not need to be updated in your .env file\n",
    "endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) if len(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) > 0 else DefaultAzureCredential()\n",
    "index_name = os.environ[\"AZURE_SEARCH_INDEX\"]\n",
    "blob_connection_string = os.environ[\"BLOB_CONNECTION_STRING\"]\n",
    "blob_container_name = os.environ[\"BLOB_CONTAINER_NAME\"]\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"] if len(os.environ[\"AZURE_OPENAI_KEY\"]) > 0 else None\n",
    "azure_openai_embedding_deployment = os.environ[\"EMBEDDING_MODEL_NAME\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Blob Storage and load documents\n",
    "\n",
    "Retrieve documents from Blob Storage. You can use the sample documents in the data/documents folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup sample data in demo-reranker\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient  \n",
    "\n",
    "# Connect to Blob Storage\n",
    "blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "container_client = blob_service_client.get_container_client(blob_container_name)\n",
    "if not container_client.exists():\n",
    "    container_client.create_container()\n",
    "\n",
    "documents_directory = os.path.join(\"data\", \"documents\")\n",
    "for file in os.listdir(documents_directory):\n",
    "    with open(os.path.join(documents_directory, file), \"rb\") as data:\n",
    "        name = os.path.basename(file)\n",
    "        if not container_client.get_blob_client(name).exists():\n",
    "            container_client.upload_blob(name=name, data=data)\n",
    "\n",
    "print(f\"Setup sample data in {blob_container_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a blob data source connector on Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source 'demo-reranker-blob' created or updated\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection\n",
    ")\n",
    "\n",
    "# Create a data source \n",
    "indexer_client = SearchIndexerClient(endpoint, credential)\n",
    "container = SearchIndexerDataContainer(name=blob_container_name)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-blob\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=blob_connection_string,\n",
    "    container=container\n",
    ")\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a search index\n",
    "\n",
    "Vector and nonvector content is stored in a search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo-reranker created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIParameters,\n",
    "    SemanticConfiguration,\n",
    "    SemanticSearch,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchIndex\n",
    ")\n",
    "\n",
    "# Create a search index  \n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)  \n",
    "fields = [  \n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),  \n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String),  \n",
    "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),  \n",
    "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),  \n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),  \n",
    "]  \n",
    "  \n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(  \n",
    "            name=\"myHnsw\",  \n",
    "            parameters=HnswParameters(  \n",
    "                m=8,  \n",
    "                ef_construction=256,  \n",
    "                ef_search=256,  \n",
    "                metric=VectorSearchAlgorithmMetric.dot_product,  \n",
    "            ),  \n",
    "        ),  \n",
    "        ExhaustiveKnnAlgorithmConfiguration(  \n",
    "            name=\"myExhaustiveKnn\",  \n",
    "            parameters=ExhaustiveKnnParameters(  \n",
    "                metric=VectorSearchAlgorithmMetric.dot_product,  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        ),  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myExhaustiveKnnProfile\",  \n",
    "            algorithm_configuration_name=\"myExhaustiveKnn\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        ),  \n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
    "                resource_uri=azure_openai_endpoint,  \n",
    "                deployment_id=azure_openai_embedding_deployment,  \n",
    "                api_key=azure_openai_key,  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "semantic_config = SemanticConfiguration(  \n",
    "    name=\"my-semantic-config\",  \n",
    "    prioritized_fields=SemanticPrioritizedFields(  \n",
    "        content_fields=[SemanticField(field_name=\"chunk\")]  \n",
    "    ),  \n",
    ")  \n",
    "  \n",
    "# Create the semantic search with the configuration  \n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])  \n",
    "  \n",
    "# Create the search index\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a skillset\n",
    "\n",
    "Skills drive integrated vectorization. [Text Split](https://learn.microsoft.com/azure/search/cognitive-search-skill-textsplit) provides data chunking. [AzureOpenAIEmbedding](https://learn.microsoft.com/azure/search/cognitive-search-skill-azure-openai-embedding) handles calls to Azure OpenAI, using the connection information you provide in the environment variables. An [indexer projection](https://learn.microsoft.com/azure/search/index-projections-concept-intro) specifies secondary indexes used for chunked data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo-reranker-skillset created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SplitSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    SearchIndexerIndexProjections,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    SearchIndexerSkillset\n",
    ")\n",
    "\n",
    "# Create a skillset  \n",
    "skillset_name = f\"{index_name}-skillset\"  \n",
    "  \n",
    "split_skill = SplitSkill(  \n",
    "    description=\"Split skill to chunk documents\",  \n",
    "    text_split_mode=\"pages\",  \n",
    "    context=\"/document\",  \n",
    "    maximum_page_length=2000,  \n",
    "    page_overlap_length=500,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "    context=\"/document/pages/*\",  \n",
    "    resource_uri=azure_openai_endpoint,  \n",
    "    deployment_id=azure_openai_embedding_deployment,  \n",
    "    api_key=azure_openai_key,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "index_projections = SearchIndexerIndexProjections(  \n",
    "    selectors=[  \n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index_name,  \n",
    "            parent_key_field_name=\"parent_id\",  \n",
    "            source_context=\"/document/pages/*\",  \n",
    "            mappings=[  \n",
    "                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),  \n",
    "                InputFieldMappingEntry(name=\"vector\", source=\"/document/pages/*/vector\"),  \n",
    "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),  \n",
    "            ],  \n",
    "        ),  \n",
    "    ],  \n",
    "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "    ),  \n",
    ")  \n",
    "  \n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "    skills=[split_skill, embedding_skill],  \n",
    "    index_projections=index_projections,  \n",
    ")  \n",
    "  \n",
    "client = SearchIndexerClient(endpoint, credential)  \n",
    "client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " demo-reranker-indexer is created and running. If queries return no results, please wait a bit and try again.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    FieldMapping\n",
    ")\n",
    "\n",
    "# Create an indexer  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "  \n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,  \n",
    "    # Map the metadata_storage_name field to the title field in the index to display the PDF title in the search results  \n",
    "    field_mappings=[FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"title\")]  \n",
    ")  \n",
    "  \n",
    "indexer_client = SearchIndexerClient(endpoint, credential)  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "# Run the indexer  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f' {indexer_name} is created and running. If queries return no results, please wait a bit and try again.')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexer completed successfully\n"
     ]
    }
   ],
   "source": [
    "indexer_status = indexer_client.get_indexer_status(indexer_name)\n",
    "if indexer_status.last_result.status == \"success\":\n",
    "    print(\"Indexer completed successfully\")\n",
    "else:\n",
    "    print(\"Indexer is still running or encountered an error\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows a pure vector search using the vectorizable text query, all you need to do is pass in text and your vectorizer will handle the query vectorization.\n",
    "\n",
    "If you indexed the health plan PDF file, send queries that ask plan-related questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: aHR0cHM6Ly9zZWFyY2h5YW4uYmxvYi5jb3JlLndpbmRvd3MubmV0L2RlbW8tcmVyYW5rZXIvQmVuZWZpdF9PcHRpb25zLnBkZg2\n",
      "chunk_id: 3959738a147b_aHR0cHM6Ly9zZWFyY2h5YW4uYmxvYi5jb3JlLndpbmRvd3MubmV0L2RlbW8tcmVyYW5rZXIvQmVuZWZpdF9PcHRpb25zLnBkZg2_pages_2\n",
      "Score: 1.9026837\n",
      "Content: for medical services. Northwind Health Plus offers coverage for hospital stays, \n",
      "doctor visits, lab tests, and X-rays. Northwind Standard only offers coverage for doctor visits and lab \n",
      "tests. \n",
      "\n",
      "Northwind Health Plus is a comprehensive plan that offers more coverage than Northwind Standard. \n",
      "Northwind Health Plus offers coverage for emergency services, mental health and substance abuse \n",
      "coverage, and out-of-network services, while Northwind Standard does not. Northwind Health Plus also \n",
      "\n",
      "\n",
      "\n",
      "offers a wider range of prescription drug coverage than Northwind Standard. Both plans offer coverage \n",
      "for vision and dental services, as well as medical services.  \n",
      "\n",
      "Cost Comparison\n",
      "Contoso Electronics deducts the employee's portion of the healthcare cost from each paycheck. This \n",
      "means that the cost of the health insurance will be spread out over the course of the year, rather \n",
      "than being paid in one lump sum. The employee's portion of the cost will be calculated based on the \n",
      "selected health plan and the number of people covered by the insurance. The table below shows a \n",
      "cost comparison between the different health plans offered by Contoso Electronics:\n",
      "\n",
      "Next Steps \n",
      "We hope that this information has been helpful in understanding the differences between Northwind \n",
      "Health Plus and Northwind Standard. We are confident that you will find the right plan for you and \n",
      "your family. Thank you for choosing Contoso Electronics!\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "# Pure Vector Search\n",
    "query = \"Which is more comprehensive, Northwind Health Plus vs Northwind Standard?\"  \n",
    "  \n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
    "# vector_query = RawVectorQuery(vector=generate_embeddings(query), k_nearest_neighbors=3, fields=\"vector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "    top=1\n",
    ")  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: aHR0cHM6Ly9zZWFyY2h5YW4uYmxvYi5jb3JlLndpbmRvd3MubmV0L2RlbW8tcmVyYW5rZXIvQmVuZWZpdF9PcHRpb25zLnBkZg2\n",
      "chunk_id: 3959738a147b_aHR0cHM6Ly9zZWFyY2h5YW4uYmxvYi5jb3JlLndpbmRvd3MubmV0L2RlbW8tcmVyYW5rZXIvQmVuZWZpdF9PcHRpb25zLnBkZg2_pages_2\n",
      "Score: 0.03279569745063782\n",
      "Content: for medical services. Northwind Health Plus offers coverage for hospital stays, \n",
      "doctor visits, lab tests, and X-rays. Northwind Standard only offers coverage for doctor visits and lab \n",
      "tests. \n",
      "\n",
      "Northwind Health Plus is a comprehensive plan that offers more coverage than Northwind Standard. \n",
      "Northwind Health Plus offers coverage for emergency services, mental health and substance abuse \n",
      "coverage, and out-of-network services, while Northwind Standard does not. Northwind Health Plus also \n",
      "\n",
      "\n",
      "\n",
      "offers a wider range of prescription drug coverage than Northwind Standard. Both plans offer coverage \n",
      "for vision and dental services, as well as medical services.  \n",
      "\n",
      "Cost Comparison\n",
      "Contoso Electronics deducts the employee's portion of the healthcare cost from each paycheck. This \n",
      "means that the cost of the health insurance will be spread out over the course of the year, rather \n",
      "than being paid in one lump sum. The employee's portion of the cost will be calculated based on the \n",
      "selected health plan and the number of people covered by the insurance. The table below shows a \n",
      "cost comparison between the different health plans offered by Contoso Electronics:\n",
      "\n",
      "Next Steps \n",
      "We hope that this information has been helpful in understanding the differences between Northwind \n",
      "Health Plus and Northwind Standard. We are confident that you will find the right plan for you and \n",
      "your family. Thank you for choosing Contoso Electronics!\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Search\n",
    "query = \"Which is more comprehensive, Northwind Health Plus vs Northwind Standard?\"  \n",
    "  \n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search + semantic reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Answer: Northwind Health Plus is a comprehensive plan that offers more coverage than Northwind Standard. Northwind Health Plus offers coverage for emergency services, mental health and substance abuse  coverage, and out-of-network services, while Northwind Standard does not.<em> Northwind Health Plus</em> also.\u0000\n",
      "Semantic Answer Score: 0.9072265625\n",
      "\n",
      "parent_id: aHR0cHM6Ly9zZWFyY2h5YW4uYmxvYi5jb3JlLndpbmRvd3MubmV0L2RlbW8tcmVyYW5rZXIvQmVuZWZpdF9PcHRpb25zLnBkZg2\n",
      "chunk_id: 3959738a147b_aHR0cHM6Ly9zZWFyY2h5YW4uYmxvYi5jb3JlLndpbmRvd3MubmV0L2RlbW8tcmVyYW5rZXIvQmVuZWZpdF9PcHRpb25zLnBkZg2_pages_1\n",
      "Reranker Score: 3.9479167461395264\n",
      "Content: a variety of in-network providers, including primary care \n",
      "physicians, specialists, hospitals, and pharmacies. This plan does not offer coverage for emergency \n",
      "services, mental health and substance abuse coverage, or out-of-network services.\n",
      "\n",
      "Comparison of Plans \n",
      "Both plans offer coverage for routine physicals, well-child visits, immunizations, and other preventive \n",
      "care services. The plans also cover preventive care services such as mammograms, colonoscopies, and \n",
      "other cancer screenings. \n",
      "\n",
      "Northwind Health Plus offers more comprehensive coverage than Northwind Standard. This plan offers \n",
      "coverage for emergency services, both in-network and out-of-network, as well as mental health and \n",
      "substance abuse coverage. Northwind Standard does not offer coverage for emergency services, mental \n",
      "health and substance abuse coverage, or out-of-network services. \n",
      "\n",
      "Both plans offer coverage for prescription drugs. Northwind Health Plus offers a wider range of \n",
      "prescription drug coverage than Northwind Standard. Northwind Health Plus covers generic, brand-\n",
      "name, and specialty drugs, while Northwind Standard only covers generic and brand-name drugs. \n",
      "\n",
      "Both plans offer coverage for vision and dental services. Northwind Health Plus offers coverage for vision \n",
      "exams, glasses, and contact lenses, as well as dental exams, cleanings, and fillings. Northwind Standard \n",
      "only offers coverage for vision exams and glasses. \n",
      "\n",
      "Both plans offer coverage for medical services. Northwind Health Plus offers coverage for hospital stays, \n",
      "doctor visits, lab tests, and X-rays. Northwind Standard only offers coverage for doctor visits and lab \n",
      "tests. \n",
      "\n",
      "Northwind Health Plus is a comprehensive plan that offers more coverage than Northwind Standard. \n",
      "Northwind Health Plus offers coverage for emergency services, mental health and substance abuse \n",
      "coverage, and out-of-network services, while Northwind Standard does not. Northwind Health Plus also\n",
      "Caption: <em>Northwind Health Plus</em> is a comprehensive plan that offers more coverage than<em> Northwind Standard. Northwind Health Plus</em> offers<em> coverage</em> for emergency services, mental health and substance abuse<em>  coverage,</em> and out-of-network services, while<em> Northwind Standard</em> does not.<em> Northwind Health Plus</em> also.\u0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    QueryCaptionType,\n",
    "    QueryAnswerType,\n",
    "    VectorizableTextQuery  # Add this line\n",
    ")\n",
    "# Semantic Hybrid Search\n",
    "query = \"Which is more comprehensive, Northwind Health Plus vs Northwind Standard?\"\n",
    "\n",
    "search_client = SearchClient(endpoint, index_name, credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name='my-semantic-config',\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=1\n",
    ")\n",
    "semantic_answers = results.get_answers()\n",
    "if semantic_answers:\n",
    "    for answer in semantic_answers:\n",
    "        if answer.highlights:\n",
    "            print(f\"Semantic Answer: {answer.highlights}\")\n",
    "        else:\n",
    "            print(f\"Semantic Answer: {answer.text}\")\n",
    "        print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['chunk']}\")  \n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = index_client.delete_index(index_name)\n",
    "    print ('Index', index_name, 'Deleted')\n",
    "except Exception as ex:\n",
    "    print (ex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
