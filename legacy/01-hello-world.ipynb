{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview  \n",
    "\"Large language models are functions that map text to text. Given an input string of text, a large language model tries to predict the text that will come next\". This \"quickstart\" notebook will introduce users to high-level LLM concepts, core package requirements for getting started with Azure Open AI, and soft introduction to prompt design\n",
    "\n",
    "For more quickstart examples please refer to the official Azure Open AI Quickstart Documentation https://learn.microsoft.com/en-us/azure/cognitive-services/openai/quickstart?pivots=programming-language-studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build your first prompt  \n",
    "This short exercise will provide a basic introduction for submitting prompts to an OpenAI model for a simple task \"summarization\".  \n",
    "![](images/generative-AI-models-reduced.jpg)  \n",
    "\n",
    "**Steps**:  \n",
    "\n",
    "1. Load standard helper libraries and set your typical OpenAI security credentials for the OpenAI Service that you've created  \n",
    "3. Choose a model for your task  \n",
    "4. Create a simple prompt for the model  \n",
    "5. Submit your request to the model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add Azure OpenAI package\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get configuration settings \n",
    "load_dotenv()\n",
    "azure_oai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_oai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_oai_model = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "api_version = os.getenv(\"API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The process of making maple syrup begins by tapping a spout (sometimes called a spile) into the sugar maple tree. The spile is inserted into the tree about 2 inches deep and the sap is collected as it flows out. The sap is then taken to a sugar shack where it is boiled down to concentrate the sugars. As the sap boils, water in the sap is evaporated and the syrup becomes more and more thick. Once the syrup reaches the right sugar content, which is usually when the boiling point reaches 219 degrees Fahrenheit, it is bottled and enjoyed.\n",
      "\n",
      "Sending request for summary to Azure OpenAI endpoint...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read text from file\n",
    "text = open(file=\"./Data/sample-text.txt\", encoding=\"utf8\").read()\n",
    "print(text)\n",
    "print(\"\\nSending request for summary to Azure OpenAI endpoint...\\n\\n\")\n",
    "\n",
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "        azure_endpoint = azure_oai_endpoint, \n",
    "        api_key=azure_oai_key,  \n",
    "        api_version=api_version\n",
    "        )\n",
    "\n",
    "# Send request to Azure OpenAI model\n",
    "response = client.chat.completions.create(\n",
    "    model=azure_oai_model,\n",
    "    seed=3,\n",
    "    temperature=0.2,\n",
    "    max_tokens=120,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Summarize the following text in 20 words or less:\\n\" + text}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AfpljUOtpfTNZbocaeupVq26Y6bGh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Maple syrup is made by tapping trees, collecting sap, boiling it, and bottling the concentrated syrup.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1734533811, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_4e924a4b48', usage=CompletionUsage(completion_tokens=22, prompt_tokens=146, total_tokens=168, completion_tokens_details=None, prompt_tokens_details=None), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Maple syrup is made by tapping trees, collecting sap, boiling it, and bottling the concentrated syrup.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary: \" + response.choices[0].message.content + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
