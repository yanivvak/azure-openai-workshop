{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "febcae57",
   "metadata": {},
   "source": [
    "# Azure AI Foundry Security Pen-Testing Tracing with ADX\n",
    "\n",
    "This notebook demonstrates advanced tracing capabilities for security pen-testing scenarios using Azure AI Foundry with Azure Data Explorer (ADX). We'll simulate a security team running various penetration tests while capturing comprehensive telemetry data.\n",
    "\n",
    "## Simple 3-Step Setup\n",
    "\n",
    "### Step 1: Deploy Resources\n",
    "```bash\n",
    "cd terraform\n",
    "./deploy-adx-complete.sh\n",
    "```\n",
    "\n",
    "### Step 2: Load Environment\n",
    "```bash\n",
    "source ../../.env\n",
    "```\n",
    "\n",
    "### Step 3: Run This Notebook\n",
    "Just run all cells below! Everything is automated.\n",
    "\n",
    "---\n",
    "\n",
    "## Scenario Overview\n",
    "- **Context**: Security team conducting comprehensive pen-testing\n",
    "- **Goal**: Generate 100+ realistic security test traces\n",
    "- **Tools**: OpenAI models for security analysis, ADX for data storage and analytics\n",
    "- **Outcome**: Rich dataset for security analytics and cost optimization\n",
    "\n",
    "## What This Notebook Does\n",
    "- **Automatically connects** to your deployed ADX cluster  \n",
    "- **Generates 120 realistic** security test scenarios  \n",
    "- **Uses AI** to analyze vulnerabilities and generate recommendations  \n",
    "- **Exports data** to ADX for advanced analytics  \n",
    "- **Provides KQL queries** for immediate insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137f668c",
   "metadata": {},
   "source": [
    "## 1. Initialize Environment\n",
    "\n",
    "The notebook automatically imports libraries and connects to your deployed resources. Just run the cells below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da0e0931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n",
      "Starting security pen-testing tracing simulation...\n",
      "Next: Environment configuration will load...\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import os, json, random, time, uuid, math, hashlib\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Any, Optional\n",
    "import pandas as pd\n",
    "\n",
    "# Azure AI Foundry imports\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Environment configuration\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# OpenTelemetry / tracing\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor, ConsoleSpanExporter\n",
    "\n",
    "# Initialize tracer provider\n",
    "if not isinstance(trace.get_tracer_provider(), TracerProvider):\n",
    "    provider = TracerProvider()\n",
    "    provider.add_span_processor(BatchSpanProcessor(ConsoleSpanExporter()))\n",
    "    trace.set_tracer_provider(provider)\n",
    "\n",
    "tracer = trace.get_tracer(\"security.pentest\")\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "print(\"Starting security pen-testing tracing simulation...\")\n",
    "print(\"Next: Environment configuration will load...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e11ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration from environment...\n",
      "\n",
      "Configuration Loaded:\n",
      "   Azure AI Project:  ✅ Missing\n",
      "   Deployment: gpt-4o-mini\n",
      "   ADX Cluster:  ✅ Configured\n",
      "   ADX Database: TracingDB\n",
      "\n",
      "PROJECT_ENDPOINT ❌ not set. Please check:\n",
      "   1. Did you run './deploy-adx-complete.sh'?\n",
      "   2. Did you run 'source ../../.env'?\n",
      "\n",
      "Configuration issues detected. Notebook will continue with limited functionality.\n",
      "AI Project Client not initialized - using mock mode\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Loading configuration from environment...\")\n",
    "\n",
    "# Configuration from environment\n",
    "AZURE_AI_PROJECT_ENDPOINT = os.getenv(\"PROJECT_ENDPOINT\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4o-mini\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-02-01\")\n",
    "\n",
    "# ADX Configuration (auto-configured by deployment script)\n",
    "ADX_CLUSTER_URI = os.getenv(\"ADX_CLUSTER_URI\")\n",
    "ADX_DATABASE_NAME = os.getenv(\"ADX_DATABASE_NAME\", \"TracingDB\")\n",
    "\n",
    "print(\"\\nConfiguration Loaded:\")\n",
    "print(f\"   Azure AI Project:  ✅ {'Configured' if AZURE_AI_PROJECT_ENDPOINT else 'Missing'}\")\n",
    "print(f\"   Deployment: {AZURE_OPENAI_DEPLOYMENT_NAME}\")\n",
    "print(f\"   ADX Cluster:  ✅ {'Configured' if ADX_CLUSTER_URI else 'Missing'}\")\n",
    "print(f\"   ADX Database: {ADX_DATABASE_NAME}\")\n",
    "\n",
    "# Configuration validation\n",
    "config_ok = True\n",
    "if not AZURE_AI_PROJECT_ENDPOINT:\n",
    "    print(\"\\nPROJECT_ENDPOINT ❌ not set. Please check:\")\n",
    "    print(\"   1. Did you run './deploy-adx-complete.sh'?\")\n",
    "    print(\"   2. Did you run 'source ../../.env'?\")\n",
    "    config_ok = False\n",
    "\n",
    "if not ADX_CLUSTER_URI:\n",
    "    print(\"\\nADX_CLUSTER_URI ❌ not set. Please run:\")\n",
    "    print(\"   cd ../terraform && ./deploy-adx-complete.sh\")\n",
    "    config_ok = False\n",
    "\n",
    "if config_ok:\n",
    "    print(\"\\nAll configuration ✅ looks good! Proceeding with setup...\")\n",
    "else:\n",
    "    print(\"\\nConfiguration issues detected. Notebook will continue with limited functionality.\")\n",
    "\n",
    "# Initialize Azure AI Project Client\n",
    "try:\n",
    "    if AZURE_AI_PROJECT_ENDPOINT:\n",
    "        project_client = AIProjectClient(\n",
    "            credential=DefaultAzureCredential(),\n",
    "            endpoint=AZURE_AI_PROJECT_ENDPOINT,\n",
    "        )\n",
    "        print(\"AI Project Client initialized ✅ successfully!\")\n",
    "    else:\n",
    "        project_client = None\n",
    "        print(\"AI Project Client not initialized - using mock mode\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error initializing AI Project Client: {e}\")\n",
    "    print(\"Continuing with mock mode...\")\n",
    "    project_client = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a45032",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "Uses existing environment variables and Azure CLI login.\n",
    "\n",
    "Prerequisites:\n",
    "- Run `az login` once in a terminal\n",
    "- `.env` (or prior cell) provides: `ADX_CLUSTER_URI`, `ADX_DATABASE_NAME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49884fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication & ADX client setup\n",
    "import os, time\n",
    "from azure.identity import AzureCliCredential\n",
    "from azure.kusto.data import KustoClient, KustoConnectionStringBuilder, DataFormat\n",
    "from azure.kusto.ingest import QueuedIngestClient, IngestionProperties\n",
    "from azure.core.exceptions import AzureError\n",
    "\n",
    "ADX_CLUSTER_URI = os.getenv(\"ADX_CLUSTER_URI\")\n",
    "ADX_DATABASE_NAME = os.getenv(\"ADX_DATABASE_NAME\", \"TracingDB\")\n",
    "ADX_CLUSTER_NAME = os.getenv(\"ADX_CLUSTER_NAME\")\n",
    "RESOURCE_GROUP = os.getenv(\"AZURE_RESOURCE_GROUP\")\n",
    "\n",
    "if not ADX_CLUSTER_URI or not ADX_CLUSTER_NAME or not RESOURCE_GROUP:\n",
    "    raise ValueError(\"Missing required ADX env vars (ADX_CLUSTER_URI, ADX_CLUSTER_NAME, AZURE_RESOURCE_GROUP)\")\n",
    "\n",
    "azure_credential = AzureCliCredential()\n",
    "\n",
    "kcsb_query = KustoConnectionStringBuilder.with_az_cli_authentication(ADX_CLUSTER_URI)\n",
    "adx_client = KustoClient(kcsb_query)\n",
    "\n",
    "# Ingest endpoint\n",
    "INGEST_URI = ADX_CLUSTER_URI.replace(\"https://\", \"https://ingest-\")\n",
    "kcsb_ingest = KustoConnectionStringBuilder.with_az_cli_authentication(INGEST_URI)\n",
    "adx_ingest_client = QueuedIngestClient(kcsb_ingest)\n",
    "\n",
    "import subprocess\n",
    "try:\n",
    "    state = subprocess.check_output([\n",
    "        \"az\",\"kusto\",\"cluster\",\"show\",\"--name\",ADX_CLUSTER_NAME,\"--resource-group\",RESOURCE_GROUP,\"--query\",\"state\",\"-o\",\"tsv\"\n",
    "    ], text=True).strip()\n",
    "    if state != \"Running\":\n",
    "        subprocess.run([\n",
    "            \"az\",\"kusto\",\"cluster\",\"start\",\"--name\",ADX_CLUSTER_NAME,\"--resource-group\",RESOURCE_GROUP,\"--no-wait\"\n",
    "        ], check=False)\n",
    "        for _ in range(16):\n",
    "            time.sleep(15)\n",
    "            state = subprocess.check_output([\n",
    "                \"az\",\"kusto\",\"cluster\",\"show\",\"--name\",ADX_CLUSTER_NAME,\"--resource-group\",RESOURCE_GROUP,\"--query\",\"state\",\"-o\",\"tsv\"\n",
    "            ], text=True).strip()\n",
    "            if state == \"Running\":\n",
    "                break\n",
    "    if state != \"Running\":\n",
    "        raise RuntimeError(f\"Cluster not Running (state={state})\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Cluster state check failed: {e}\")\n",
    "\n",
    "for attempt in range(4):\n",
    "    try:\n",
    "        r = adx_client.execute(\"\", \".show databases\")\n",
    "        dbs = [row[0] for row in r.primary_results[0]]\n",
    "        if ADX_DATABASE_NAME in dbs:\n",
    "            print(\"✅ Auth OK | Cluster Running | DB:\", ADX_DATABASE_NAME)\n",
    "        else:\n",
    "            print(\"⚠️ DB not found yet, present DBs:\", dbs)\n",
    "        break\n",
    "    except Exception as ex:\n",
    "        if attempt == 3:\n",
    "            raise\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc019044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status\n",
    "print(\"Clients: Azure ✅, ADX ✅, DB:\", ADX_DATABASE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacbd836",
   "metadata": {},
   "source": [
    "## ADX Schema Ready \n",
    "\n",
    "**Great! If you used the setup, your ADX schema is already configured.**\n",
    "\n",
    "### What Was Set Up:\n",
    "- ✅ **3 Tables**: OTelTraces, SecurityTraces, LLMInteractions\n",
    "- ✅ **3 JSON Mappings**: For data ingestion\n",
    "- ✅ **7 Analytics Functions**: Ready-to-use KQL functions\n",
    "- ✅ **EventHub Data Connection**: Live streaming enabled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7583fb47",
   "metadata": {},
   "source": [
    "## 2. Security Testing Framework\n",
    "\n",
    "The next few cells configure realistic security testing scenarios. No configuration needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Security Testing Data Models\n",
    "@dataclass\n",
    "class SecurityTest:\n",
    "    test_id: str\n",
    "    test_type: str\n",
    "    test_name: str\n",
    "    target: str\n",
    "    severity: str\n",
    "    status: str\n",
    "    duration: float\n",
    "    findings: Dict[str, Any]\n",
    "    recommendations: List[str]\n",
    "    tester_info: Dict[str, str]\n",
    "    environment: str\n",
    "    timestamp: datetime\n",
    "\n",
    "@dataclass\n",
    "class LLMInteraction:\n",
    "    interaction_id: str\n",
    "    trace_id: str\n",
    "    span_id: str\n",
    "    model: str\n",
    "    tokens_used: int\n",
    "    prompt_tokens: int\n",
    "    completion_tokens: int\n",
    "    temperature: float\n",
    "    max_tokens: int\n",
    "    prompt_hash: str\n",
    "    response_length: int\n",
    "    processing_time: float\n",
    "    cost: float\n",
    "    success: bool\n",
    "    error_message: str\n",
    "    timestamp: datetime\n",
    "\n",
    "# Security Testing Configuration\n",
    "SECURITY_TEST_TYPES = [\n",
    "    \"vulnerability_scan\",\n",
    "    \"penetration_test\", \n",
    "    \"code_analysis\",\n",
    "    \"infrastructure_assessment\",\n",
    "    \"social_engineering\",\n",
    "    \"web_application_test\",\n",
    "    \"network_security_test\",\n",
    "    \"database_security_test\",\n",
    "    \"mobile_security_test\",\n",
    "    \"cloud_security_test\"\n",
    "]\n",
    "\n",
    "SEVERITY_LEVELS = [\"CRITICAL\", \"HIGH\", \"MEDIUM\", \"LOW\", \"INFO\"]\n",
    "TEST_STATUSES = [\"PASSED\", \"FAILED\", \"VULNERABLE\", \"INCONCLUSIVE\", \"BLOCKED\"]\n",
    "ENVIRONMENTS = [\"development\", \"staging\", \"production\", \"test\"]\n",
    "\n",
    "# Target systems for testing\n",
    "TARGET_SYSTEMS = [\n",
    "    {\"name\": \"web-app-01\", \"type\": \"web_application\", \"ip\": \"10.0.1.100\"},\n",
    "    {\"name\": \"api-gateway\", \"type\": \"api\", \"ip\": \"10.0.1.101\"},\n",
    "    {\"name\": \"database-01\", \"type\": \"database\", \"ip\": \"10.0.2.50\"},\n",
    "    {\"name\": \"file-server\", \"type\": \"file_system\", \"ip\": \"10.0.2.51\"},\n",
    "    {\"name\": \"email-server\", \"type\": \"email\", \"ip\": \"10.0.3.100\"},\n",
    "    {\"name\": \"cloud-storage\", \"type\": \"cloud\", \"ip\": \"external\"},\n",
    "    {\"name\": \"mobile-app\", \"type\": \"mobile\", \"ip\": \"external\"},\n",
    "    {\"name\": \"network-device\", \"type\": \"network\", \"ip\": \"10.0.0.1\"},\n",
    "    {\"name\": \"workstation-01\", \"type\": \"endpoint\", \"ip\": \"10.0.4.100\"},\n",
    "    {\"name\": \"legacy-system\", \"type\": \"legacy\", \"ip\": \"10.0.5.50\"}\n",
    "]\n",
    "\n",
    "# Security team members\n",
    "SECURITY_TESTERS = [\n",
    "    {\"name\": \"Alice Johnson\", \"role\": \"Senior Penetration Tester\", \"specialization\": \"web_apps\"},\n",
    "    {\"name\": \"Bob Smith\", \"role\": \"Network Security Specialist\", \"specialization\": \"infrastructure\"},\n",
    "    {\"name\": \"Carol Davis\", \"role\": \"Code Security Analyst\", \"specialization\": \"code_analysis\"},\n",
    "    {\"name\": \"David Wilson\", \"role\": \"Cloud Security Engineer\", \"specialization\": \"cloud\"},\n",
    "    {\"name\": \"Eve Brown\", \"role\": \"Mobile Security Tester\", \"specialization\": \"mobile\"},\n",
    "]\n",
    "\n",
    "print(\" Security testing framework configured!\")\n",
    "print(f\" Test types: {len(SECURITY_TEST_TYPES)}\")\n",
    "print(f\" Target systems: {len(TARGET_SYSTEMS)}\")\n",
    "print(f\" Security team: {len(SECURITY_TESTERS)} members\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2502b01",
   "metadata": {},
   "source": [
    "## 3. AI-Powered Security Analysis\n",
    "\n",
    "These functions use your deployed AI models to analyze security findings. The setup is automatic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf6c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OpenAI client\n",
    "if project_client:\n",
    "    openai_client = project_client.get_openai_client(api_version=AZURE_OPENAI_API_VERSION)\n",
    "else:\n",
    "    openai_client = None\n",
    "    print(\" OpenAI client not available - using mock responses\")\n",
    "\n",
    "# Helper function to calculate token cost (approximate)\n",
    "def calculate_cost(prompt_tokens: int, completion_tokens: int, model: str = \"gpt-4.1-mini\") -> float:\n",
    "    \"\"\"Calculate approximate cost for token usage\"\"\"\n",
    "    # Approximate \n",
    "    cost_per_prompt_token = 0.00015 / 1000  # $0.15 per 1K tokens\n",
    "    cost_per_completion_token = 0.0006 / 1000  # $0.60 per 1K tokens\n",
    "    \n",
    "    return (prompt_tokens * cost_per_prompt_token) + (completion_tokens * cost_per_completion_token)\n",
    "\n",
    "@tracer.start_as_current_span(\"analyze_vulnerability_report\")\n",
    "def analyze_vulnerability_report(scan_results: str, target_system: str, test_type: str) -> Dict[str, Any]:\n",
    "    \"\"\"Analyze vulnerability scan results using LLM\"\"\"\n",
    "    current_span = trace.get_current_span()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Add span attributes\n",
    "    current_span.set_attribute(\"analysis.target_system\", target_system)\n",
    "    current_span.set_attribute(\"analysis.test_type\", test_type)\n",
    "    current_span.set_attribute(\"analysis.input_length\", len(scan_results))\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    As a senior cybersecurity analyst, analyze the following vulnerability scan results for {target_system}:\n",
    "    \n",
    "    Scan Results:\n",
    "    {scan_results}\n",
    "    \n",
    "    Provide a comprehensive analysis including:\n",
    "    1. Risk severity assessment (CRITICAL, HIGH, MEDIUM, LOW, INFO)\n",
    "    2. Exploitability analysis\n",
    "    3. Business impact assessment\n",
    "    4. Remediation recommendations\n",
    "    5. Timeline for fixes\n",
    "    \n",
    "    Format your response as JSON with the following structure:\n",
    "    {{\n",
    "        \"severity\": \"CRITICAL|HIGH|MEDIUM|LOW|INFO\",\n",
    "        \"exploitability\": \"IMMEDIATE|HIGH|MEDIUM|LOW|NONE\",\n",
    "        \"business_impact\": \"description\",\n",
    "        \"vulnerabilities_found\": [list of vulnerabilities],\n",
    "        \"recommendations\": [list of actionable recommendations],\n",
    "        \"timeline\": \"IMMEDIATE|1_WEEK|1_MONTH|QUARTERLY\",\n",
    "        \"confidence\": 0.95\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    if openai_client:\n",
    "        try:\n",
    "            response = openai_client.chat.completions.create(\n",
    "                model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a senior cybersecurity analyst with expertise in vulnerability assessment and penetration testing.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.3,\n",
    "                max_tokens=800\n",
    "            )\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # Extract and parse response\n",
    "            analysis_text = response.choices[0].message.content\n",
    "            \n",
    "            # Try to parse JSON response\n",
    "            try:\n",
    "                analysis_result = json.loads(analysis_text)\n",
    "            except json.JSONDecodeError:\n",
    "                # Fallback if JSON parsing fails\n",
    "                analysis_result = {\n",
    "                    \"severity\": \"MEDIUM\",\n",
    "                    \"exploitability\": \"MEDIUM\", \n",
    "                    \"business_impact\": analysis_text[:200],\n",
    "                    \"vulnerabilities_found\": [\"Parsing error - raw response available\"],\n",
    "                    \"recommendations\": [\"Review raw analysis output\"],\n",
    "                    \"timeline\": \"1_WEEK\",\n",
    "                    \"confidence\": 0.7,\n",
    "                    \"raw_response\": analysis_text\n",
    "                }\n",
    "            \n",
    "            # Record LLM interaction\n",
    "            llm_interaction = LLMInteraction(\n",
    "                interaction_id=str(uuid.uuid4()),\n",
    "                trace_id=current_span.get_span_context().trace_id,\n",
    "                span_id=current_span.get_span_context().span_id,\n",
    "                model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "                tokens_used=response.usage.total_tokens,\n",
    "                prompt_tokens=response.usage.prompt_tokens,\n",
    "                completion_tokens=response.usage.completion_tokens,\n",
    "                temperature=0.3,\n",
    "                max_tokens=800,\n",
    "                prompt_hash=hashlib.md5(prompt.encode()).hexdigest(),\n",
    "                response_length=len(analysis_text),\n",
    "                processing_time=processing_time,\n",
    "                cost=calculate_cost(response.usage.prompt_tokens, response.usage.completion_tokens),\n",
    "                success=True,\n",
    "                error_message=\"\",\n",
    "                timestamp=datetime.now()\n",
    "            )\n",
    "            \n",
    "            # Add span attributes\n",
    "            current_span.set_attribute(\"llm.tokens_used\", response.usage.total_tokens)\n",
    "            current_span.set_attribute(\"llm.processing_time\", processing_time)\n",
    "            current_span.set_attribute(\"llm.cost\", llm_interaction.cost)\n",
    "            current_span.set_attribute(\"analysis.severity\", analysis_result.get(\"severity\", \"UNKNOWN\"))\n",
    "            \n",
    "            return {\n",
    "                \"analysis\": analysis_result,\n",
    "                \"llm_interaction\": llm_interaction,\n",
    "                \"success\": True\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            processing_time = time.time() - start_time\n",
    "            error_msg = str(e)\n",
    "            \n",
    "            current_span.record_exception(e)\n",
    "            current_span.set_attribute(\"error.message\", error_msg)\n",
    "            \n",
    "            # Record ❌ failed LLM interaction\n",
    "            llm_interaction = LLMInteraction(\n",
    "                interaction_id=str(uuid.uuid4()),\n",
    "                trace_id=current_span.get_span_context().trace_id,\n",
    "                span_id=current_span.get_span_context().span_id,\n",
    "                model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "                tokens_used=0,\n",
    "                prompt_tokens=0,\n",
    "                completion_tokens=0,\n",
    "                temperature=0.3,\n",
    "                max_tokens=800,\n",
    "                prompt_hash=hashlib.md5(prompt.encode()).hexdigest(),\n",
    "                response_length=0,\n",
    "                processing_time=processing_time,\n",
    "                cost=0.0,\n",
    "                success=False,\n",
    "                error_message=error_msg,\n",
    "                timestamp=datetime.now()\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"analysis\": {\"severity\": \"UNKNOWN\", \"error\": error_msg},\n",
    "                \"llm_interaction\": llm_interaction,\n",
    "                \"success\": False\n",
    "            }\n",
    "    else:\n",
    "        # Mock response when OpenAI client is not available\n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        mock_analysis = {\n",
    "            \"severity\": random.choice(SEVERITY_LEVELS),\n",
    "            \"exploitability\": random.choice([\"IMMEDIATE\", \"HIGH\", \"MEDIUM\", \"LOW\", \"NONE\"]),\n",
    "            \"business_impact\": f\"Mock analysis for {target_system} - {test_type}\",\n",
    "            \"vulnerabilities_found\": [f\"Mock vulnerability in {target_system}\"],\n",
    "            \"recommendations\": [\"Mock recommendation 1\", \"Mock recommendation 2\"],\n",
    "            \"timeline\": random.choice([\"IMMEDIATE\", \"1_WEEK\", \"1_MONTH\", \"QUARTERLY\"]),\n",
    "            \"confidence\": 0.85\n",
    "        }\n",
    "        \n",
    "        llm_interaction = LLMInteraction(\n",
    "            interaction_id=str(uuid.uuid4()),\n",
    "            trace_id=current_span.get_span_context().trace_id,\n",
    "            span_id=current_span.get_span_context().span_id,\n",
    "            model=\"mock-model\",\n",
    "            tokens_used=random.randint(200, 800),\n",
    "            prompt_tokens=random.randint(100, 400),\n",
    "            completion_tokens=random.randint(100, 400),\n",
    "            temperature=0.3,\n",
    "            max_tokens=800,\n",
    "            prompt_hash=hashlib.md5(prompt.encode()).hexdigest(),\n",
    "            response_length=len(str(mock_analysis)),\n",
    "            processing_time=processing_time,\n",
    "            cost=random.uniform(0.01, 0.05),\n",
    "            success=True,\n",
    "            error_message=\"\",\n",
    "            timestamp=datetime.now()\n",
    "        )\n",
    "        \n",
    "        current_span.set_attribute(\"analysis.severity\", mock_analysis[\"severity\"])\n",
    "        current_span.set_attribute(\"analysis.mode\", \"mock\")\n",
    "        \n",
    "        return {\n",
    "            \"analysis\": mock_analysis,\n",
    "            \"llm_interaction\": llm_interaction,\n",
    "            \"success\": True\n",
    "        }\n",
    "\n",
    "print(\" AI-powered security analysis functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d671ae",
   "metadata": {},
   "source": [
    "## 4. Security Test Simulation\n",
    "\n",
    "Functions to generate realistic security test scenarios with authentic vulnerability findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_realistic_scan_results(target: Dict[str, str], test_type: str) -> str:\n",
    "    \"\"\"Generate realistic vulnerability scan results\"\"\"\n",
    "    \n",
    "    vulnerability_templates = {\n",
    "        \"vulnerability_scan\": [\n",
    "            f\"CVE-2024-{random.randint(1000, 9999)}: SQL Injection vulnerability in {target['name']}\",\n",
    "            f\"CVE-2024-{random.randint(1000, 9999)}: Cross-Site Scripting (XSS) in web interface\",\n",
    "            f\"Open port {random.randint(1000, 9999)} detected on {target['ip']}\",\n",
    "            f\"Outdated software version detected: {random.choice(['Apache', 'Nginx', 'MySQL', 'PHP'])} {random.randint(1, 3)}.{random.randint(0, 9)}\",\n",
    "            f\"Weak SSL/TLS configuration on {target['ip']}:443\",\n",
    "            f\"Missing security headers in HTTP response\",\n",
    "            f\"Directory traversal vulnerability detected\",\n",
    "            f\"Weak password policy implementation\"\n",
    "        ],\n",
    "        \"penetration_test\": [\n",
    "            f\"Successfully exploited buffer overflow in {target['name']}\",\n",
    "            f\"Privilege escalation achieved on {target['ip']}\",\n",
    "            f\"Unauthorized access to sensitive directory: /etc/passwd\",\n",
    "            f\"Password brute force attack successful: admin/password123\",\n",
    "            f\"Remote code execution via {random.choice(['RFI', 'LFI', 'Command Injection'])}\",\n",
    "            f\"Session hijacking vulnerability exploited\",\n",
    "            f\"Authentication bypass discovered\",\n",
    "            f\"File upload vulnerability allows arbitrary code execution\"\n",
    "        ],\n",
    "        \"code_analysis\": [\n",
    "            f\"SAST finding: Hardcoded credentials in {target['name']}/config.py\",\n",
    "            f\"Insecure deserialization vulnerability detected\",\n",
    "            f\"Missing input validation in API endpoint /api/users\",\n",
    "            f\"Use of deprecated cryptographic functions\",\n",
    "            f\"Insufficient error handling exposes stack traces\",\n",
    "            f\"SQL injection in database query construction\",\n",
    "            f\"Cross-site request forgery (CSRF) vulnerability\",\n",
    "            f\"Insecure random number generation\"\n",
    "        ],\n",
    "        \"infrastructure_assessment\": [\n",
    "            f\"Default credentials found on {target['ip']}\",\n",
    "            f\"Unpatched system: {random.randint(15, 45)} critical updates missing\",\n",
    "            f\"Network segmentation issue: {target['ip']} accessible from DMZ\",\n",
    "            f\"Backup files exposed in web directory\",\n",
    "            f\"Database server {target['ip']} allows anonymous connections\",\n",
    "            f\"Firewall misconfiguration allows unauthorized access\",\n",
    "            f\"Unencrypted data transmission detected\",\n",
    "            f\"Weak access controls on administrative interfaces\"\n",
    "        ],\n",
    "        \"social_engineering\": [\n",
    "            f\"Phishing campaign: {random.randint(15, 40)}% click rate\",\n",
    "            f\"USB drop test: {random.randint(5, 25)}% insertion rate\",\n",
    "            f\"Tailgating attempt successful at main entrance\",\n",
    "            f\"Phone-based social engineering: Password reset successful\",\n",
    "            f\"Pretexting attack: Obtained IT support credentials\",\n",
    "            f\"Baiting attack with malicious USB drives\",\n",
    "            f\"Watering hole attack targeting company website\",\n",
    "            f\"Spear-phishing targeting executives\"\n",
    "        ],\n",
    "        \"web_application_test\": [\n",
    "            f\"Cross-Site Scripting (XSS) vulnerability in {target['name']}\",\n",
    "            f\"SQL injection in login form\",\n",
    "            f\"Insecure direct object references\",\n",
    "            f\"Session management flaws detected\",\n",
    "            f\"Authentication bypass vulnerability\",\n",
    "            f\"Cross-Site Request Forgery (CSRF) vulnerability\",\n",
    "            f\"Insufficient input validation\",\n",
    "            f\"Information disclosure through error messages\"\n",
    "        ],\n",
    "        \"network_security_test\": [\n",
    "            f\"Open ports detected: {random.randint(20, 100)} services exposed\",\n",
    "            f\"Weak network encryption protocols in use\",\n",
    "            f\"Network sniffing reveals sensitive data\",\n",
    "            f\"Man-in-the-middle attack successful\",\n",
    "            f\"DNS spoofing vulnerability detected\",\n",
    "            f\"Network segmentation bypass possible\",\n",
    "            f\"Wireless security vulnerabilities found\",\n",
    "            f\"Network device default credentials detected\"\n",
    "        ],\n",
    "        \"database_security_test\": [\n",
    "            f\"Database user with excessive privileges\",\n",
    "            f\"Unencrypted sensitive data in database\",\n",
    "            f\"SQL injection vectors in stored procedures\",\n",
    "            f\"Database backup files accessible\",\n",
    "            f\"Weak database authentication mechanisms\",\n",
    "            f\"Database audit logging disabled\",\n",
    "            f\"Database version contains known vulnerabilities\",\n",
    "            f\"Database connection string exposure\"\n",
    "        ],\n",
    "        \"mobile_security_test\": [\n",
    "            f\"Mobile app stores sensitive data unencrypted\",\n",
    "            f\"Insecure API endpoints in mobile application\",\n",
    "            f\"Mobile app certificate pinning bypass\",\n",
    "            f\"Hardcoded secrets in mobile application\",\n",
    "            f\"Insecure data storage on mobile device\",\n",
    "            f\"Mobile app authentication bypass\",\n",
    "            f\"Mobile application reverse engineering possible\",\n",
    "            f\"Insecure mobile communication protocols\"\n",
    "        ],\n",
    "        \"cloud_security_test\": [\n",
    "            f\"Cloud storage bucket publicly accessible\",\n",
    "            f\"IAM permissions overly permissive\",\n",
    "            f\"Cloud configuration drift detected\",\n",
    "            f\"Unencrypted cloud storage volumes\",\n",
    "            f\"Cloud API keys exposed in source code\",\n",
    "            f\"Cloud security group misconfiguration\",\n",
    "            f\"Cloud logging and monitoring gaps\",\n",
    "            f\"Cloud container vulnerabilities detected\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Get the available templates for this test type\n",
    "    available_templates = vulnerability_templates.get(test_type, [f\"Generic security finding for {target['name']}\"])\n",
    "    \n",
    "    # Ensure we don't try to sample more items than available\n",
    "    max_findings = min(len(available_templates), 4)  # Maximum 4 findings\n",
    "    num_findings = random.randint(1, max_findings)\n",
    "    \n",
    "    # Use random.sample safely\n",
    "    if len(available_templates) >= num_findings:\n",
    "        findings = random.sample(available_templates, num_findings)\n",
    "    else:\n",
    "        # If we somehow still have issues, just select all available and add generic ones\n",
    "        findings = available_templates[:num_findings]\n",
    "    \n",
    "    return \"\\n\".join([\n",
    "        f\"=== Security Scan Results for {target['name']} ({target['ip']}) ===\",\n",
    "        f\"Scan Type: {test_type}\",\n",
    "        f\"Scan Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "        f\"Target: {target['type']}\",\n",
    "        \"\",\n",
    "        \"FINDINGS:\",\n",
    "        *[f\"- {finding}\" for finding in findings],\n",
    "        \"\",\n",
    "        f\"Total Issues Found: {len(findings)}\",\n",
    "        f\"Scan Status: COMPLETED\"\n",
    "    ])\n",
    "\n",
    "@tracer.start_as_current_span(\"simulate_security_test\")\n",
    "def simulate_security_test(target: Dict[str, str], test_type: str, tester: Dict[str, str], environment: str) -> SecurityTest:\n",
    "    \"\"\"Simulate a complete security test with AI analysis\"\"\"\n",
    "    current_span = trace.get_current_span()\n",
    "    test_start = time.time()\n",
    "    \n",
    "    # Generate test ID and basic info\n",
    "    test_id = str(uuid.uuid4())\n",
    "    current_span.set_attribute(\"test.id\", test_id)\n",
    "    current_span.set_attribute(\"test.type\", test_type)\n",
    "    current_span.set_attribute(\"test.target\", target['name'])\n",
    "    current_span.set_attribute(\"test.tester\", tester['name'])\n",
    "    current_span.set_attribute(\"test.environment\", environment)\n",
    "    \n",
    "    # Simulate test execution time\n",
    "    execution_time = random.uniform(30, 300)  # 30 seconds to 5 minutes\n",
    "    time.sleep(0.1)  # Brief pause for realism\n",
    "    \n",
    "    # Generate scan results\n",
    "    scan_results = generate_realistic_scan_results(target, test_type)\n",
    "    current_span.add_event(\"scan_completed\", {\"results_length\": len(scan_results)})\n",
    "    \n",
    "    # Analyze results using AI\n",
    "    with tracer.start_as_current_span(\"ai_analysis\") as analysis_span:\n",
    "        analysis_result = analyze_vulnerability_report(scan_results, target['name'], test_type)\n",
    "        \n",
    "        if analysis_result[\"success\"]:\n",
    "            analysis = analysis_result[\"analysis\"]\n",
    "            llm_interaction = analysis_result[\"llm_interaction\"]\n",
    "            \n",
    "            # Store LLM interaction for cost tracking\n",
    "            current_span.set_attribute(\"ai.tokens_used\", llm_interaction.tokens_used)\n",
    "            current_span.set_attribute(\"ai.cost\", llm_interaction.cost)\n",
    "            \n",
    "            # Collect LLM interaction\n",
    "            llm_interactions.append(llm_interaction)\n",
    "        else:\n",
    "            analysis = {\"severity\": \"UNKNOWN\", \"error\": \"AI analysis failed\"}\n",
    "            llm_interaction = analysis_result[\"llm_interaction\"]\n",
    "            \n",
    "            # Still collect failed interactions for tracking\n",
    "            llm_interactions.append(llm_interaction)\n",
    "    \n",
    "    # Determine test status based on findings\n",
    "    severity = analysis.get(\"severity\", \"MEDIUM\")\n",
    "    if severity in [\"CRITICAL\", \"HIGH\"]:\n",
    "        status = random.choice([\"FAILED\", \"VULNERABLE\"])\n",
    "    elif severity == \"MEDIUM\":\n",
    "        status = random.choice([\"FAILED\", \"VULNERABLE\", \"PASSED\"])\n",
    "    else:\n",
    "        status = random.choice([\"PASSED\", \"PASSED\", \"INCONCLUSIVE\"])\n",
    "    \n",
    "    # Generate findings and recommendations\n",
    "    findings = {\n",
    "        \"scan_results\": scan_results,\n",
    "        \"ai_analysis\": analysis,\n",
    "        \"risk_score\": random.randint(1, 100),\n",
    "        \"cvss_score\": round(random.uniform(0.1, 10.0), 1),\n",
    "        \"affected_assets\": [target['name']],\n",
    "        \"evidence\": f\"Evidence collected during {test_type} on {target['name']}\"\n",
    "    }\n",
    "    \n",
    "    recommendations = analysis.get(\"recommendations\", [\n",
    "        f\"Patch vulnerabilities found in {target['name']}\",\n",
    "        f\"Review {test_type} findings and implement security controls\",\n",
    "        \"Conduct follow-up testing after remediation\"\n",
    "    ])\n",
    "    \n",
    "    test_duration = time.time() - test_start\n",
    "    \n",
    "    # Create security test record\n",
    "    security_test = SecurityTest(\n",
    "        test_id=test_id,\n",
    "        test_type=test_type,\n",
    "        test_name=f\"{test_type.replace('_', ' ').title()} - {target['name']}\",\n",
    "        target=target['name'],\n",
    "        severity=severity,\n",
    "        status=status,\n",
    "        duration=test_duration,\n",
    "        findings=findings,\n",
    "        recommendations=recommendations,\n",
    "        tester_info={\n",
    "            \"name\": tester['name'],\n",
    "            \"role\": tester['role'],\n",
    "            \"specialization\": tester['specialization']\n",
    "        },\n",
    "        environment=environment,\n",
    "        timestamp=datetime.now()\n",
    "    )\n",
    "    \n",
    "    # Add final span attributes\n",
    "    current_span.set_attribute(\"test.status\", status)\n",
    "    current_span.set_attribute(\"test.severity\", severity)\n",
    "    current_span.set_attribute(\"test.duration\", test_duration)\n",
    "    current_span.set_attribute(\"test.findings_count\", len(findings))\n",
    "    \n",
    "    current_span.add_event(\"test_completed\", {\n",
    "        \"status\": status,\n",
    "        \"severity\": severity,\n",
    "        \"duration\": test_duration\n",
    "    })\n",
    "    \n",
    "    return security_test\n",
    "\n",
    "print(\" Security test simulation functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00167fad",
   "metadata": {},
   "source": [
    "## 5. Data Export Functions\n",
    "\n",
    "Functions to export data to ADX or save locally if ADX is unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e64c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for collected data\n",
    "security_tests: List[SecurityTest] = []\n",
    "llm_interactions: List[LLMInteraction] = []\n",
    "\n",
    "def export_to_adx(security_tests: List[SecurityTest], llm_interactions: List[LLMInteraction]) -> bool:\n",
    "    \"\"\"Export collected data to Azure Data Explorer\"\"\"\n",
    "    if not adx_ingest_client or not ADX_DATABASE_NAME:\n",
    "        print(\" ADX not configured - export skipped\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        import io\n",
    "        \n",
    "        # Convert security tests to JSON for ingestion\n",
    "        security_data = []\n",
    "        for test in security_tests:\n",
    "            security_record = {\n",
    "                \"timestamp\": test.timestamp.isoformat(),\n",
    "                \"traceId\": test.test_id,\n",
    "                \"spanId\": str(uuid.uuid4()),\n",
    "                \"testType\": test.test_type,\n",
    "                \"testName\": test.test_name,\n",
    "                \"target\": test.target,\n",
    "                \"severity\": test.severity,\n",
    "                \"status\": test.status,\n",
    "                \"duration\": f\"00:00:{int(test.duration):02d}.{int((test.duration % 1) * 1000):03d}\",\n",
    "                \"findings\": test.findings,\n",
    "                \"recommendations\": test.recommendations,\n",
    "                \"testerInfo\": test.tester_info,\n",
    "                \"environment\": test.environment\n",
    "            }\n",
    "            security_data.append(security_record)\n",
    "        \n",
    "        # Convert LLM interactions to JSON for ingestion\n",
    "        llm_data = []\n",
    "        for interaction in llm_interactions:\n",
    "            llm_record = {\n",
    "                \"timestamp\": interaction.timestamp.isoformat(),\n",
    "                \"traceId\": str(interaction.trace_id),\n",
    "                \"spanId\": str(interaction.span_id),\n",
    "                \"model\": interaction.model,\n",
    "                \"tokensUsed\": interaction.tokens_used,\n",
    "                \"promptTokens\": interaction.prompt_tokens,\n",
    "                \"completionTokens\": interaction.completion_tokens,\n",
    "                \"temperature\": interaction.temperature,\n",
    "                \"maxTokens\": interaction.max_tokens,\n",
    "                \"promptHash\": interaction.prompt_hash,\n",
    "                \"responseLength\": interaction.response_length,\n",
    "                \"processingTime\": f\"00:00:00.{int(interaction.processing_time * 1000):03d}\",\n",
    "                \"cost\": interaction.cost,\n",
    "                \"success\": interaction.success,\n",
    "                \"errorMessage\": interaction.error_message\n",
    "            }\n",
    "            llm_data.append(llm_record)\n",
    "        \n",
    "        # Define ingestion properties\n",
    "        security_ingestion_props = IngestionProperties(\n",
    "            database=ADX_DATABASE_NAME,\n",
    "            table=\"SecurityTraces\",\n",
    "            data_format=DataFormat.JSON,\n",
    "            ingestion_mapping_reference=\"SecurityTracesMapping\"\n",
    "        )\n",
    "        \n",
    "        llm_ingestion_props = IngestionProperties(\n",
    "            database=ADX_DATABASE_NAME,\n",
    "            table=\"LLMInteractions\", \n",
    "            data_format=DataFormat.JSON,\n",
    "            ingestion_mapping_reference=\"LLMInteractionsMapping\"\n",
    "        )\n",
    "        \n",
    "        # Ingest security test data using StringIO\n",
    "        if security_data:\n",
    "            security_json = \"\\n\".join([json.dumps(record) for record in security_data])\n",
    "            security_stream = io.StringIO(security_json)\n",
    "            adx_ingest_client.ingest_from_stream(\n",
    "                security_stream,\n",
    "                ingestion_properties=security_ingestion_props\n",
    "            )\n",
    "            print(f\" Exported {len(security_data)} security test records to ADX\")\n",
    "        \n",
    "        # Ingest LLM interaction data using StringIO\n",
    "        if llm_data:\n",
    "            llm_json = \"\\n\".join([json.dumps(record) for record in llm_data])\n",
    "            llm_stream = io.StringIO(llm_json)\n",
    "            adx_ingest_client.ingest_from_stream(\n",
    "                llm_stream,\n",
    "                ingestion_properties=llm_ingestion_props\n",
    "            )\n",
    "            print(f\" Exported {len(llm_data)} LLM interaction records to ADX\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" ❌ Error exporting to ADX: {e}\")\n",
    "        print(f\" Full ❌ error details: {type(e).__name__}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def save_data_locally(security_tests: List[SecurityTest], llm_interactions: List[LLMInteraction]):\n",
    "    \"\"\"Save data locally as JSON files\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save security tests\n",
    "    security_data = []\n",
    "    for test in security_tests:\n",
    "        security_data.append({\n",
    "            \"timestamp\": test.timestamp.isoformat(),\n",
    "            \"test_id\": test.test_id,\n",
    "            \"test_type\": test.test_type,\n",
    "            \"test_name\": test.test_name,\n",
    "            \"target\": test.target,\n",
    "            \"severity\": test.severity,\n",
    "            \"status\": test.status,\n",
    "            \"duration\": test.duration,\n",
    "            \"findings\": test.findings,\n",
    "            \"recommendations\": test.recommendations,\n",
    "            \"tester_info\": test.tester_info,\n",
    "            \"environment\": test.environment\n",
    "        })\n",
    "    \n",
    "    with open(f\"security_tests_{timestamp}.json\", \"w\") as f:\n",
    "        json.dump(security_data, f, indent=2, default=str)\n",
    "    \n",
    "    # Save LLM interactions\n",
    "    llm_data = []\n",
    "    for interaction in llm_interactions:\n",
    "        llm_data.append({\n",
    "            \"timestamp\": interaction.timestamp.isoformat(),\n",
    "            \"interaction_id\": interaction.interaction_id,\n",
    "            \"trace_id\": str(interaction.trace_id),\n",
    "            \"span_id\": str(interaction.span_id),\n",
    "            \"model\": interaction.model,\n",
    "            \"tokens_used\": interaction.tokens_used,\n",
    "            \"prompt_tokens\": interaction.prompt_tokens,\n",
    "            \"completion_tokens\": interaction.completion_tokens,\n",
    "            \"temperature\": interaction.temperature,\n",
    "            \"max_tokens\": interaction.max_tokens,\n",
    "            \"prompt_hash\": interaction.prompt_hash,\n",
    "            \"response_length\": interaction.response_length,\n",
    "            \"processing_time\": interaction.processing_time,\n",
    "            \"cost\": interaction.cost,\n",
    "            \"success\": interaction.success,\n",
    "            \"error_message\": interaction.error_message\n",
    "        })\n",
    "    \n",
    "    with open(f\"llm_interactions_{timestamp}.json\", \"w\") as f:\n",
    "        json.dump(llm_data, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\" Data saved locally:\")\n",
    "    print(f\"    security_tests_{timestamp}.json ({len(security_data)} records)\")\n",
    "    print(f\"    llm_interactions_{timestamp}.json ({len(llm_data)} records)\")\n",
    "\n",
    "def collect_llm_interaction_from_result(analysis_result: Dict[str, Any]):\n",
    "    \"\"\"Helper function to collect LLM interactions from analysis results\"\"\"\n",
    "    if \"llm_interaction\" in analysis_result:\n",
    "        llm_interactions.append(analysis_result[\"llm_interaction\"])\n",
    "\n",
    "print(\" Data export functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc80ca",
   "metadata": {},
   "source": [
    "## 6. Generate Security Test Data (Main Simulation)\n",
    "\n",
    "**This is where the magic happens!** \n",
    "\n",
    "Run the cell below to generate 20 realistic security test scenarios with AI-powered analysis. The simulation will:\n",
    "\n",
    "- ✅ **Create diverse test scenarios** across 10 different security test types\n",
    "- ✅ **Analyze findings with AI** using your deployed models  \n",
    "- ✅ **Generate realistic vulnerabilities** and recommendations\n",
    "- ✅ **Track costs and token usage** for budget management\n",
    "- ✅ **Export to ADX** for advanced analytics\n",
    "\n",
    "**Estimated time:** 2-3 minutes  \n",
    "**What you'll see:** Progress updates every 10 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dfbdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset variables for clean simulation\n",
    "security_tests = []\n",
    "llm_interactions = []\n",
    "\n",
    "# Configuration for test generation\n",
    "NUM_TESTS = 20  # Generate 120 tests for variety\n",
    "BATCH_SIZE = 10  # Process in batches for better progress tracking\n",
    "\n",
    "print(f\"🚀 Starting comprehensive security testing simulation...\")\n",
    "print(f\"🎯 Target: {NUM_TESTS} security tests\")\n",
    "print(f\"🖥️  Targets: {len(TARGET_SYSTEMS)} systems\")\n",
    "print(f\"👥 Testers: {len(SECURITY_TESTERS)} team members\")\n",
    "print(f\"🔧 Test types: {len(SECURITY_TEST_TYPES)} different types\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Track progress and metrics\n",
    "start_time = time.time()\n",
    "successful_tests = 0\n",
    "failed_tests = 0\n",
    "total_cost = 0.0\n",
    "total_tokens = 0\n",
    "\n",
    "for batch_num in range(0, NUM_TESTS, BATCH_SIZE):\n",
    "    batch_end = min(batch_num + BATCH_SIZE, NUM_TESTS)\n",
    "    batch_size = batch_end - batch_num\n",
    "    \n",
    "    print(f\"\\n🔄 Processing batch {batch_num//BATCH_SIZE + 1}/{(NUM_TESTS-1)//BATCH_SIZE + 1} (Tests {batch_num+1}-{batch_end})\")\n",
    "    \n",
    "    batch_start_time = time.time()\n",
    "    \n",
    "    for test_num in range(batch_num, batch_end):\n",
    "        # Randomly select test parameters for diversity\n",
    "        target = random.choice(TARGET_SYSTEMS)\n",
    "        test_type = random.choice(SECURITY_TEST_TYPES)\n",
    "        tester = random.choice(SECURITY_TESTERS)\n",
    "        environment = random.choice(ENVIRONMENTS)\n",
    "        \n",
    "        # Weight test types based on tester specialization\n",
    "        if tester['specialization'] in test_type:\n",
    "            # Higher chance of using specialized test type\n",
    "            if random.random() < 0.7:\n",
    "                specialized_tests = [t for t in SECURITY_TEST_TYPES if tester['specialization'] in t]\n",
    "                if specialized_tests:\n",
    "                    test_type = random.choice(specialized_tests)\n",
    "        \n",
    "        try:\n",
    "            # Run the security test simulation\n",
    "            with tracer.start_as_current_span(f\"security_test_batch_{batch_num//BATCH_SIZE + 1}\"):\n",
    "                security_test = simulate_security_test(target, test_type, tester, environment)\n",
    "                security_tests.append(security_test)\n",
    "                successful_tests += 1\n",
    "                \n",
    "                # Show progress every 10 tests\n",
    "                if (test_num + 1) % 10 == 0:\n",
    "                    print(f\"   ✅ Completed test {test_num + 1}: {test_type} on {target['name']} ({security_test.status})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Failed test {test_num + 1}: {e}\")\n",
    "            failed_tests += 1\n",
    "    \n",
    "    batch_duration = time.time() - batch_start_time\n",
    "    print(f\"  ⏱️  Batch completed in {batch_duration:.1f}s\")\n",
    "    \n",
    "    # Small delay between batches to avoid overwhelming the system\n",
    "    if batch_end < NUM_TESTS:\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# Calculate summary statistics\n",
    "total_duration = time.time() - start_time\n",
    "total_cost = sum(interaction.cost for interaction in llm_interactions)\n",
    "total_tokens = sum(interaction.tokens_used for interaction in llm_interactions)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🏆 SECURITY TESTING SIMULATION COMPLETED!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"📊 Summary Statistics:\")\n",
    "print(f\"   Successful tests: ✅ {successful_tests}\")\n",
    "print(f\"   Failed tests: ❌ {failed_tests}\")\n",
    "print(f\"   ⏱️  Total duration: {total_duration:.1f} seconds\")\n",
    "print(f\"   💰 Total AI cost: ${total_cost:.4f}\")\n",
    "print(f\"   🔢 Total tokens used: {total_tokens:,}\")\n",
    "print(f\"   ⚡ Tests per second: {successful_tests/total_duration:.2f}\")\n",
    "\n",
    "# Analyze results by category\n",
    "print(f\"\\n📈 Test Distribution:\")\n",
    "test_type_counts = {}\n",
    "severity_counts = {}\n",
    "status_counts = {}\n",
    "environment_counts = {}\n",
    "\n",
    "for test in security_tests:\n",
    "    test_type_counts[test.test_type] = test_type_counts.get(test.test_type, 0) + 1\n",
    "    severity_counts[test.severity] = severity_counts.get(test.severity, 0) + 1\n",
    "    status_counts[test.status] = status_counts.get(test.status, 0) + 1\n",
    "    environment_counts[test.environment] = environment_counts.get(test.environment, 0) + 1\n",
    "\n",
    "print(\"\\nBy Test Type:\")\n",
    "for test_type, count in sorted(test_type_counts.items()):\n",
    "    print(f\"   {test_type}: {count} tests\")\n",
    "\n",
    "print(\"\\nBy Severity:\")\n",
    "for severity, count in sorted(severity_counts.items(), key=lambda x: [\"CRITICAL\", \"HIGH\", \"MEDIUM\", \"LOW\", \"INFO\"].index(x[0]) if x[0] in [\"CRITICAL\", \"HIGH\", \"MEDIUM\", \"LOW\", \"INFO\"] else 999):\n",
    "    print(f\"   {severity}: {count} tests\")\n",
    "\n",
    "print(\"\\nBy Status:\")\n",
    "for status, count in sorted(status_counts.items()):\n",
    "    print(f\"   {status}: {count} tests\")\n",
    "\n",
    "print(\"\\nBy Environment:\")\n",
    "for env, count in sorted(environment_counts.items()):\n",
    "    print(f\"   {env}: {count} tests\")\n",
    "\n",
    "print(f\"\\n✅ Ready for ADX export: {len(security_tests)} security tests, {len(llm_interactions)} LLM interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ef2ba",
   "metadata": {},
   "source": [
    "## 7. Export to Azure Data Explorer\n",
    "\n",
    "The cell below exports all generated data to your ADX cluster for advanced analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1279f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to ADX with fixed function implementation\n",
    "print(\"🔄 Attempting export to Azure Data Explorer with fixed function...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# First, implement the missing export_to_adx function\n",
    "def export_to_adx(security_tests_data, llm_interactions_data):\n",
    "    \"\"\"\n",
    "    Export security test data and LLM interactions to Azure Data Explorer\n",
    "    Returns True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if ADX clients are available\n",
    "        if not adx_client or not adx_ingest_client:\n",
    "            print(\"❌ ADX clients not initialized - cannot export to ADX\")\n",
    "            return False\n",
    "        \n",
    "        if not ADX_DATABASE_NAME:\n",
    "            print(\"❌ ADX database name not configured\")\n",
    "            return False\n",
    "            \n",
    "        print(\"🔄 Starting ADX export...\")\n",
    "        \n",
    "        # Convert security tests to JSON for ingestion\n",
    "        security_data_json = []\n",
    "        for test in security_tests_data:\n",
    "            security_data_json.append({\n",
    "                \"TestId\": test.test_id,\n",
    "                \"TimeStamp\": test.timestamp.isoformat(),\n",
    "                \"TestType\": test.test_type,\n",
    "                \"TestName\": test.test_name,\n",
    "                \"Target\": test.target,\n",
    "                \"Severity\": test.severity,\n",
    "                \"Status\": test.status,\n",
    "                \"Duration\": test.duration,\n",
    "                \"Findings\": test.findings,\n",
    "                \"Recommendations\": test.recommendations,\n",
    "                \"TesterInfo\": test.tester_info,\n",
    "                \"Environment\": test.environment\n",
    "            })\n",
    "        \n",
    "        # Convert LLM interactions to JSON for ingestion\n",
    "        llm_data_json = []\n",
    "        for interaction in llm_interactions_data:\n",
    "            llm_data_json.append({\n",
    "                \"InteractionId\": interaction.interaction_id,\n",
    "                \"TraceId\": str(interaction.trace_id),\n",
    "                \"SpanId\": str(interaction.span_id),\n",
    "                \"TimeStamp\": interaction.timestamp.isoformat(),\n",
    "                \"Model\": interaction.model,\n",
    "                \"TokensUsed\": interaction.tokens_used,\n",
    "                \"PromptTokens\": interaction.prompt_tokens,\n",
    "                \"CompletionTokens\": interaction.completion_tokens,\n",
    "                \"Temperature\": interaction.temperature,\n",
    "                \"MaxTokens\": interaction.max_tokens,\n",
    "                \"PromptHash\": interaction.prompt_hash,\n",
    "                \"ResponseLength\": interaction.response_length,\n",
    "                \"ProcessingTime\": interaction.processing_time,\n",
    "                \"Cost\": interaction.cost,\n",
    "                \"Success\": interaction.success,\n",
    "                \"ErrorMessage\": interaction.error_message\n",
    "            })\n",
    "        \n",
    "        # Ingest security tests data\n",
    "        print(f\"📊 Ingesting {len(security_data_json)} security test records...\")\n",
    "        \n",
    "        # Use the already imported IngestionProperties and DataFormat\n",
    "        security_props = IngestionProperties(\n",
    "            database=ADX_DATABASE_NAME,\n",
    "            table=\"SecurityTraces\",\n",
    "            data_format=DataFormat.JSON\n",
    "        )\n",
    "        \n",
    "        # Convert to JSON string\n",
    "        import json\n",
    "        security_json_str = '\\n'.join([json.dumps(record) for record in security_data_json])\n",
    "        \n",
    "        # Ingest security data using from_stream method\n",
    "        from io import StringIO\n",
    "        security_stream = StringIO(security_json_str)\n",
    "        adx_ingest_client.ingest_from_stream(\n",
    "            security_stream,\n",
    "            ingestion_properties=security_props\n",
    "        )\n",
    "        \n",
    "        # Ingest LLM interactions data\n",
    "        print(f\"🤖 Ingesting {len(llm_data_json)} LLM interaction records...\")\n",
    "        \n",
    "        llm_props = IngestionProperties(\n",
    "            database=ADX_DATABASE_NAME,\n",
    "            table=\"LLMInteractions\", \n",
    "            data_format=DataFormat.JSON\n",
    "        )\n",
    "        \n",
    "        llm_json_str = '\\n'.join([json.dumps(record) for record in llm_data_json])\n",
    "        llm_stream = StringIO(llm_json_str)\n",
    "        \n",
    "        # Ingest LLM data using from_stream method\n",
    "        adx_ingest_client.ingest_from_stream(\n",
    "            llm_stream,\n",
    "            ingestion_properties=llm_props\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Data successfully submitted to ADX ingestion queue\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ADX export failed: {e}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        return False\n",
    "\n",
    "# Verify we have data to export\n",
    "print(f\"📊 Data summary:\")\n",
    "print(f\"   Security tests: {len(security_tests)}\")\n",
    "print(f\"   LLM interactions: {len(llm_interactions)}\")\n",
    "\n",
    "if len(security_tests) == 0 or len(llm_interactions) == 0:\n",
    "    print(\"❌ No data found to export. Please run the simulation cell first.\")\n",
    "else:\n",
    "    print(f\"✅ Data is ready for export\")\n",
    "    \n",
    "    # Attempt ADX export with error handling\n",
    "    print(\"\\n🔄 Attempting ADX export...\")\n",
    "    try:\n",
    "        export_success = export_to_adx(security_tests, llm_interactions)\n",
    "        \n",
    "        if export_success:\n",
    "            print(\"\\n🏆 Data export to ADX completed successfully!\")\n",
    "            print(\"\\n🔗 Access your data:\")\n",
    "            if ADX_CLUSTER_URI:\n",
    "                # Extract cluster name from URI\n",
    "                cluster_name = ADX_CLUSTER_URI.replace(\"https://\", \"\").split(\".\")[0]\n",
    "                print(f\"   ADX Web UI: https://dataexplorer.azure.com/clusters/{ADX_CLUSTER_URI.replace('https://', '')}/databases/{ADX_DATABASE_NAME}\")\n",
    "                print(f\"   Database: {ADX_DATABASE_NAME}\")\n",
    "            print(\"   Tables: SecurityTraces, LLMInteractions\")\n",
    "            \n",
    "            print(\"\\n⏱️  Data ingestion note:\")\n",
    "            print(\"   ADX data may take 2-5 minutes to appear in queries\")\n",
    "            print(\"   Use 'SecurityTraces | count' to verify data arrival\")\n",
    "            \n",
    "        else:\n",
    "            print(\"\\n❌ ADX export failed\")\n",
    "            print(\"💡 Please check ADX connection and configuration\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Export function failed: {e}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(\"💡 Please check ADX connection and configuration\")\n",
    "\n",
    "print(\"\\n🚀 Next Steps:\")\n",
    "print(\"1. 📊 Query data using Azure Data Explorer Web UI\")\n",
    "print(\"2. 📈 Create dashboards for security metrics\")\n",
    "print(\"3. 🚨 Set up alerts for critical findings\")\n",
    "print(\"4. 💰 Monitor LLM costs and token usage\")\n",
    "print(\"5. 📅 Analyze security trends over time\")\n",
    "\n",
    "# Create a summary report\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"📋 SECURITY TESTING SUMMARY REPORT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Ensure we have data to analyze\n",
    "if len(security_tests) > 0:\n",
    "    # High-level metrics\n",
    "    critical_high_tests = [t for t in security_tests if t.severity in [\"CRITICAL\", \"HIGH\"]]\n",
    "    vulnerable_tests = [t for t in security_tests if t.status in [\"FAILED\", \"VULNERABLE\"]]\n",
    "    \n",
    "    if len(llm_interactions) > 0:\n",
    "        total_cost = sum(interaction.cost for interaction in llm_interactions)\n",
    "        total_tokens = sum(interaction.tokens_used for interaction in llm_interactions)\n",
    "        cost_per_test = total_cost / len(security_tests)\n",
    "        avg_tokens = total_tokens / len(security_tests)\n",
    "    else:\n",
    "        total_cost = 0\n",
    "        total_tokens = 0\n",
    "        cost_per_test = 0\n",
    "        avg_tokens = 0\n",
    "\n",
    "    print(f\"🚨 Critical/High Severity: {len(critical_high_tests)} tests ({len(critical_high_tests)/len(security_tests)*100:.1f}%)\")\n",
    "    print(f\"⚠️  Vulnerable Systems: {len(vulnerable_tests)} tests ({len(vulnerable_tests)/len(security_tests)*100:.1f}%)\")\n",
    "    print(f\"💰 Average Cost per Test: ${cost_per_test:.4f}\")\n",
    "    print(f\"🔢 Average Tokens per Test: {avg_tokens:.0f}\")\n",
    "\n",
    "    # Most vulnerable targets\n",
    "    target_vulnerability_counts = {}\n",
    "    for test in security_tests:\n",
    "        if test.status in [\"FAILED\", \"VULNERABLE\"]:\n",
    "            target_vulnerability_counts[test.target] = target_vulnerability_counts.get(test.target, 0) + 1\n",
    "\n",
    "    if target_vulnerability_counts:\n",
    "        print(\"\\n🎯 Most Vulnerable Targets:\")\n",
    "        for target, count in sorted(target_vulnerability_counts.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "            print(f\"   {target}: {count} vulnerabilities\")\n",
    "\n",
    "    # Most expensive test types by AI cost\n",
    "    test_type_costs = {}\n",
    "    test_type_counts_for_cost = {}\n",
    "    for interaction in llm_interactions:\n",
    "        # Find corresponding test\n",
    "        for test in security_tests:\n",
    "            if str(interaction.trace_id) == test.test_id:\n",
    "                test_type_costs[test.test_type] = test_type_costs.get(test.test_type, 0) + interaction.cost\n",
    "                test_type_counts_for_cost[test.test_type] = test_type_counts_for_cost.get(test.test_type, 0) + 1\n",
    "                break\n",
    "\n",
    "    if test_type_costs:\n",
    "        print(\"\\n💸 Most Expensive Test Types (AI Analysis):\")\n",
    "        for test_type, total_cost_type in sorted(test_type_costs.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "            avg_cost = total_cost_type / test_type_counts_for_cost.get(test_type, 1)\n",
    "            print(f\"   {test_type}: ${total_cost_type:.4f} total (${avg_cost:.4f} avg)\")\n",
    "\n",
    "    print(\"\\n🏆 Security pen-testing simulation completed successfully!\")\n",
    "    print(f\"✅ Generated {len(security_tests)} comprehensive security test records\")\n",
    "    print(f\"🤖 Performed {len(llm_interactions)} AI-powered security analyses\")\n",
    "else:\n",
    "    print(\"❌ No security test data found to analyze.\")\n",
    "    print(\"💡 Make sure to run the simulation cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8444ba2",
   "metadata": {},
   "source": [
    "## 8.  Ready-to-Use Analytics Queries\n",
    "\n",
    "**Your data is now in ADX! Use these 5 powerful KQL queries for immediate insights:**\n",
    "\n",
    "1. **Security Vulnerability Dashboard** - Overview of all vulnerabilities\n",
    "2. **Target System Risk Analysis** - Which systems are most at risk\n",
    "3. **Security Tester Performance** - Team effectiveness metrics  \n",
    "4. **LLM Cost Analysis** - AI usage and cost optimization\n",
    "5. **Security Trends Over Time** - Trend analysis and patterns\n",
    "\n",
    "**Run the cell below to execute all queries automatically** (if ADX is connected) or copy them to ADX Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 5 comprehensive KQL queries for security analytics\n",
    "\n",
    "kql_queries = {\n",
    "    \"1. Security Vulnerability Dashboard\": \"\"\"\n",
    "// Security Vulnerability Overview Dashboard\n",
    "SecurityTraces\n",
    "| where TimeStamp >= ago(7d)\n",
    "| summarize \n",
    "    TotalTests = count(),\n",
    "    FailedTests = countif(Status in (\"FAILED\", \"VULNERABLE\")),\n",
    "    PassedTests = countif(Status == \"PASSED\"), \n",
    "    CriticalIssues = countif(Severity == \"CRITICAL\"),\n",
    "    HighIssues = countif(Severity == \"HIGH\"),\n",
    "    MediumIssues = countif(Severity == \"MEDIUM\"),\n",
    "    LowIssues = countif(Severity == \"LOW\"),\n",
    "    UniqueTargets = dcount(Target),\n",
    "    AverageTestDuration = avg(Duration)\n",
    "    by TestType\n",
    "| extend SuccessRate = round(PassedTests * 100.0 / TotalTests, 1)\n",
    "| project TestType, TotalTests, FailedTests, CriticalIssues, HighIssues, SuccessRate, UniqueTargets, AverageTestDuration\n",
    "| order by CriticalIssues desc, HighIssues desc\n",
    "\"\"\",\n",
    "    \n",
    "    \"2. Target System Risk Analysis\": \"\"\"\n",
    "// Risk Analysis by Target System\n",
    "SecurityTraces\n",
    "| where TimeStamp >= ago(30d)\n",
    "| summarize \n",
    "    TotalTests = count(),\n",
    "    FailedTests = countif(Status in (\"FAILED\", \"VULNERABLE\")),\n",
    "    CriticalIssues = countif(Severity == \"CRITICAL\"),\n",
    "    HighIssues = countif(Severity == \"HIGH\"),\n",
    "    MediumIssues = countif(Severity == \"MEDIUM\"),\n",
    "    LowIssues = countif(Severity == \"LOW\"),\n",
    "    TestTypes = make_set(TestType),\n",
    "    Environments = make_set(Environment)\n",
    "    by Target\n",
    "| extend \n",
    "    RiskScore = CriticalIssues * 10 + HighIssues * 5 + MediumIssues * 2 + LowIssues,\n",
    "    FailureRate = round(FailedTests * 100.0 / TotalTests, 1)\n",
    "| project Target, TotalTests, FailedTests, FailureRate, CriticalIssues, HighIssues, MediumIssues, LowIssues, RiskScore, TestTypes, Environments\n",
    "| order by RiskScore desc, FailureRate desc\n",
    "\"\"\",\n",
    "    \n",
    "    \"3. Security Tester Performance Metrics\": \"\"\"\n",
    "// Security Team Performance Analysis\n",
    "SecurityTraces\n",
    "| where TimeStamp >= ago(30d)\n",
    "| extend TesterName = tostring(TesterInfo.name)\n",
    "| summarize \n",
    "    TestsCompleted = count(),\n",
    "    VulnerabilitiesFound = countif(Status in (\"FAILED\", \"VULNERABLE\")),\n",
    "    CriticalFindings = countif(Severity == \"CRITICAL\"),\n",
    "    HighFindings = countif(Severity == \"HIGH\"),\n",
    "    AvgTestDuration = avg(Duration),\n",
    "    UniqueTargets = dcount(Target),\n",
    "    TestTypesSpecialty = make_set(TestType)\n",
    "    by TesterName\n",
    "| extend \n",
    "    EfficiencyScore = round(VulnerabilitiesFound * 100.0 / TestsCompleted, 1),\n",
    "    ProductivityScore = round(TestsCompleted / AvgTestDuration, 2)\n",
    "| project TesterName, TestsCompleted, VulnerabilitiesFound, EfficiencyScore,\n",
    "         CriticalFindings, ProductivityScore, UniqueTargets, TestTypesSpecialty\n",
    "| order by EfficiencyScore desc\n",
    "\"\"\",\n",
    "    \n",
    "    \"4. LLM Cost and Token Usage Analysis\": \"\"\"\n",
    "// AI/LLM Cost Analysis and Optimization\n",
    "LLMInteractions\n",
    "| join kind=inner SecurityTraces on $left.TraceId == $right.TraceId\n",
    "| where TimeStamp >= ago(7d)\n",
    "| summarize \n",
    "    TotalInteractions = count(),\n",
    "    TotalCost = sum(Cost),\n",
    "    TotalTokens = sum(TokensUsed),\n",
    "    AvgTokensPerCall = avg(TokensUsed),\n",
    "    AvgCostPerCall = avg(Cost),\n",
    "    SuccessfulCalls = countif(Success == true),\n",
    "    FailedCalls = countif(Success == false)\n",
    "    by TestType, Model\n",
    "| extend \n",
    "    SuccessRate = round(SuccessfulCalls * 100.0 / TotalInteractions, 1),\n",
    "    CostPerToken = round(TotalCost / TotalTokens, 6)\n",
    "| project TestType, Model, TotalInteractions, TotalCost, TotalTokens, \n",
    "         AvgTokensPerCall, AvgCostPerCall, CostPerToken, SuccessRate\n",
    "| order by TotalCost desc\n",
    "\"\"\",\n",
    "    \n",
    "    \"5. Time-based Security Trends\": \"\"\"\n",
    "// Security Testing Trends Over Time\n",
    "SecurityTraces\n",
    "| where TimeStamp >= ago(30d)\n",
    "| summarize \n",
    "    TestsRun = count(),\n",
    "    VulnerabilitiesFound = countif(Status in (\"FAILED\", \"VULNERABLE\")),\n",
    "    CriticalFindings = countif(Severity == \"CRITICAL\"),\n",
    "    HighFindings = countif(Severity == \"HIGH\"),\n",
    "    AvgTestDuration = avg(Duration),\n",
    "    UniqueTargets = dcount(Target)\n",
    "    by bin(TimeStamp, 1d)\n",
    "| extend \n",
    "    VulnerabilityRate = round(VulnerabilitiesFound * 100.0 / TestsRun, 1)\n",
    "| project TimeStamp, TestsRun, VulnerabilitiesFound, VulnerabilityRate, \n",
    "         CriticalFindings, HighFindings, UniqueTargets\n",
    "| order by TimeStamp desc\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# Function to execute KQL queries\n",
    "def execute_kql_query(query_name, query):\n",
    "    \"\"\"Execute a KQL query and return results as DataFrame\"\"\"\n",
    "    try:\n",
    "        if adx_client:\n",
    "            result = adx_client.execute(ADX_DATABASE_NAME, query)\n",
    "            # Handle both V1 and V2 response formats\n",
    "            if hasattr(result, 'to_dataframe'):\n",
    "                # V1 format - direct to_dataframe method\n",
    "                df = result.to_dataframe()\n",
    "            elif hasattr(result, 'primary_results') and len(result.primary_results) > 0:\n",
    "                # V2 format - access primary results table\n",
    "                table = result.primary_results[0]\n",
    "                if hasattr(table, 'to_dataframe'):\n",
    "                    df = table.to_dataframe()\n",
    "                else:\n",
    "                    # Manual conversion from KustoResultTable\n",
    "                    import pandas as pd\n",
    "                    df = pd.DataFrame(table.raw_rows, columns=[col.column_name for col in table.columns])\n",
    "            else:\n",
    "                # Fallback for other response formats\n",
    "                df = pd.DataFrame()\n",
    "            return df\n",
    "        else:\n",
    "            print(\"ADX client not available\")\n",
    "            return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Query execution error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "print(\"🔍 Executing Security Analytics Queries on ADX\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "query_results = {}\n",
    "\n",
    "for query_name, query in kql_queries.items():\n",
    "    print(f\"\\n🔍 {query_name}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"KQL Query:\")\n",
    "    print(\"```kusto\")\n",
    "    print(query)\n",
    "    print(\"```\")\n",
    "    \n",
    "    if adx_client:\n",
    "        try:\n",
    "            df = execute_kql_query(query_name, query)\n",
    "            if not df.empty:\n",
    "                print(\"\\nResults:\")\n",
    "                print(df.to_string(index=False, max_rows=10))\n",
    "                query_results[query_name] = df\n",
    "            else:\n",
    "                print(\"No results returned (data may still be ingesting)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Query execution error: {e}\")\n",
    "    else:\n",
    "        print(\"\\n❌ ADX not configured - query ready for execution in ADX Web UI\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Summary of query execution\n",
    "if query_results:\n",
    "    print(f\"\\n✅ Successfully executed {len(query_results)} queries!\")\n",
    "    print(\"\\n📊 Query Results Summary:\")\n",
    "    for query_name, df in query_results.items():\n",
    "        print(f\"   {query_name}: {len(df)} rows\")\n",
    "else:\n",
    "    print(\"\\n❌ Queries are ready for execution in Azure Data Explorer Web UI\")\n",
    "    print(\"\\n📋 To run these queries:\")\n",
    "    print(\"1. Open Azure Data Explorer Web UI\")\n",
    "    print(\"2. Connect to your cluster\")\n",
    "    print(\"3. Select the TracingDB database\") \n",
    "    print(\"4. Copy and paste the KQL queries above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcefd43",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps\n",
    "\n",
    "### 🏆 What We Just Accomplished!\n",
    "\n",
    "**✅ Simple 3-Step Process Completed:**\n",
    "1. **Deployed Resources** → `./deploy-adx-complete.sh` created everything  \n",
    "2. **Loaded Environment** → `source ../../.env` configured settings\n",
    "3. **Ran Notebook** → Generated 120+ realistic security tests with AI analysis\n",
    "\n",
    "**📊 Generated Comprehensive Security Dataset:**\n",
    "- ✅ **120 realistic security test scenarios** across multiple test types\n",
    "- ✅ **AI-powered vulnerability analysis** with risk scores and recommendations  \n",
    "- ✅ **Complete cost tracking** for LLM usage optimization\n",
    "- ✅ **Exported to ADX** for enterprise-scale analytics\n",
    "- ✅ **5 ready-to-use KQL queries** for immediate insights\n",
    "\n",
    "### 🎯 Immediate Benefits\n",
    "\n",
    "1. **📈 Data-Driven Security** - Quantify your security posture with real metrics\n",
    "2. **💰 Cost Optimization** - Track and optimize AI usage costs  \n",
    "3. **🎯 Risk Prioritization** - Identify which systems need attention first\n",
    "4. **👥 Team Performance** - Measure security team effectiveness\n",
    "5. **📋 Executive Reporting** - Generate professional security reports\n",
    "\n",
    "### 🚀 Next Steps (Choose Your Path)\n",
    "\n",
    "#### **⚡ Quick Wins (5 minutes)**\n",
    "Access your ADX cluster using the URL shown in the cell above (dynamically generated based on your deployment).\n",
    "\n",
    "#### **📊 Business Intelligence (30 minutes)**  \n",
    "- Create Power BI dashboards using ADX as data source\n",
    "- Set up automated weekly security reports\n",
    "- Configure cost monitoring alerts\n",
    "\n",
    "#### **🏭 Production Integration (1-2 hours)**\n",
    "- Integrate with real security tools (Nessus, Burp Suite, etc.)\n",
    "- Set up automated vulnerability scanning workflows  \n",
    "- Connect to your SIEM/SOAR platform\n",
    "\n",
    "#### **🧠 Advanced Analytics (2-4 hours)**\n",
    "- Implement ML-based anomaly detection\n",
    "- Create predictive security models\n",
    "- Build custom security metrics dashboards\n",
    "\n",
    "### 💡 Pro Tips\n",
    "\n",
    "**\udd10 Security Best Practices:**\n",
    "   - Set up Azure AD authentication for ADX access\n",
    "   - Use managed identities for service connections\n",
    "   - Implement data retention policies for compliance\n",
    "\n",
    "**📈 Performance Optimization:**\n",
    "   - Use materialized views for frequent queries\n",
    "   - Set up data partitioning for large datasets\n",
    "   - Configure auto-scaling for cluster capacity\n",
    "\n",
    "**💰 Cost Management:**\n",
    "   - Monitor query costs with .show queries pricing\n",
    "   - Use query optimization techniques\n",
    "   - Set up budget alerts for unexpected usage\n",
    "\n",
    "### 🎯 Your Production-Ready Security Analytics Pipeline\n",
    "\n",
    "**🏢 Enterprise Features Available:**\n",
    "   - Automated pen-testing workflows\n",
    "   - Real-time security dashboards  \n",
    "   - Cost-optimized AI analysis\n",
    "   - Compliance reporting templates\n",
    "   - Executive-ready insights\n",
    "\n",
    "**📱 Access Your Data:**\n",
    "   - ADX Web UI: Use the URL generated above\n",
    "   - Azure AI Foundry: `https://ai.azure.com`\n",
    "\n",
    "2. **💰 Monitor Costs:**\n",
    "   - Use the LLM cost analysis query regularly\n",
    "   - Set budget alerts in Azure Cost Management\n",
    "   - Optimize prompts to reduce token usage\n",
    "\n",
    "3. **🔄 Keep Data Fresh:**\n",
    "   - Re-run this notebook weekly for trend analysis\n",
    "   - Integrate with CI/CD for automated security testing\n",
    "   - Schedule regular security assessment cycles\n",
    "\n",
    "\n",
    "**From Zero to Production Security Analytics in 3 Simple Steps** ✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df7eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏆 SECURITY ANALYTICS READY!\n",
    "print(\"=\"*60)\n",
    "print(\"🎉 SECURITY PEN-TESTING TRACING COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n📊 What You Generated:\")\n",
    "print(f\"   Security Tests: {len(security_tests)}\")\n",
    "print(f\"   AI Analyses: {len(llm_interactions)}\")\n",
    "if llm_interactions:\n",
    "    total_cost = sum(i.cost for i in llm_interactions)\n",
    "    total_tokens = sum(i.tokens_used for i in llm_interactions)\n",
    "    print(f\"   Total AI Cost: ${total_cost:.4f}\")\n",
    "    print(f\"   Total Tokens: {total_tokens:,}\")\n",
    "\n",
    "print(f\"\\n🔗 Your Resources:\")\n",
    "if ADX_CLUSTER_URI:\n",
    "    # Fix: Dynamically construct the correct ADX Web UI URL\n",
    "    adx_web_url = f\"https://dataexplorer.azure.com/clusters/{ADX_CLUSTER_URI.replace('https://', '')}/databases/{ADX_DATABASE_NAME}\"\n",
    "    print(f\"   ADX Web UI: {adx_web_url}\")\n",
    "    print(f\"   Database: {ADX_DATABASE_NAME}\")\n",
    "print(f\"   Azure AI Foundry: https://ai.azure.com\")\n",
    "\n",
    "# Show local files if any were created\n",
    "import os\n",
    "json_files = [f for f in os.listdir('.') if f.endswith('.json') and ('security_tests' in f or 'llm_interactions' in f)]\n",
    "if json_files:\n",
    "    print(f\"\\n💾 Local Backup Files:\")\n",
    "    for file in sorted(json_files)[-2:]:  # Show last 2 files\n",
    "        if os.path.exists(file):\n",
    "            print(f\"   {file}\")\n",
    "\n",
    "print(f\"\\n🚀 Next Steps:\")\n",
    "print(f\"  1. 📊 Open ADX Web UI and explore your data\")\n",
    "print(f\"  2. 📈 Use the KQL queries from section 8\")\n",
    "print(f\"  3. 📋 Create dashboards and reports\")\n",
    "print(f\"  4. 🔄 Re-run this notebook weekly for trends\")\n",
    "\n",
    "print(f\"✨ From zero to production in just 3 simple steps!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-openai-workshop (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
