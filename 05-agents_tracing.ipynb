{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1cca87b1",
      "metadata": {},
      "source": [
        "# Trace Your AI Agents Using Azure AI Foundry SDK (Preview)\n",
        "\n",
        "This notebook demonstrates how to instrument tracing in agents using Azure AI Foundry SDK with OpenTelemetry and Azure Monitor for enhanced observability and debugging.\n",
        "\n",
        "## Key Concepts\n",
        "\n",
        "- **Traces**: Capture the journey of a request or workflow through your application\n",
        "- **Spans**: Building blocks of traces, representing single operations within a trace\n",
        "- **Attributes**: Key-value pairs providing contextual metadata\n",
        "- **Semantic conventions**: Standardized names and formats for trace data\n",
        "- **Trace exporters**: Send trace data to backend systems for storage and analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db359feb",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Configure environment variables and import necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7e1f1cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Enable content recording (optional - may contain personal data)\n",
        "os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"  # False by default\n",
        "\n",
        "# Set service name for identification in Application Insights\n",
        "os.environ[\"OTEL_SERVICE_NAME\"] = \"azure-ai-agents-tracing-demo\"\n",
        "\n",
        "# Verify required environment variables\n",
        "required_vars = [\"PROJECT_ENDPOINT\", \"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
        "for var in required_vars:\n",
        "    if var not in os.environ:\n",
        "        print(f\"  Warning: {var} environment variable ❌ not set\")\n",
        "    else:\n",
        "        print(f\" {var} is configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53cf4a25",
      "metadata": {},
      "source": [
        "## Import Required Libraries\n",
        "\n",
        "Import all necessary libraries for Azure AI Foundry, OpenTelemetry, and tracing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c859d843",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Azure AI imports\n",
        "from azure.ai.projects import AIProjectClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.agents.telemetry import AIAgentsInstrumentor\n",
        "\n",
        "# OpenTelemetry imports\n",
        "from opentelemetry import trace\n",
        "from opentelemetry.sdk.trace import TracerProvider\n",
        "from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter\n",
        "from opentelemetry.trace import SpanKind\n",
        "\n",
        "# Azure Monitor imports\n",
        "from azure.monitor.opentelemetry import configure_azure_monitor\n",
        "\n",
        "# Core tracing settings\n",
        "from azure.core.settings import settings\n",
        "settings.tracing_implementation = \"opentelemetry\"\n",
        "\n",
        "print(\" ✅ All libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0af2205b",
      "metadata": {},
      "source": [
        "## Option 1: Local Console Tracing Setup\n",
        "\n",
        "Configure tracing to output to console for local development and debugging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "532d21c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_console_tracing():\n",
        "    \"\"\"Setup tracing to console for local development\"\"\"\n",
        "    # Setup tracing to console\n",
        "    span_exporter = ConsoleSpanExporter()\n",
        "    tracer_provider = TracerProvider()\n",
        "    tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter))\n",
        "    trace.set_tracer_provider(tracer_provider)\n",
        "    \n",
        "    print(\" Console tracing configured\")\n",
        "    return trace.get_tracer(__name__)\n",
        "\n",
        "# Uncomment the line below to enable console tracing\n",
        "# console_tracer = setup_console_tracing()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cad9bb56",
      "metadata": {},
      "source": [
        "## Option 2: Azure Monitor Tracing Setup\n",
        "\n",
        "Configure tracing to send data to Azure Monitor Application Insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f32f3bca",
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_azure_monitor_tracing(project_client):\n",
        "    \"\"\"Setup tracing to Azure Monitor Application Insights\"\"\"\n",
        "    try:\n",
        "        # Get connection string from the Application Insights resource\n",
        "        connection_string = project_client.telemetry.get_application_insights_connection_string()\n",
        "        \n",
        "        # Configure Azure Monitor\n",
        "        configure_azure_monitor(connection_string=connection_string)\n",
        "        \n",
        "        print(\" Azure Monitor tracing configured\")\n",
        "        print(f\" Connection string: {connection_string[:50]}...\")\n",
        "        \n",
        "        return trace.get_tracer(__name__)\n",
        "    except Exception as e:\n",
        "        print(f\" ❌ Failed to setup Azure Monitor tracing: {e}\")\n",
        "        print(\" Make sure Application Insights is connected to your AI Foundry project\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89af7a2c",
      "metadata": {},
      "source": [
        "## Initialize Azure AI Project Client\n",
        "\n",
        "Create the AI Project Client to connect to your Azure AI Foundry project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d3c2143",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Azure AI Project Client\n",
        "try:\n",
        "    project_client = AIProjectClient(\n",
        "        credential=DefaultAzureCredential(),\n",
        "        endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n",
        "    )\n",
        "    print(\" Azure AI Project Client initialized ✅ successfully\")\n",
        "    print(f\" Project endpoint: {os.environ['PROJECT_ENDPOINT']}\")\n",
        "except Exception as e:\n",
        "    print(f\" ❌ Failed to initialize project client: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bed809ae",
      "metadata": {},
      "source": [
        "## Setup Tracing Configuration\n",
        "\n",
        "Choose between console tracing (local) or Azure Monitor tracing (cloud)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c99348",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose tracing method\n",
        "USE_AZURE_MONITOR = True  # Set to False for console tracing\n",
        "\n",
        "if USE_AZURE_MONITOR:\n",
        "    tracer = setup_azure_monitor_tracing(project_client)\n",
        "    if tracer is None:\n",
        "        print(\" Falling back to console tracing\")\n",
        "        tracer = setup_console_tracing()\n",
        "else:\n",
        "    tracer = setup_console_tracing()\n",
        "\n",
        "# Enable AI Agents instrumentation\n",
        "AIAgentsInstrumentor().instrument()\n",
        "print(\" AI Agents instrumentation enabled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6973066a",
      "metadata": {},
      "source": [
        "## Basic Agent with Tracing Example\n",
        "\n",
        "Create and run an AI agent with tracing enabled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bb1df2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_and_run_agent_with_tracing():\n",
        "    \"\"\"Create and run an AI agent with comprehensive tracing\"\"\"\n",
        "    \n",
        "    with tracer.start_as_current_span(\"agent-creation-and-execution\") as main_span:\n",
        "        # Add attributes to the main span\n",
        "        main_span.set_attribute(\"operation.type\", \"agent_execution\")\n",
        "        main_span.set_attribute(\"model.deployment\", os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"])\n",
        "        \n",
        "        try:\n",
        "            # Create agent\n",
        "            with tracer.start_as_current_span(\"create-agent\") as agent_span:\n",
        "                agent_span.set_attribute(\"agent.name\", \"helpful-assistant\")\n",
        "                agent_span.set_attribute(\"agent.instructions\", \"You are a helpful assistant\")\n",
        "                \n",
        "                agent = project_client.agents.create_agent(\n",
        "                    model=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
        "                    name=\"helpful-assistant\",\n",
        "                    instructions=\"You are a helpful assistant that provides clear and concise answers.\"\n",
        "                )\n",
        "                \n",
        "                agent_span.set_attribute(\"agent.id\", agent.id)\n",
        "                print(f\" Agent created with ID: {agent.id}\")\n",
        "            \n",
        "            # Create thread\n",
        "            with tracer.start_as_current_span(\"create-thread\") as thread_span:\n",
        "                thread = project_client.agents.threads.create()\n",
        "                thread_span.set_attribute(\"thread.id\", thread.id)\n",
        "                print(f\" Thread created with ID: {thread.id}\")\n",
        "            \n",
        "            # Create message\n",
        "            with tracer.start_as_current_span(\"create-message\") as message_span:\n",
        "                user_message = \"Tell me a joke about programming\"\n",
        "                message_span.set_attribute(\"message.role\", \"user\")\n",
        "                message_span.set_attribute(\"message.content\", user_message)\n",
        "                \n",
        "                message = project_client.agents.messages.create(\n",
        "                    thread_id=thread.id,\n",
        "                    role=\"user\",\n",
        "                    content=user_message\n",
        "                )\n",
        "                \n",
        "                message_span.set_attribute(\"message.id\", message.id)\n",
        "                print(f\" Message created: {user_message}\")\n",
        "            \n",
        "            # Run agent\n",
        "            with tracer.start_as_current_span(\"run-agent\") as run_span:\n",
        "                run_span.set_attribute(\"run.agent_id\", agent.id)\n",
        "                run_span.set_attribute(\"run.thread_id\", thread.id)\n",
        "                \n",
        "                run = project_client.agents.runs.create_and_process(\n",
        "                    thread_id=thread.id,\n",
        "                    agent_id=agent.id\n",
        "                )\n",
        "                \n",
        "                run_span.set_attribute(\"run.id\", run.id)\n",
        "                run_span.set_attribute(\"run.status\", run.status)\n",
        "                print(f\" Run completed with status: {run.status}\")\n",
        "            \n",
        "            # Get response\n",
        "            with tracer.start_as_current_span(\"get-response\") as response_span:\n",
        "                messages = project_client.agents.messages.list(thread_id=thread.id)\n",
        "                \n",
        "                # Find the assistant's response\n",
        "                assistant_messages = [msg for msg in messages if msg.role == \"assistant\"]\n",
        "                if assistant_messages:\n",
        "                    latest_response = assistant_messages[0]\n",
        "                    response_content = latest_response.content[0].text.value\n",
        "                    \n",
        "                    response_span.set_attribute(\"response.content\", response_content)\n",
        "                    response_span.set_attribute(\"response.message_id\", latest_response.id)\n",
        "                    \n",
        "                    print(f\"\\n Assistant Response:\")\n",
        "                    print(f\"{response_content}\")\n",
        "                    \n",
        "                    return {\n",
        "                        \"agent_id\": agent.id,\n",
        "                        \"thread_id\": thread.id,\n",
        "                        \"run_id\": run.id,\n",
        "                        \"response\": response_content\n",
        "                    }\n",
        "                else:\n",
        "                    print(\" No assistant response found\")\n",
        "                    return None\n",
        "                    \n",
        "        except Exception as e:\n",
        "            main_span.set_attribute(\"error.message\", str(e))\n",
        "            main_span.set_attribute(\"error.type\", type(e).__name__)\n",
        "            print(f\" ❌ Error in agent execution: {e}\")\n",
        "            raise\n",
        "\n",
        "# Run the agent with tracing\n",
        "result = create_and_run_agent_with_tracing()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a21174f",
      "metadata": {},
      "source": [
        "## Custom Function Tracing\n",
        "\n",
        "Demonstrate how to trace custom functions with detailed attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c87a0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_user_input(user_input: str) -> dict:\n",
        "    \"\"\"Custom function with tracing to process user input\"\"\"\n",
        "    \n",
        "    with tracer.start_as_current_span(\"process-user-input\") as span:\n",
        "        span.set_attribute(\"input.length\", len(user_input))\n",
        "        span.set_attribute(\"input.type\", \"text\")\n",
        "        \n",
        "        # Simulate processing\n",
        "        import time\n",
        "        time.sleep(0.1)  # Simulate processing time\n",
        "        \n",
        "        # Extract some metadata\n",
        "        word_count = len(user_input.split())\n",
        "        has_question = \"?\" in user_input\n",
        "        has_exclamation = \"!\" in user_input\n",
        "        \n",
        "        # Add processing attributes\n",
        "        span.set_attribute(\"processing.word_count\", word_count)\n",
        "        span.set_attribute(\"processing.has_question\", has_question)\n",
        "        span.set_attribute(\"processing.has_exclamation\", has_exclamation)\n",
        "        \n",
        "        result = {\n",
        "            \"original_input\": user_input,\n",
        "            \"word_count\": word_count,\n",
        "            \"sentiment\": \"curious\" if has_question else \"excited\" if has_exclamation else \"neutral\",\n",
        "            \"processed_at\": time.time()\n",
        "        }\n",
        "        \n",
        "        span.set_attribute(\"output.sentiment\", result[\"sentiment\"])\n",
        "        \n",
        "        return result\n",
        "\n",
        "def analyze_conversation_flow(messages: list) -> dict:\n",
        "    \"\"\"Analyze conversation flow with nested tracing\"\"\"\n",
        "    \n",
        "    with tracer.start_as_current_span(\"analyze-conversation-flow\") as span:\n",
        "        span.set_attribute(\"conversation.message_count\", len(messages))\n",
        "        \n",
        "        analysis = {\n",
        "            \"total_messages\": len(messages),\n",
        "            \"user_messages\": 0,\n",
        "            \"assistant_messages\": 0,\n",
        "            \"average_length\": 0\n",
        "        }\n",
        "        \n",
        "        total_length = 0\n",
        "        \n",
        "        for i, message in enumerate(messages):\n",
        "            with tracer.start_as_current_span(f\"analyze-message-{i}\") as msg_span:\n",
        "                msg_span.set_attribute(\"message.role\", message.get(\"role\", \"unknown\"))\n",
        "                msg_span.set_attribute(\"message.length\", len(message.get(\"content\", \"\")))\n",
        "                \n",
        "                if message.get(\"role\") == \"user\":\n",
        "                    analysis[\"user_messages\"] += 1\n",
        "                elif message.get(\"role\") == \"assistant\":\n",
        "                    analysis[\"assistant_messages\"] += 1\n",
        "                \n",
        "                total_length += len(message.get(\"content\", \"\"))\n",
        "        \n",
        "        if len(messages) > 0:\n",
        "            analysis[\"average_length\"] = total_length / len(messages)\n",
        "        \n",
        "        # Add analysis results to span\n",
        "        for key, value in analysis.items():\n",
        "            span.set_attribute(f\"analysis.{key}\", value)\n",
        "        \n",
        "        return analysis\n",
        "\n",
        "# Test custom function tracing\n",
        "print(\" Testing custom function tracing...\")\n",
        "\n",
        "# Process user input\n",
        "user_input = \"How can I improve my Python coding skills?\"\n",
        "processed_input = process_user_input(user_input)\n",
        "print(f\"Processed input: {processed_input}\")\n",
        "\n",
        "# Analyze conversation (mock data)\n",
        "mock_conversation = [\n",
        "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"I'm doing well, thank you! How can I help you today?\"},\n",
        "    {\"role\": \"user\", \"content\": \"Can you explain machine learning?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Machine learning is a subset of artificial intelligence...\"}\n",
        "]\n",
        "\n",
        "conversation_analysis = analyze_conversation_flow(mock_conversation)\n",
        "print(f\"Conversation analysis: {conversation_analysis}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9be24f37",
      "metadata": {},
      "source": [
        "## Simulating User Feedback Tracing\n",
        "\n",
        "Demonstrate how to attach user feedback to traces for better observability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6250798c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_user_feedback(response_id: str, feedback_data: dict):\n",
        "    \"\"\"Simulate user feedback collection and tracing\"\"\"\n",
        "    \n",
        "    with tracer.start_as_current_span(\"user-feedback\") as feedback_span:\n",
        "        # Set feedback attributes according to OpenTelemetry semantic conventions\n",
        "        feedback_span.set_attribute(\"gen_ai.user.feedback.rating\", feedback_data.get(\"rating\", 0))\n",
        "        feedback_span.set_attribute(\"gen_ai.user.feedback.comment\", feedback_data.get(\"comment\", \"\"))\n",
        "        feedback_span.set_attribute(\"gen_ai.response.id\", response_id)\n",
        "        feedback_span.set_attribute(\"feedback.timestamp\", feedback_data.get(\"timestamp\", \"\"))\n",
        "        feedback_span.set_attribute(\"feedback.user_id\", feedback_data.get(\"user_id\", \"anonymous\"))\n",
        "        \n",
        "        # Add custom attributes\n",
        "        if \"helpful\" in feedback_data:\n",
        "            feedback_span.set_attribute(\"feedback.helpful\", feedback_data[\"helpful\"])\n",
        "        \n",
        "        if \"accuracy\" in feedback_data:\n",
        "            feedback_span.set_attribute(\"feedback.accuracy\", feedback_data[\"accuracy\"])\n",
        "        \n",
        "        print(f\" User feedback recorded for response: {response_id}\")\n",
        "        print(f\"   Rating: {feedback_data.get('rating')}/5\")\n",
        "        print(f\"   Comment: {feedback_data.get('comment')}\")\n",
        "        \n",
        "        return feedback_span.get_span_context().span_id\n",
        "\n",
        "# Simulate user feedback for the previous agent response\n",
        "if result:\n",
        "    import time\n",
        "    \n",
        "    feedback_examples = [\n",
        "        {\n",
        "            \"rating\": 5,\n",
        "            \"comment\": \"Great joke! Very funny and programming-related.\",\n",
        "            \"helpful\": True,\n",
        "            \"accuracy\": 5,\n",
        "            \"timestamp\": str(int(time.time())),\n",
        "            \"user_id\": \"user_123\"\n",
        "        },\n",
        "        {\n",
        "            \"rating\": 3,\n",
        "            \"comment\": \"The joke was okay, but could be funnier.\",\n",
        "            \"helpful\": True,\n",
        "            \"accuracy\": 4,\n",
        "            \"timestamp\": str(int(time.time())),\n",
        "            \"user_id\": \"user_456\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    for i, feedback in enumerate(feedback_examples):\n",
        "        print(f\"\\n Simulating feedback {i+1}:\")\n",
        "        feedback_id = simulate_user_feedback(result[\"run_id\"], feedback)\n",
        "else:\n",
        "    print(\"  No agent result available for feedback simulation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3743645",
      "metadata": {},
      "source": [
        "## Advanced Tracing: Multi-Agent Workflow\n",
        "\n",
        "Demonstrate tracing in a more complex scenario with multiple agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a9af793",
      "metadata": {},
      "outputs": [],
      "source": [
        "def multi_agent_workflow():\n",
        "    \"\"\"Demonstrate tracing with multiple agents in a workflow\"\"\"\n",
        "    \n",
        "    with tracer.start_as_current_span(\"multi-agent-workflow\") as workflow_span:\n",
        "        workflow_span.set_attribute(\"workflow.type\", \"multi_agent\")\n",
        "        workflow_span.set_attribute(\"workflow.agents_count\", 2)\n",
        "        \n",
        "        try:\n",
        "            # Create first agent (Research Assistant)\n",
        "            with tracer.start_as_current_span(\"create-research-agent\") as research_span:\n",
        "                research_agent = project_client.agents.create_agent(\n",
        "                    model=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
        "                    name=\"research-assistant\",\n",
        "                    instructions=\"You are a research assistant that provides factual information and sources.\"\n",
        "                )\n",
        "                research_span.set_attribute(\"agent.type\", \"research\")\n",
        "                research_span.set_attribute(\"agent.id\", research_agent.id)\n",
        "                print(f\" Research agent created: {research_agent.id}\")\n",
        "            \n",
        "            # Create second agent (Writing Assistant)\n",
        "            with tracer.start_as_current_span(\"create-writing-agent\") as writing_span:\n",
        "                writing_agent = project_client.agents.create_agent(\n",
        "                    model=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
        "                    name=\"writing-assistant\",\n",
        "                    instructions=\"You are a writing assistant that creates well-structured content based on research.\"\n",
        "                )\n",
        "                writing_span.set_attribute(\"agent.type\", \"writing\")\n",
        "                writing_span.set_attribute(\"agent.id\", writing_agent.id)\n",
        "                print(f\" Writing agent created: {writing_agent.id}\")\n",
        "            \n",
        "            # Research phase\n",
        "            with tracer.start_as_current_span(\"research-phase\") as research_phase_span:\n",
        "                research_thread = project_client.agents.threads.create()\n",
        "                research_query = \"What are the key benefits of using OpenTelemetry for observability?\"\n",
        "                \n",
        "                research_phase_span.set_attribute(\"phase.name\", \"research\")\n",
        "                research_phase_span.set_attribute(\"query\", research_query)\n",
        "                \n",
        "                # Send query to research agent\n",
        "                project_client.agents.messages.create(\n",
        "                    thread_id=research_thread.id,\n",
        "                    role=\"user\",\n",
        "                    content=research_query\n",
        "                )\n",
        "                \n",
        "                research_run = project_client.agents.runs.create_and_process(\n",
        "                    thread_id=research_thread.id,\n",
        "                    agent_id=research_agent.id\n",
        "                )\n",
        "                \n",
        "                research_phase_span.set_attribute(\"run.status\", research_run.status)\n",
        "                print(f\" Research phase completed: {research_run.status}\")\n",
        "                \n",
        "                # Get research results\n",
        "                research_messages = project_client.agents.messages.list(thread_id=research_thread.id)\n",
        "                research_result = None\n",
        "                for msg in research_messages:\n",
        "                    if msg.role == \"assistant\":\n",
        "                        research_result = msg.content[0].text.value\n",
        "                        break\n",
        "            \n",
        "            # Writing phase - only proceed if we have research results\n",
        "            final_result = None\n",
        "            if research_result:\n",
        "                with tracer.start_as_current_span(\"writing-phase\") as writing_phase_span:\n",
        "                    writing_thread = project_client.agents.threads.create()\n",
        "                    # Truncate research result to avoid overwhelming the writing agent\n",
        "                    truncated_research = research_result[:1000] + \"...\" if len(research_result) > 1000 else research_result\n",
        "                    writing_prompt = f\"Based on this research: {truncated_research}\\n\\nPlease write a concise summary in bullet points.\"\n",
        "                    \n",
        "                    writing_phase_span.set_attribute(\"phase.name\", \"writing\")\n",
        "                    writing_phase_span.set_attribute(\"input.source\", \"research_agent\")\n",
        "                    writing_phase_span.set_attribute(\"input.length\", len(truncated_research))\n",
        "                    \n",
        "                    # Send research to writing agent\n",
        "                    project_client.agents.messages.create(\n",
        "                        thread_id=writing_thread.id,\n",
        "                        role=\"user\",\n",
        "                        content=writing_prompt\n",
        "                    )\n",
        "                    \n",
        "                    writing_run = project_client.agents.runs.create_and_process(\n",
        "                        thread_id=writing_thread.id,\n",
        "                        agent_id=writing_agent.id\n",
        "                    )\n",
        "                    \n",
        "                    writing_phase_span.set_attribute(\"run.status\", writing_run.status)\n",
        "                    print(f\" Writing phase completed: {writing_run.status}\")\n",
        "                    \n",
        "                    # Get final result\n",
        "                    writing_messages = project_client.agents.messages.list(thread_id=writing_thread.id)\n",
        "                    for msg in writing_messages:\n",
        "                        if msg.role == \"assistant\":\n",
        "                            final_result = msg.content[0].text.value\n",
        "                            break\n",
        "            else:\n",
        "                print(\" Skipping writing phase - no research result available\")\n",
        "            \n",
        "            workflow_span.set_attribute(\"workflow.status\", \"completed\")\n",
        "            \n",
        "            print(\"\\n Multi-Agent Workflow Results:\")\n",
        "            print(\"=\" * 50)\n",
        "            print(f\"Research Query: {research_query}\")\n",
        "            \n",
        "            # Add null checks before slicing\n",
        "            if research_result:\n",
        "                print(f\"\\n Research Result:\\n{research_result[:200]}...\")\n",
        "            else:\n",
        "                print(\"\\n Research Result: ❌ No result available (agent may have ❌ failed)\")\n",
        "                \n",
        "            if final_result:\n",
        "                print(f\"\\n  Final Summary:\\n{final_result}\")\n",
        "            else:\n",
        "                print(\"\\n  Final Summary: ❌ No result available (writing agent skipped or ❌ failed)\")\n",
        "            \n",
        "            return {\n",
        "                \"research_agent_id\": research_agent.id,\n",
        "                \"writing_agent_id\": writing_agent.id,\n",
        "                \"research_result\": research_result,\n",
        "                \"final_result\": final_result\n",
        "            }\n",
        "            \n",
        "        except Exception as e:\n",
        "            workflow_span.set_attribute(\"workflow.status\", \"failed\")\n",
        "            workflow_span.set_attribute(\"error.message\", str(e))\n",
        "            print(f\" Multi-agent workflow ❌ failed: {e}\")\n",
        "            raise\n",
        "\n",
        "# Run multi-agent workflow\n",
        "print(\" Starting multi-agent workflow...\")\n",
        "workflow_result = multi_agent_workflow()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b0c18c6",
      "metadata": {},
      "source": [
        "## Tracing Best Practices and Tips\n",
        "\n",
        "Demonstrate best practices for effective tracing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e78fb8bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def demonstrate_tracing_best_practices():\n",
        "    \"\"\"Demonstrate tracing best practices\"\"\"\n",
        "    \n",
        "    print(\" Tracing Best Practices Demo\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # 1. Use meaningful span names\n",
        "    with tracer.start_as_current_span(\"user-authentication-flow\") as auth_span:\n",
        "        auth_span.set_attribute(\"user.action\", \"login_attempt\")\n",
        "        auth_span.set_attribute(\"auth.method\", \"azure_ad\")\n",
        "        \n",
        "        # 2. Add contextual attributes\n",
        "        import time\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Simulate authentication\n",
        "        time.sleep(0.1)\n",
        "        \n",
        "        end_time = time.time()\n",
        "        auth_span.set_attribute(\"auth.duration_ms\", (end_time - start_time) * 1000)\n",
        "        auth_span.set_attribute(\"auth.success\", True)\n",
        "        \n",
        "        print(\" Authentication traced with detailed attributes\")\n",
        "    \n",
        "    # 3. Use nested spans for complex operations\n",
        "    with tracer.start_as_current_span(\"data-processing-pipeline\") as pipeline_span:\n",
        "        pipeline_span.set_attribute(\"pipeline.type\", \"text_analysis\")\n",
        "        \n",
        "        # Step 1: Data validation\n",
        "        with tracer.start_as_current_span(\"validate-input\") as validation_span:\n",
        "            validation_span.set_attribute(\"validation.rules_count\", 5)\n",
        "            validation_span.set_attribute(\"validation.passed\", True)\n",
        "            print(\"   Input validation traced\")\n",
        "        \n",
        "        # Step 2: Data transformation\n",
        "        with tracer.start_as_current_span(\"transform-data\") as transform_span:\n",
        "            transform_span.set_attribute(\"transform.type\", \"text_normalization\")\n",
        "            transform_span.set_attribute(\"transform.input_size\", 1024)\n",
        "            transform_span.set_attribute(\"transform.output_size\", 987)\n",
        "            print(\"   Data transformation traced\")\n",
        "        \n",
        "        # Step 3: Analysis\n",
        "        with tracer.start_as_current_span(\"analyze-content\") as analysis_span:\n",
        "            analysis_span.set_attribute(\"analysis.model\", \"sentiment_analyzer_v2\")\n",
        "            analysis_span.set_attribute(\"analysis.confidence\", 0.95)\n",
        "            analysis_span.set_attribute(\"analysis.result\", \"positive\")\n",
        "            print(\"   Content analysis traced\")\n",
        "        \n",
        "        pipeline_span.set_attribute(\"pipeline.steps_completed\", 3)\n",
        "        pipeline_span.set_attribute(\"pipeline.success\", True)\n",
        "        \n",
        "        print(\" ✅ Complete pipeline traced with nested spans\")\n",
        "    \n",
        "    # 4. ❌ Error handling with tracing\n",
        "    with tracer.start_as_current_span(\"error-handling-demo\") as error_span:\n",
        "        try:\n",
        "            # Simulate an operation that might fail\n",
        "            error_span.set_attribute(\"operation.type\", \"risky_operation\")\n",
        "            \n",
        "            # This will not actually fail for demo purposes\n",
        "            success = True\n",
        "            \n",
        "            if success:\n",
        "                error_span.set_attribute(\"operation.result\", \"success\")\n",
        "                print(\" ❌ Error handling pattern demonstrated (success case)\")\n",
        "            else:\n",
        "                raise ValueError(\"Simulated error\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            error_span.set_attribute(\"error.type\", type(e).__name__)\n",
        "            error_span.set_attribute(\"error.message\", str(e))\n",
        "            error_span.set_attribute(\"operation.result\", \"failure\")\n",
        "            print(f\" ❌ Error traced: {e}\")\n",
        "    \n",
        "    print(\"\\n Key Takeaways:\")\n",
        "    print(\"   • Use descriptive span names\")\n",
        "    print(\"   • Add relevant attributes for context\")\n",
        "    print(\"   • Use nested spans for complex workflows\")\n",
        "    print(\"   • Always trace errors with details\")\n",
        "    print(\"   • Include timing and performance metrics\")\n",
        "    print(\"   • Use semantic conventions when possible\")\n",
        "\n",
        "demonstrate_tracing_best_practices()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28d3ac0c",
      "metadata": {},
      "source": [
        "## Viewing Traces\n",
        "\n",
        "Information about where and how to view your traces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7696616e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_tracing_info():\n",
        "    \"\"\"Display information about viewing traces\"\"\"\n",
        "    \n",
        "    print(\" Viewing Your Traces\")\n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    if USE_AZURE_MONITOR:\n",
        "        print(\" Azure AI Foundry Portal:\")\n",
        "        print(f\"   • Navigate to your project: {os.environ.get('PROJECT_ENDPOINT', 'YOUR_PROJECT_ENDPOINT')}\")\n",
        "        print(\"   • Go to 'Tracing' in the left navigation\")\n",
        "        print(\"   • Filter and view your traces\")\n",
        "        print(\"   • Click on traces to see detailed spans\")\n",
        "        \n",
        "        print(\"\\n Azure Monitor Application Insights:\")\n",
        "        print(\"   • Access via 'Manage data source' in AI Foundry\")\n",
        "        print(\"   • Use End-to-end transaction details\")\n",
        "        print(\"   • Query with KQL for advanced analysis\")\n",
        "        print(\"   • Example query: | where cloud_RoleName == 'azure-ai-agents-tracing-demo'\")\n",
        "        \n",
        "    else:\n",
        "        print(\"  Console Output:\")\n",
        "        print(\"   • Traces are displayed in the console above\")\n",
        "        print(\"   • Each span shows start/end times and attributes\")\n",
        "        \n",
        "    print(\"\\n What to Look For:\")\n",
        "    print(\"   • Span durations and performance bottlenecks\")\n",
        "    print(\"   • ❌ Error rates and failure patterns\")\n",
        "    print(\"   • Agent interactions and conversation flows\")\n",
        "    print(\"   • Custom attributes and business metrics\")\n",
        "    print(\"   • User feedback correlation\")\n",
        "    \n",
        "    print(\"\\n Monitoring Tips:\")\n",
        "    print(\"   • Set up alerts for high ❌ error rates\")\n",
        "    print(\"   • Monitor response times and latency\")\n",
        "    print(\"   • Track user satisfaction through feedback\")\n",
        "    print(\"   • Use service name to filter multi-app environments\")\n",
        "\n",
        "display_tracing_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7636927f",
      "metadata": {},
      "source": [
        "## Cleanup and Summary\n",
        "\n",
        "Clean up resources and provide a summary of what was covered."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c59f0a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def display_summary():\n",
        "    \"\"\"Display a summary of what was covered in this notebook\"\"\"\n",
        "    \n",
        "    print(\"\\n Notebook Summary\")\n",
        "    print(\"=\" * 20)\n",
        "    \n",
        "    print(\" What we covered:\")\n",
        "    print(\"   • Azure AI Foundry SDK setup and configuration\")\n",
        "    print(\"   • OpenTelemetry tracing configuration\")\n",
        "    print(\"   • Console vs Azure Monitor tracing\")\n",
        "    print(\"   • Basic agent creation and execution with tracing\")\n",
        "    print(\"   • Custom function tracing with attributes\")\n",
        "    print(\"   • User feedback collection and correlation\")\n",
        "    print(\"   • Multi-agent workflow tracing\")\n",
        "    print(\"   • Tracing best practices and patterns\")\n",
        "    print(\"   • ❌ Error handling in traced operations\")\n",
        "    \n",
        "    print(\"\\n Key Benefits of Tracing:\")\n",
        "    print(\"   • Enhanced debugging and troubleshooting\")\n",
        "    print(\"   • Performance monitoring and optimization\")\n",
        "    print(\"   • Better understanding of agent behavior\")\n",
        "    print(\"   • User experience insights through feedback\")\n",
        "    print(\"   • Compliance and audit capabilities\")\n",
        "    \n",
        "    print(\"\\n Next Steps:\")\n",
        "    print(\"   • Implement tracing in your production agents\")\n",
        "    print(\"   • Set up Application Insights monitoring\")\n",
        "    print(\"   • Create custom dashboards and alerts\")\n",
        "    print(\"   • Establish tracing standards for your team\")\n",
        "    print(\"   • Explore advanced OpenTelemetry features\")\n",
        "    \n",
        "    print(\"\\n Additional Resources:\")\n",
        "    print(\"   • Azure AI Foundry Documentation\")\n",
        "    print(\"   • OpenTelemetry Python SDK Documentation\")\n",
        "    print(\"   • Azure Monitor OpenTelemetry Guide\")\n",
        "    print(\"   • Semantic Conventions for AI/ML\")\n",
        "\n",
        "# Execute cleanup and summary\n",
        "display_summary()\n",
        "\n",
        "print(\"\\n Tracing agents tutorial completed ✅ successfully!\")\n",
        "print(\"Happy tracing! ‍\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "azure-openai-workshop (3.12.8)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}