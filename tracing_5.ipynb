{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2233701",
   "metadata": {},
   "source": [
    "# Tracing AI Applications Using OpenAI SDK\n",
    "\n",
    "Welcome to this comprehensive guide on implementing tracing for AI applications using OpenAI SDK with OpenTelemetry in Azure AI Foundry. This notebook demonstrates how to trace AI applications to gain deep visibility into execution steps, diagnose issues, and enhance performance.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Prerequisites Setup** - Configure Azure AI Foundry project and Application Insights\n",
    "2. **Enable Project Tracing** - Connect Azure Application Insights to your AI Foundry resource\n",
    "3. **OpenAI SDK Instrumentation** - Automatic tracing of OpenAI API calls\n",
    "4. **Azure AI Projects Integration** - Using project clients for streamlined authentication\n",
    "5. **Custom Spans and Attributes** - Adding business logic tracing\n",
    "6. **Console Tracing** - Local debugging with console output\n",
    "7. **Advanced Tracing Patterns** - Complex workflows and error handling\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- An Azure AI Foundry project created\n",
    "- An AI application that uses OpenAI SDK\n",
    "- Environment variables configured in `.env` file\n",
    "- Azure Application Insights resource (will be configured)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand how to:\n",
    "- Configure OpenTelemetry for Azure AI applications\n",
    "- Trace OpenAI API calls automatically\n",
    "- Create custom spans for business logic\n",
    "- Send traces to Azure Application Insights\n",
    "- Debug applications using trace data\n",
    "- Implement production-ready monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e57cf",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Prerequisites Check\n",
    "\n",
    "Let's start by setting up our environment and checking that all prerequisites are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c749856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”§ Azure AI Foundry Tracing Prerequisites Check:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check required environment variables\n",
    "required_vars = {\n",
    "    'AZURE_AI_PROJECT_ENDPOINT': 'Azure AI Foundry project endpoint',\n",
    "    'AZURE_OPENAI_DEPLOYMENT_NAME': 'OpenAI model deployment name'\n",
    "}\n",
    "\n",
    "optional_vars = {\n",
    "    'APPLICATION_INSIGHTS_CONNECTION_STRING': 'Azure Application Insights connection string'\n",
    "}\n",
    "\n",
    "print(\"ğŸ“‹ Required Environment Variables:\")\n",
    "all_required_set = True\n",
    "for var, description in required_vars.items():\n",
    "    value = os.getenv(var)\n",
    "    if value:\n",
    "        # Show only partial values for security\n",
    "        display_value = f\"{value[:50]}...\" if len(value) > 50 else value\n",
    "        print(f\"  âœ… {var}: {display_value}\")\n",
    "    else:\n",
    "        print(f\"  âŒ {var}: Not set\")\n",
    "        print(f\"     ğŸ“ {description}\")\n",
    "        all_required_set = False\n",
    "\n",
    "print(\"\\nğŸ“‹ Optional Environment Variables:\")\n",
    "for var, description in optional_vars.items():\n",
    "    value = os.getenv(var)\n",
    "    if value:\n",
    "        print(f\"  âœ… {var}: Connection string configured\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸  {var}: Not set (will be configured from project)\")\n",
    "        print(f\"     ğŸ“ {description}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "if all_required_set:\n",
    "    print(\"ğŸš€ Prerequisites check passed! Ready to proceed.\")\n",
    "else:\n",
    "    print(\"âš ï¸  Please configure missing environment variables before proceeding.\")\n",
    "    print(\"ğŸ’¡ Check your .env file or Azure AI Foundry project settings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49eeaee",
   "metadata": {},
   "source": [
    "## 2. Install Required Packages\n",
    "\n",
    "Install the necessary packages for tracing with OpenAI SDK and Azure Monitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdb714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if required packages are available\n",
    "try:\n",
    "    # Azure AI Projects SDK\n",
    "    from azure.ai.projects import AIProjectClient\n",
    "    from azure.identity import DefaultAzureCredential\n",
    "    \n",
    "    # Azure Monitor OpenTelemetry\n",
    "    from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "    \n",
    "    # OpenTelemetry instrumentation\n",
    "    from opentelemetry.instrumentation.openai_v2 import OpenAIInstrumentor\n",
    "    from opentelemetry import trace\n",
    "    from opentelemetry.sdk.trace import TracerProvider\n",
    "    from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter\n",
    "    \n",
    "    print(\"âœ… All required packages are available!\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"ğŸ“¦ Packages loaded:\")\n",
    "    print(\"  â€¢ azure-ai-projects\")\n",
    "    print(\"  â€¢ azure-monitor-opentelemetry\") \n",
    "    print(\"  â€¢ opentelemetry-instrumentation-openai-v2\")\n",
    "    print(\"  â€¢ opentelemetry-sdk\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Missing package: {e}\")\n",
    "    print(\"\\nğŸ’¡ Install missing packages with:\")\n",
    "    print(\"pip install azure-ai-projects azure-monitor-opentelemetry opentelemetry-instrumentation-openai-v2\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000274af",
   "metadata": {},
   "source": [
    "## 3. Configure Azure AI Foundry Project Client\n",
    "\n",
    "Connect to your Azure AI Foundry project using the Azure AI Projects client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd52388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_ai_project_client():\n",
    "    \"\"\"\n",
    "    Set up the Azure AI Project client with authentication.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”— Setting up Azure AI Project Client...\")\n",
    "    \n",
    "    # Get project endpoint from environment variables\n",
    "    project_endpoint = os.getenv('AZURE_AI_PROJECT_ENDPOINT')\n",
    "    \n",
    "    if not project_endpoint:\n",
    "        raise ValueError(\"AZURE_AI_PROJECT_ENDPOINT not found in environment variables\")\n",
    "    \n",
    "    # Create project client with default Azure credentials\n",
    "    try:\n",
    "        project_client = AIProjectClient(\n",
    "            credential=DefaultAzureCredential(),\n",
    "            endpoint=project_endpoint\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… Azure AI Project client created successfully!\")\n",
    "        print(f\"ğŸ“ Project Endpoint: {project_endpoint}\")\n",
    "        \n",
    "        return project_client\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to create project client: {e}\")\n",
    "        print(\"ğŸ’¡ Troubleshooting tips:\")\n",
    "        print(\"  â€¢ Ensure you're logged in with 'az login'\")\n",
    "        print(\"  â€¢ Verify your Azure permissions for the AI project\")\n",
    "        print(\"  â€¢ Check the project endpoint URL format\")\n",
    "        raise\n",
    "\n",
    "# Initialize the project client\n",
    "project_client = setup_ai_project_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe69d1",
   "metadata": {},
   "source": [
    "## 4. Get Application Insights Connection String\n",
    "\n",
    "Retrieve the Application Insights connection string from your Azure AI Foundry project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_application_insights_connection():\n",
    "    \"\"\"\n",
    "    Get the Application Insights connection string from the AI project.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“Š Retrieving Application Insights Connection...\")\n",
    "    \n",
    "    try:\n",
    "        # Get the connection string from the project\n",
    "        connection_string = project_client.telemetry.get_application_insights_connection_string()\n",
    "        \n",
    "        if connection_string:\n",
    "            print(\"âœ… Application Insights connection string retrieved!\")\n",
    "            print(f\"ğŸ”— Connection configured: {connection_string[:30]}...\")\n",
    "            return connection_string\n",
    "        else:\n",
    "            print(\"âŒ No Application Insights connection string found\")\n",
    "            print(\"ğŸ’¡ Enable Application Insights in your AI Foundry project:\")\n",
    "            print(\"  1. Go to Azure AI Foundry portal\")\n",
    "            print(\"  2. Navigate to your project\")\n",
    "            print(\"  3. Select 'Tracing' in the sidebar\")\n",
    "            print(\"  4. Configure Application Insights resource\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to get Application Insights connection: {e}\")\n",
    "        print(\"ğŸ’¡ This might be expected if Application Insights is not configured\")\n",
    "        return None\n",
    "\n",
    "# Get the connection string\n",
    "connection_string = get_application_insights_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aab5ae",
   "metadata": {},
   "source": [
    "## 5. Instrument OpenAI SDK\n",
    "\n",
    "Set up OpenTelemetry instrumentation for the OpenAI SDK to automatically trace API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2906cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instrument_openai_sdk():\n",
    "    \"\"\"\n",
    "    Instrument the OpenAI SDK for automatic tracing.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”§ Instrumenting OpenAI SDK...\")\n",
    "    \n",
    "    # Instrument the OpenAI SDK\n",
    "    OpenAIInstrumentor().instrument()\n",
    "    \n",
    "    # Configure content capture (be careful with sensitive data)\n",
    "    content_capture = os.getenv('OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT', 'false')\n",
    "    if content_capture.lower() == 'true':\n",
    "        print(\"âš ï¸  Content capture ENABLED - prompts and responses will be traced\")\n",
    "        print(\"   (Only enable this in development environments)\")\n",
    "    else:\n",
    "        print(\"ğŸ”’ Content capture DISABLED - only metadata will be traced\")\n",
    "        print(\"   (Recommended for production environments)\")\n",
    "    \n",
    "    print(\"âœ… OpenAI SDK instrumentation complete!\")\n",
    "    print(\"ğŸ“ˆ All OpenAI API calls will now be automatically traced\")\n",
    "\n",
    "# Set up OpenAI instrumentation\n",
    "instrument_openai_sdk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c4951b",
   "metadata": {},
   "source": [
    "## 6. Configure Azure Monitor (Application Insights)\n",
    "\n",
    "Configure OpenTelemetry to send traces to Azure Application Insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e3cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_azure_monitor_tracing(connection_string):\n",
    "    \"\"\"\n",
    "    Configure Azure Monitor to send traces to Application Insights.\n",
    "    \"\"\"\n",
    "    if not connection_string:\n",
    "        print(\"âš ï¸  Skipping Azure Monitor configuration - no connection string available\")\n",
    "        print(\"   Traces will only be visible in console output\")\n",
    "        return False\n",
    "    \n",
    "    print(\"â˜ï¸ Configuring Azure Monitor for tracing...\")\n",
    "    \n",
    "    try:\n",
    "        # Configure Azure Monitor with the connection string\n",
    "        configure_azure_monitor(connection_string=connection_string)\n",
    "        \n",
    "        print(\"âœ… Azure Monitor configured successfully!\")\n",
    "        print(\"ğŸ“Š Traces will be sent to Application Insights\")\n",
    "        print(\"ğŸ” View traces at: Azure AI Foundry â†’ Your Project â†’ Tracing\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to configure Azure Monitor: {e}\")\n",
    "        print(\"ğŸ’¡ Continuing with console tracing only\")\n",
    "        return False\n",
    "\n",
    "# Configure Azure Monitor if connection string is available\n",
    "azure_monitor_enabled = configure_azure_monitor_tracing(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e08ecb",
   "metadata": {},
   "source": [
    "## 7. Set Up Console Tracing\n",
    "\n",
    "Configure console tracing for local debugging and development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3fd09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_console_tracing():\n",
    "    \"\"\"\n",
    "    Set up console tracing for local debugging.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ–¥ï¸ Setting up console tracing...\")\n",
    "    \n",
    "    # Set up trace provider if not already configured by Azure Monitor\n",
    "    if not azure_monitor_enabled:\n",
    "        trace_provider = TracerProvider()\n",
    "        trace.set_tracer_provider(trace_provider)\n",
    "        \n",
    "        # Add console exporter for local viewing\n",
    "        console_exporter = ConsoleSpanExporter()\n",
    "        span_processor = SimpleSpanProcessor(console_exporter)\n",
    "        trace.get_tracer_provider().add_span_processor(span_processor)\n",
    "        \n",
    "        print(\"âœ… Console tracing configured\")\n",
    "        print(\"ğŸ“º Traces will be displayed in console output\")\n",
    "    else:\n",
    "        print(\"â„¹ï¸  Console tracing not needed - Azure Monitor already configured\")\n",
    "    \n",
    "    # Get tracer for creating custom spans\n",
    "    tracer = trace.get_tracer(__name__)\n",
    "    print(\"ğŸ” Tracer ready for custom spans\")\n",
    "    \n",
    "    return tracer\n",
    "\n",
    "# Set up console tracing\n",
    "tracer = setup_console_tracing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b7866d",
   "metadata": {},
   "source": [
    "## 8. Create OpenAI Client\n",
    "\n",
    "Get the OpenAI client from the Azure AI project for making traced API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c388ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_openai_client():\n",
    "    \"\"\"\n",
    "    Set up the OpenAI client through the Azure AI project.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ¤– Setting up OpenAI client...\")\n",
    "    \n",
    "    try:\n",
    "        # Get the OpenAI client from the project\n",
    "        client = project_client.get_openai_client()\n",
    "        \n",
    "        # Get the deployment name\n",
    "        deployment_name = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')\n",
    "        \n",
    "        if not deployment_name:\n",
    "            raise ValueError(\"AZURE_OPENAI_DEPLOYMENT_NAME not found in environment variables\")\n",
    "        \n",
    "        print(\"âœ… OpenAI client configured successfully!\")\n",
    "        print(f\"ğŸ¯ Using deployment: {deployment_name}\")\n",
    "        print(\"ğŸ“¡ Client is instrumented and ready for traced API calls\")\n",
    "        \n",
    "        return client, deployment_name\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to setup OpenAI client: {e}\")\n",
    "        print(\"ğŸ’¡ Troubleshooting:\")\n",
    "        print(\"  â€¢ Check your Azure AI project has OpenAI connections\")\n",
    "        print(\"  â€¢ Verify the deployment name in your environment variables\")\n",
    "        print(\"  â€¢ Ensure proper Azure permissions\")\n",
    "        raise\n",
    "\n",
    "# Setup the OpenAI client\n",
    "client, deployment_name = setup_openai_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9205b174",
   "metadata": {},
   "source": [
    "## 9. Basic Traced API Call\n",
    "\n",
    "Make a simple API call to test the tracing setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754102b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_basic_traced_call():\n",
    "    \"\"\"\n",
    "    Make a basic OpenAI API call with tracing enabled.\n",
    "    \"\"\"\n",
    "    print(\"ğŸš€ Making basic traced API call...\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # The OpenAI call will be automatically traced by the instrumentation\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"Write a short poem about OpenTelemetry.\"}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… API call successful!\")\n",
    "        print(f\"ğŸ“ Response: {response.choices[0].message.content}\")\n",
    "        print(f\"ğŸ“Š Token usage: {response.usage.total_tokens} total\")\n",
    "        print(f\"   (Prompt: {response.usage.prompt_tokens}, Completion: {response.usage.completion_tokens})\")\n",
    "        \n",
    "        if azure_monitor_enabled:\n",
    "            print(\"\\nğŸ” Trace should now be visible in:\")\n",
    "            print(\"   â€¢ Azure AI Foundry â†’ Your Project â†’ Tracing\")\n",
    "            print(\"   â€¢ Application Insights â†’ Transaction Search\")\n",
    "        else:\n",
    "            print(\"\\nğŸ“º Check console output above for trace data\")\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ API call failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Test basic tracing\n",
    "response = make_basic_traced_call()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade5218",
   "metadata": {},
   "source": [
    "## 10. Custom Spans and Business Logic Tracing\n",
    "\n",
    "Demonstrate how to add custom spans to trace business logic around AI operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931f502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_claims_with_context(claims, contexts):\n",
    "    \"\"\"\n",
    "    Example function from the documentation that assesses claims with context.\n",
    "    This demonstrates custom spans around business logic.\n",
    "    \"\"\"\n",
    "    def build_prompt_with_context(claim: str, context: str) -> list:\n",
    "        return [\n",
    "            {\n",
    "                'role': 'system', \n",
    "                'content': \"I will ask you to assess whether a particular scientific claim is supported by evidence provided. Output only the text 'True' if the claim is true, 'False' if the claim is false, or 'NEE' if there's not enough evidence.\"\n",
    "            },\n",
    "            {\n",
    "                'role': 'user', \n",
    "                'content': f\"\"\"\n",
    "                    The evidence is the following: {context}\n",
    "\n",
    "                    Assess the following claim on the basis of the evidence. Output only the text 'True' if the claim is true, 'False' if the claim is false, or 'NEE' if there's not enough evidence. Do not output any other text.\n",
    "\n",
    "                    Claim:\n",
    "                    {claim}\n",
    "\n",
    "                    Assessment:\n",
    "                \"\"\"\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    # Create a custom span for the entire operation\n",
    "    with tracer.start_as_current_span(\"assess_claims_with_context\") as operation_span:\n",
    "        responses = []\n",
    "        current_span = trace.get_current_span()\n",
    "        \n",
    "        # Add operation metadata\n",
    "        current_span.set_attribute(\"operation.claims_count\", len(claims))\n",
    "        current_span.set_attribute(\"operation.type\", \"claim_assessment\")\n",
    "        \n",
    "        print(f\"ğŸ” Assessing {len(claims)} claims with custom tracing...\")\n",
    "        \n",
    "        for i, (claim, context) in enumerate(zip(claims, contexts)):\n",
    "            # Create a span for each individual claim assessment\n",
    "            with tracer.start_as_current_span(f\"assess_claim_{i+1}\") as claim_span:\n",
    "                claim_span.set_attribute(\"claim.index\", i + 1)\n",
    "                claim_span.set_attribute(\"claim.length\", len(claim))\n",
    "                claim_span.set_attribute(\"context.length\", len(context))\n",
    "                \n",
    "                try:\n",
    "                    # Make the API call (automatically traced)\n",
    "                    response = client.chat.completions.create(\n",
    "                        model=deployment_name,\n",
    "                        messages=build_prompt_with_context(claim=claim, context=context),\n",
    "                        max_tokens=10,\n",
    "                        temperature=0.1\n",
    "                    )\n",
    "                    \n",
    "                    assessment = response.choices[0].message.content.strip('., ')\n",
    "                    responses.append(assessment)\n",
    "                    \n",
    "                    # Add result to span\n",
    "                    claim_span.set_attribute(\"assessment.result\", assessment)\n",
    "                    claim_span.set_attribute(\"tokens.used\", response.usage.total_tokens)\n",
    "                    claim_span.add_event(f\"Claim {i+1} assessed successfully\")\n",
    "                    \n",
    "                    print(f\"  Claim {i+1}: {assessment}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    claim_span.record_exception(e)\n",
    "                    claim_span.set_attribute(\"assessment.error\", True)\n",
    "                    print(f\"  âŒ Claim {i+1} failed: {e}\")\n",
    "                    responses.append(\"ERROR\")\n",
    "        \n",
    "        operation_span.add_event(\"All claims processed\")\n",
    "        operation_span.set_attribute(\"operation.success_rate\", \n",
    "                                   len([r for r in responses if r != \"ERROR\"]) / len(responses))\n",
    "        \n",
    "        return responses\n",
    "\n",
    "# Example usage with custom spans\n",
    "def demo_custom_spans():\n",
    "    \"\"\"\n",
    "    Demonstrate custom spans with a claims assessment example.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ§ª Testing Custom Spans with Claims Assessment:\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Sample claims and contexts\n",
    "    claims = [\n",
    "        \"The sky is blue during the day\",\n",
    "        \"Water freezes at 100 degrees Celsius\",\n",
    "        \"Artificial intelligence can process natural language\"\n",
    "    ]\n",
    "    \n",
    "    contexts = [\n",
    "        \"Scientific observations show that the sky appears blue due to Rayleigh scattering of sunlight by molecules in Earth's atmosphere.\",\n",
    "        \"Water freezes at 0 degrees Celsius (32 degrees Fahrenheit) at standard atmospheric pressure.\",\n",
    "        \"Modern AI systems like GPT models demonstrate advanced natural language processing capabilities through transformer architectures.\"\n",
    "    ]\n",
    "    \n",
    "    # Run the assessment with custom tracing\n",
    "    results = assess_claims_with_context(claims, contexts)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Assessment Results:\")\n",
    "    for i, (claim, result) in enumerate(zip(claims, results)):\n",
    "        print(f\"  {i+1}. {claim[:50]}... â†’ {result}\")\n",
    "    \n",
    "    print(f\"\\nğŸ” Custom spans created:\")\n",
    "    print(\"  â€¢ 'assess_claims_with_context' - Main operation span\")\n",
    "    print(\"  â€¢ 'assess_claim_N' - Individual claim assessment spans\")\n",
    "    print(\"  â€¢ Automatic OpenAI API spans within each claim span\")\n",
    "\n",
    "# Run the demo\n",
    "demo_custom_spans()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20569ca5",
   "metadata": {},
   "source": [
    "## 11. Advanced Tracing with Attributes and Events\n",
    "\n",
    "Demonstrate advanced tracing features including custom attributes and events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde162a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_tracing_demo():\n",
    "    \"\"\"\n",
    "    Demonstrate advanced tracing features with attributes and events.\n",
    "    \"\"\"\n",
    "    print(\"ğŸš€ Advanced Tracing Features Demo:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    with tracer.start_as_current_span(\"advanced_ai_workflow\") as workflow_span:\n",
    "        # Set workflow-level attributes\n",
    "        workflow_span.set_attribute(\"workflow.version\", \"1.0\")\n",
    "        workflow_span.set_attribute(\"workflow.type\", \"content_generation\")\n",
    "        workflow_span.set_attribute(\"user.session_id\", \"demo_session_123\")\n",
    "        \n",
    "        # Add an event to mark workflow start\n",
    "        workflow_span.add_event(\"Workflow started\", {\n",
    "            \"timestamp\": time.time(),\n",
    "            \"environment\": \"development\"\n",
    "        })\n",
    "        \n",
    "        # Step 1: Input processing\n",
    "        with tracer.start_as_current_span(\"process_input\") as input_span:\n",
    "            input_text = \"Explain quantum computing in simple terms\"\n",
    "            \n",
    "            input_span.set_attribute(\"input.text_length\", len(input_text))\n",
    "            input_span.set_attribute(\"input.language\", \"english\")\n",
    "            input_span.set_attribute(\"processing.step\", 1)\n",
    "            \n",
    "            # Simulate processing time\n",
    "            time.sleep(0.1)\n",
    "            input_span.add_event(\"Input processing complete\")\n",
    "        \n",
    "        # Step 2: AI generation with multiple attempts\n",
    "        for attempt in range(2):\n",
    "            with tracer.start_as_current_span(f\"ai_generation_attempt_{attempt + 1}\") as gen_span:\n",
    "                gen_span.set_attribute(\"generation.attempt\", attempt + 1)\n",
    "                gen_span.set_attribute(\"generation.max_tokens\", 150)\n",
    "                gen_span.set_attribute(\"generation.temperature\", 0.7 + (attempt * 0.1))\n",
    "                \n",
    "                try:\n",
    "                    response = client.chat.completions.create(\n",
    "                        model=deployment_name,\n",
    "                        messages=[\n",
    "                            {\n",
    "                                \"role\": \"system\", \n",
    "                                \"content\": \"You are an expert at explaining complex topics in simple terms.\"\n",
    "                            },\n",
    "                            {\"role\": \"user\", \"content\": input_text}\n",
    "                        ],\n",
    "                        max_tokens=150,\n",
    "                        temperature=0.7 + (attempt * 0.1)\n",
    "                    )\n",
    "                    \n",
    "                    # Add detailed response attributes\n",
    "                    gen_span.set_attribute(\"response.length\", len(response.choices[0].message.content))\n",
    "                    gen_span.set_attribute(\"response.finish_reason\", response.choices[0].finish_reason)\n",
    "                    gen_span.set_attribute(\"tokens.prompt\", response.usage.prompt_tokens)\n",
    "                    gen_span.set_attribute(\"tokens.completion\", response.usage.completion_tokens)\n",
    "                    gen_span.set_attribute(\"tokens.total\", response.usage.total_tokens)\n",
    "                    gen_span.set_attribute(\"model.name\", response.model)\n",
    "                    \n",
    "                    # Add success event\n",
    "                    gen_span.add_event(\"Generation successful\", {\n",
    "                        \"attempt\": attempt + 1,\n",
    "                        \"tokens_used\": response.usage.total_tokens\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"âœ… Attempt {attempt + 1} successful:\")\n",
    "                    print(f\"   {response.choices[0].message.content[:100]}...\")\n",
    "                    \n",
    "                    # Success - break out of retry loop\n",
    "                    break\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    gen_span.record_exception(e)\n",
    "                    gen_span.set_attribute(\"generation.error\", True)\n",
    "                    gen_span.add_event(\"Generation failed\", {\n",
    "                        \"attempt\": attempt + 1,\n",
    "                        \"error_type\": type(e).__name__\n",
    "                    })\n",
    "                    print(f\"âŒ Attempt {attempt + 1} failed: {e}\")\n",
    "        \n",
    "        # Step 3: Post-processing\n",
    "        with tracer.start_as_current_span(\"post_processing\") as post_span:\n",
    "            post_span.set_attribute(\"processing.step\", 3)\n",
    "            post_span.set_attribute(\"processing.type\", \"formatting\")\n",
    "            \n",
    "            # Simulate post-processing\n",
    "            time.sleep(0.05)\n",
    "            \n",
    "            # Add metadata about the final result\n",
    "            if 'response' in locals():\n",
    "                word_count = len(response.choices[0].message.content.split())\n",
    "                post_span.set_attribute(\"output.word_count\", word_count)\n",
    "                post_span.set_attribute(\"output.has_technical_terms\", True)\n",
    "                \n",
    "            post_span.add_event(\"Post-processing complete\")\n",
    "        \n",
    "        # Mark workflow completion\n",
    "        workflow_span.add_event(\"Workflow completed successfully\", {\n",
    "            \"total_steps\": 3,\n",
    "            \"final_status\": \"success\"\n",
    "        })\n",
    "        \n",
    "        workflow_span.set_attribute(\"workflow.status\", \"completed\")\n",
    "        workflow_span.set_attribute(\"workflow.duration_category\", \"normal\")\n",
    "\n",
    "# Run advanced tracing demo\n",
    "advanced_tracing_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7e1a17",
   "metadata": {},
   "source": [
    "## 12. Console Tracing Configuration\n",
    "\n",
    "Configure tracing to output to console for local debugging, as shown in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8c0923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_console_only_tracing():\n",
    "    \"\"\"\n",
    "    Set up console-only tracing for CI/CD or local development.\n",
    "    This follows the console tracing example from the documentation.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“º Setting up Console-Only Tracing...\")\n",
    "    \n",
    "    # Import additional components for console tracing\n",
    "    from opentelemetry.sdk.trace import TracerProvider\n",
    "    from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter\n",
    "    \n",
    "    # Create a separate tracer provider for console output\n",
    "    span_exporter = ConsoleSpanExporter()\n",
    "    tracer_provider = TracerProvider()\n",
    "    tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter))\n",
    "    \n",
    "    # Note: Don't set this as the global provider if Azure Monitor is already configured\n",
    "    # This is just for demonstration\n",
    "    \n",
    "    print(\"âœ… Console tracing setup complete\")\n",
    "    print(\"ğŸ“‹ Use this configuration for:\")\n",
    "    print(\"  â€¢ Unit testing environments\")\n",
    "    print(\"  â€¢ CI/CD pipelines\")\n",
    "    print(\"  â€¢ Local development debugging\")\n",
    "    print(\"  â€¢ When Azure connectivity is not available\")\n",
    "    \n",
    "    return tracer_provider\n",
    "\n",
    "def demo_console_tracing():\n",
    "    \"\"\"\n",
    "    Demonstrate console-only tracing with a simple API call.\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ§ª Console Tracing Demo:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Make a simple API call that will be traced to console\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Write a short poem on open telemetry.\"}\n",
    "        ],\n",
    "        max_tokens=80,\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    print(f\"ğŸ“ Generated poem:\\n{response.choices[0].message.content}\")\n",
    "    print(f\"\\nğŸ“Š Usage: {response.usage.total_tokens} tokens\")\n",
    "    print(\"\\nğŸ’¡ Check the console output above for the JSON trace data\")\n",
    "\n",
    "# Set up console tracing (for demonstration)\n",
    "console_tracer_provider = setup_console_only_tracing()\n",
    "\n",
    "# Demo console tracing\n",
    "demo_console_tracing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257b99cd",
   "metadata": {},
   "source": [
    "## 13. Error Handling and Exception Tracing\n",
    "\n",
    "Demonstrate how to properly trace errors and exceptions in AI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f94d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_error_tracing():\n",
    "    \"\"\"\n",
    "    Demonstrate error handling and exception tracing.\n",
    "    \"\"\"\n",
    "    print(\"ğŸš¨ Error Handling and Exception Tracing Demo:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test 1: Invalid model name (should fail)\n",
    "    with tracer.start_as_current_span(\"test_invalid_model\") as error_span:\n",
    "        error_span.set_attribute(\"test.type\", \"invalid_model_error\")\n",
    "        error_span.set_attribute(\"test.expected_outcome\", \"failure\")\n",
    "        \n",
    "        try:\n",
    "            print(\"1ï¸âƒ£ Testing invalid model name...\")\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"non-existent-model\",\n",
    "                messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "                max_tokens=10\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Properly record the exception in the span\n",
    "            error_span.record_exception(e)\n",
    "            error_span.set_attribute(\"error.type\", type(e).__name__)\n",
    "            error_span.set_attribute(\"error.message\", str(e))\n",
    "            error_span.set_status(trace.Status(trace.StatusCode.ERROR, str(e)))\n",
    "            \n",
    "            print(f\"   âŒ Expected error caught: {type(e).__name__}\")\n",
    "            print(f\"   ğŸ“ Error message: {str(e)[:100]}...\")\n",
    "    \n",
    "    # Test 2: Malformed request (should fail)\n",
    "    with tracer.start_as_current_span(\"test_malformed_request\") as malformed_span:\n",
    "        malformed_span.set_attribute(\"test.type\", \"malformed_request\")\n",
    "        \n",
    "        try:\n",
    "            print(\"\\n2ï¸âƒ£ Testing malformed request...\")\n",
    "            # This should fail due to invalid max_tokens\n",
    "            response = client.chat.completions.create(\n",
    "                model=deployment_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "                max_tokens=-1  # Invalid value\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            malformed_span.record_exception(e)\n",
    "            malformed_span.set_attribute(\"error.type\", type(e).__name__)\n",
    "            malformed_span.set_status(trace.Status(trace.StatusCode.ERROR, str(e)))\n",
    "            \n",
    "            print(f\"   âŒ Expected error caught: {type(e).__name__}\")\n",
    "    \n",
    "    # Test 3: Successful request with error recovery\n",
    "    with tracer.start_as_current_span(\"test_error_recovery\") as recovery_span:\n",
    "        recovery_span.set_attribute(\"test.type\", \"error_recovery\")\n",
    "        recovery_span.set_attribute(\"retry.max_attempts\", 3)\n",
    "        \n",
    "        for attempt in range(3):\n",
    "            with tracer.start_as_current_span(f\"retry_attempt_{attempt + 1}\") as attempt_span:\n",
    "                attempt_span.set_attribute(\"retry.attempt\", attempt + 1)\n",
    "                \n",
    "                try:\n",
    "                    print(f\"\\n3ï¸âƒ£ Retry attempt {attempt + 1}...\")\n",
    "                    \n",
    "                    # Simulate different error conditions for first attempts\n",
    "                    if attempt == 0:\n",
    "                        # Simulate a temporary failure\n",
    "                        attempt_span.add_event(\"Simulating temporary failure\")\n",
    "                        raise Exception(\"Simulated temporary network error\")\n",
    "                    elif attempt == 1:\n",
    "                        # Simulate another temporary failure\n",
    "                        attempt_span.add_event(\"Simulating another temporary failure\")\n",
    "                        raise Exception(\"Simulated rate limiting error\")\n",
    "                    else:\n",
    "                        # Success on third attempt\n",
    "                        response = client.chat.completions.create(\n",
    "                            model=deployment_name,\n",
    "                            messages=[{\"role\": \"user\", \"content\": \"Hello! This is a test.\"}],\n",
    "                            max_tokens=30\n",
    "                        )\n",
    "                        \n",
    "                        attempt_span.set_attribute(\"retry.success\", True)\n",
    "                        attempt_span.set_attribute(\"tokens.used\", response.usage.total_tokens)\n",
    "                        attempt_span.add_event(\"Request succeeded\")\n",
    "                        \n",
    "                        recovery_span.set_attribute(\"recovery.successful_attempt\", attempt + 1)\n",
    "                        recovery_span.add_event(\"Error recovery successful\")\n",
    "                        \n",
    "                        print(f\"   âœ… Success on attempt {attempt + 1}!\")\n",
    "                        print(f\"   ğŸ“ Response: {response.choices[0].message.content}\")\n",
    "                        break\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    attempt_span.record_exception(e)\n",
    "                    attempt_span.set_attribute(\"retry.failed\", True)\n",
    "                    attempt_span.set_attribute(\"error.type\", type(e).__name__)\n",
    "                    \n",
    "                    print(f\"   âŒ Attempt {attempt + 1} failed: {e}\")\n",
    "                    \n",
    "                    if attempt == 2:  # Last attempt\n",
    "                        recovery_span.set_status(trace.Status(trace.StatusCode.ERROR, \"All retry attempts failed\"))\n",
    "                        recovery_span.add_event(\"Error recovery failed\")\n",
    "    \n",
    "    print(f\"\\nâœ… Error tracing demo completed!\")\n",
    "    print(\"ğŸ” All errors and exceptions have been properly recorded in traces\")\n",
    "\n",
    "# Run error tracing demo\n",
    "demo_error_tracing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5413ab6",
   "metadata": {},
   "source": [
    "## 14. Production Monitoring Best Practices\n",
    "\n",
    "Learn about production-ready monitoring and tracing patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ab10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_production_patterns():\n",
    "    \"\"\"\n",
    "    Demonstrate production monitoring patterns and best practices.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ­ Production Monitoring Best Practices:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create a production-style AI service simulation\n",
    "    with tracer.start_as_current_span(\"ai_service_request\") as service_span:\n",
    "        # Add service-level attributes\n",
    "        service_span.set_attribute(\"service.name\", \"ai-content-generator\")\n",
    "        service_span.set_attribute(\"service.version\", \"1.2.3\")\n",
    "        service_span.set_attribute(\"service.instance\", \"instance-001\")\n",
    "        service_span.set_attribute(\"user.id\", \"user_456\")\n",
    "        service_span.set_attribute(\"request.id\", \"req_789\")\n",
    "        service_span.set_attribute(\"request.type\", \"content_generation\")\n",
    "        \n",
    "        # Step 1: Input validation\n",
    "        with tracer.start_as_current_span(\"input_validation\") as validation_span:\n",
    "            validation_span.set_attribute(\"validation.required_fields\", [\"content_type\", \"prompt\"])\n",
    "            validation_span.set_attribute(\"validation.passed\", True)\n",
    "            validation_span.add_event(\"Input validation completed\")\n",
    "        \n",
    "        # Step 2: Rate limiting check\n",
    "        with tracer.start_as_current_span(\"rate_limit_check\") as rate_span:\n",
    "            rate_span.set_attribute(\"rate_limit.user_id\", \"user_456\")\n",
    "            rate_span.set_attribute(\"rate_limit.current_usage\", 45)\n",
    "            rate_span.set_attribute(\"rate_limit.limit\", 100)\n",
    "            rate_span.set_attribute(\"rate_limit.window\", \"hourly\")\n",
    "            rate_span.set_attribute(\"rate_limit.allowed\", True)\n",
    "        \n",
    "        # Step 3: Content generation\n",
    "        with tracer.start_as_current_span(\"content_generation\") as content_span:\n",
    "            content_span.set_attribute(\"generation.model\", deployment_name)\n",
    "            content_span.set_attribute(\"generation.max_tokens\", 200)\n",
    "            content_span.set_attribute(\"generation.temperature\", 0.7)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=deployment_name,\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": \"You are a professional content writer. Create engaging, high-quality content.\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": \"Write a brief introduction for a blog post about sustainable technology innovations.\"\n",
    "                        }\n",
    "                    ],\n",
    "                    max_tokens=200,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                \n",
    "                generation_time = time.time() - start_time\n",
    "                \n",
    "                # Add comprehensive performance metrics\n",
    "                content_span.set_attribute(\"generation.duration_ms\", round(generation_time * 1000, 2))\n",
    "                content_span.set_attribute(\"generation.tokens_per_second\", \n",
    "                                         round(response.usage.total_tokens / generation_time, 2))\n",
    "                content_span.set_attribute(\"generation.prompt_tokens\", response.usage.prompt_tokens)\n",
    "                content_span.set_attribute(\"generation.completion_tokens\", response.usage.completion_tokens)\n",
    "                content_span.set_attribute(\"generation.total_tokens\", response.usage.total_tokens)\n",
    "                \n",
    "                # Business metrics\n",
    "                content_span.set_attribute(\"business.content_length\", len(response.choices[0].message.content))\n",
    "                content_span.set_attribute(\"business.estimated_cost_usd\", \n",
    "                                         round(response.usage.total_tokens * 0.0001, 6))  # Rough estimate\n",
    "                \n",
    "                print(f\"âœ… Content generated successfully!\")\n",
    "                print(f\"   Duration: {generation_time:.2f}s\")\n",
    "                print(f\"   Tokens: {response.usage.total_tokens}\")\n",
    "                print(f\"   Content: {response.choices[0].message.content[:100]}...\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                content_span.record_exception(e)\n",
    "                content_span.set_attribute(\"generation.error\", True)\n",
    "                raise\n",
    "        \n",
    "        # Step 4: Content quality check\n",
    "        with tracer.start_as_current_span(\"quality_check\") as quality_span:\n",
    "            content_text = response.choices[0].message.content\n",
    "            \n",
    "            # Simulate quality metrics\n",
    "            word_count = len(content_text.split())\n",
    "            char_count = len(content_text)\n",
    "            has_proper_structure = len(content_text.split('.')) > 2\n",
    "            \n",
    "            quality_span.set_attribute(\"quality.word_count\", word_count)\n",
    "            quality_span.set_attribute(\"quality.character_count\", char_count)\n",
    "            quality_span.set_attribute(\"quality.has_proper_structure\", has_proper_structure)\n",
    "            quality_span.set_attribute(\"quality.readability_score\", 85)  # Simulated\n",
    "            quality_span.set_attribute(\"quality.passed\", True)\n",
    "        \n",
    "        # Add final service metrics\n",
    "        service_span.set_attribute(\"service.request_status\", \"completed\")\n",
    "        service_span.set_attribute(\"service.total_processing_time_ms\", \n",
    "                                 round((time.time() - start_time) * 1000, 2))\n",
    "        service_span.add_event(\"Service request completed successfully\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Production Monitoring Key Metrics:\")\n",
    "    print(\"  â€¢ Request duration and throughput\")\n",
    "    print(\"  â€¢ Token usage and estimated costs\")\n",
    "    print(\"  â€¢ Error rates and types\")\n",
    "    print(\"  â€¢ Business metrics (content quality, user satisfaction)\")\n",
    "    print(\"  â€¢ Infrastructure metrics (rate limits, quotas)\")\n",
    "    \n",
    "    print(f\"\\nğŸš¨ Recommended Alerts:\")\n",
    "    print(\"  â€¢ Response time > 95th percentile (e.g., > 5 seconds)\")\n",
    "    print(\"  â€¢ Error rate > 5% over 5-minute window\")\n",
    "    print(\"  â€¢ Token usage approaching monthly quota\")\n",
    "    print(\"  â€¢ Quality score dropping below threshold\")\n",
    "\n",
    "# Run production patterns demo\n",
    "demonstrate_production_patterns()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93297f",
   "metadata": {},
   "source": [
    "## 15. Viewing Traces in Azure AI Foundry\n",
    "\n",
    "Instructions for viewing and analyzing your traces in Azure AI Foundry portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7056c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_trace_viewing_instructions():\n",
    "    \"\"\"\n",
    "    Provide instructions for viewing traces in Azure AI Foundry and Application Insights.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” Viewing Your Traces in Azure AI Foundry:\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    if azure_monitor_enabled:\n",
    "        print(\"âœ… Your traces are being sent to Azure Application Insights!\")\n",
    "        print()\n",
    "        \n",
    "        print(\"ğŸ“‹ Step-by-Step Instructions:\")\n",
    "        steps = [\n",
    "            \"1. ğŸŒ Go to Azure AI Foundry portal (ai.azure.com)\",\n",
    "            \"2. ğŸ” Navigate to your project\",\n",
    "            \"3. ğŸ“Š Click 'Tracing' in the left sidebar\",\n",
    "            \"4. ğŸ¯ You should see traces from this notebook session\",\n",
    "            \"5. ğŸ” Click on any trace to see detailed span information\",\n",
    "            \"6. ğŸ“ˆ Explore span attributes, events, and timing data\"\n",
    "        ]\n",
    "        \n",
    "        for step in steps:\n",
    "            print(f\"   {step}\")\n",
    "        \n",
    "        print(f\"\\nğŸ” What to Look for in Your Traces:\")\n",
    "        trace_elements = [\n",
    "            \"â€¢ 'assess_claims_with_context' - Custom business logic spans\",\n",
    "            \"â€¢ 'chat completions' - Automatic OpenAI API call spans\",\n",
    "            \"â€¢ 'advanced_ai_workflow' - Multi-step process spans\",\n",
    "            \"â€¢ Error spans with exception details\",\n",
    "            \"â€¢ Performance metrics and token usage data\"\n",
    "        ]\n",
    "        \n",
    "        for element in trace_elements:\n",
    "            print(f\"  {element}\")\n",
    "        \n",
    "        print(f\"\\nâš¡ Pro Tips for Trace Analysis:\")\n",
    "        tips = [\n",
    "            \"â€¢ Use the timeline view to identify performance bottlenecks\",\n",
    "            \"â€¢ Filter traces by custom attributes (e.g., user.session_id)\",\n",
    "            \"â€¢ Look for patterns in error traces to identify common issues\",\n",
    "            \"â€¢ Monitor token usage trends across different operations\",\n",
    "            \"â€¢ Set up alerts on high-latency or high-error operations\"\n",
    "        ]\n",
    "        \n",
    "        for tip in tips:\n",
    "            print(f\"  {tip}\")\n",
    "            \n",
    "        print(f\"\\nğŸ“Š Alternative: Direct Application Insights Access:\")\n",
    "        ai_steps = [\n",
    "            \"1. Go to Azure Portal (portal.azure.com)\",\n",
    "            \"2. Find your Application Insights resource\",\n",
    "            \"3. Navigate to 'Investigate' â†’ 'Transaction search'\",\n",
    "            \"4. Use filters to find specific traces\",\n",
    "            \"5. Try KQL queries in the 'Logs' section\"\n",
    "        ]\n",
    "        \n",
    "        for step in ai_steps:\n",
    "            print(f\"   {step}\")\n",
    "            \n",
    "        print(f\"\\nğŸ”§ Sample KQL Queries to Try:\")\n",
    "        queries = [\n",
    "            \"// Find all AI workflow traces\",\n",
    "            \"traces | where operation_Name contains 'ai_workflow'\",\n",
    "            \"\",\n",
    "            \"// Analyze token usage\",\n",
    "            \"traces | where customDimensions has 'tokens.total'\",\n",
    "            \"| extend tokens = toint(customDimensions['tokens.total'])\",\n",
    "            \"| summarize avg(tokens), max(tokens) by bin(timestamp, 1h)\",\n",
    "            \"\",\n",
    "            \"// Find error traces\",\n",
    "            \"traces | where severityLevel >= 3\",\n",
    "            \"| order by timestamp desc\"\n",
    "        ]\n",
    "        \n",
    "        for query in queries:\n",
    "            print(f\"   {query}\")\n",
    "    else:\n",
    "        print(\"âŒ Azure Monitor not configured\")\n",
    "        print(\"ğŸ’¡ To view traces in Azure AI Foundry:\")\n",
    "        print(\"  1. Configure Application Insights in your AI Foundry project\")\n",
    "        print(\"  2. Run this notebook again to send traces to Azure\")\n",
    "        print(\"  3. For now, traces are only visible in console output\")\n",
    "\n",
    "show_trace_viewing_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74740a8",
   "metadata": {},
   "source": [
    "## 16. Summary and Next Steps\n",
    "\n",
    "Congratulations! You've successfully implemented comprehensive tracing for AI applications using OpenTelemetry and Azure AI Foundry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24422a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def workshop_summary():\n",
    "    \"\"\"\n",
    "    Summarize the workshop achievements and provide next steps.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ¯ Workshop Summary: Tracing AI Applications\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"âœ… What You've Accomplished:\")\n",
    "    achievements = [\n",
    "        \"â€¢ Set up Azure AI Foundry project integration\",\n",
    "        \"â€¢ Configured OpenTelemetry instrumentation for OpenAI SDK\",\n",
    "        \"â€¢ Established Azure Application Insights connectivity\",\n",
    "        \"â€¢ Created custom spans for business logic tracing\",\n",
    "        \"â€¢ Implemented comprehensive error handling and exception tracing\",\n",
    "        \"â€¢ Added detailed attributes and events for observability\",\n",
    "        \"â€¢ Demonstrated production monitoring patterns\",\n",
    "        \"â€¢ Set up both cloud and console tracing options\"\n",
    "    ]\n",
    "    \n",
    "    for achievement in achievements:\n",
    "        print(f\"  {achievement}\")\n",
    "    \n",
    "    print(f\"\\nğŸ› ï¸ Technical Skills Gained:\")\n",
    "    skills = [\n",
    "        \"â€¢ OpenTelemetry SDK configuration and usage\",\n",
    "        \"â€¢ Azure AI Projects client integration\",\n",
    "        \"â€¢ Custom span creation with attributes and events\",\n",
    "        \"â€¢ Exception recording and error status handling\",\n",
    "        \"â€¢ Performance monitoring and metrics collection\",\n",
    "        \"â€¢ Production-ready observability patterns\"\n",
    "    ]\n",
    "    \n",
    "    for skill in skills:\n",
    "        print(f\"  {skill}\")\n",
    "    \n",
    "    print(f\"\\nğŸš€ Next Steps for Your AI Applications:\")\n",
    "    next_steps = [\n",
    "        \"1. ğŸ“Š Implement monitoring dashboards in Application Insights\",\n",
    "        \"2. ğŸš¨ Set up alerts for error rates and performance thresholds\",\n",
    "        \"3. ğŸ“ˆ Add business-specific metrics to track AI effectiveness\",\n",
    "        \"4. ğŸ” Use trace data to optimize AI application performance\",\n",
    "        \"5. ğŸ­ Deploy with production monitoring best practices\",\n",
    "        \"6. ğŸ“š Explore advanced OpenTelemetry features (sampling, batching)\",\n",
    "        \"7. ğŸ”— Integrate with other Azure monitoring services\"\n",
    "    ]\n",
    "    \n",
    "    for step in next_steps:\n",
    "        print(f\"  {step}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ Key Takeaways:\")\n",
    "    takeaways = [\n",
    "        \"â€¢ Observability is crucial for production AI applications\",\n",
    "        \"â€¢ OpenTelemetry provides standardized, vendor-neutral tracing\",\n",
    "        \"â€¢ Azure AI Foundry simplifies AI application monitoring setup\",\n",
    "        \"â€¢ Custom spans enable business-specific observability\",\n",
    "        \"â€¢ Proper error tracing helps diagnose and resolve issues quickly\",\n",
    "        \"â€¢ Performance data guides optimization efforts\"\n",
    "    ]\n",
    "    \n",
    "    for takeaway in takeaways:\n",
    "        print(f\"  {takeaway}\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ Congratulations on completing this comprehensive tracing workshop!\")\n",
    "    print(\"You're now equipped to build observable, production-ready AI applications!\")\n",
    "\n",
    "# Clean up resources\n",
    "def cleanup_resources():\n",
    "    \"\"\"\n",
    "    Clean up OpenTelemetry instrumentation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Uninstrument OpenAI SDK\n",
    "        OpenAIInstrumentor().uninstrument()\n",
    "        print(\"\\nğŸ§¹ OpenAI SDK instrumentation cleaned up\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nNote: Cleanup not needed or failed: {e}\")\n",
    "\n",
    "# Display summary and cleanup\n",
    "workshop_summary()\n",
    "cleanup_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e484c5",
   "metadata": {},
   "source": [
    "## ğŸ“š Additional Resources and References\n",
    "\n",
    "### Official Documentation\n",
    "- [Azure AI Foundry Tracing Documentation](https://learn.microsoft.com/azure/ai-foundry/how-to/develop/trace-application)\n",
    "- [OpenTelemetry Python Documentation](https://opentelemetry.io/docs/languages/python/)\n",
    "- [Azure Monitor OpenTelemetry Documentation](https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-enable)\n",
    "\n",
    "### Code Examples and Templates\n",
    "- [Azure AI Projects SDK Samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-projects)\n",
    "- [OpenTelemetry Instrumentation Examples](https://github.com/open-telemetry/opentelemetry-python-contrib)\n",
    "\n",
    "### Best Practices Guides\n",
    "- [Production Monitoring for AI Applications](https://learn.microsoft.com/azure/architecture/ai-ml/guide/monitoring-ai-applications)\n",
    "- [OpenTelemetry Best Practices](https://opentelemetry.io/docs/specs/otel/performance/)\n",
    "\n",
    "### Troubleshooting\n",
    "Common issues and solutions:\n",
    "\n",
    "1. **No traces appearing**: Check Application Insights configuration and connection string\n",
    "2. **High performance overhead**: Implement sampling and batch processors\n",
    "3. **Missing span data**: Verify custom attributes don't contain special characters\n",
    "4. **Authentication errors**: Ensure Azure credentials are properly configured\n",
    "\n",
    "### Environment Variables Reference\n",
    "Required variables for this notebook:\n",
    "```bash\n",
    "# Azure AI Foundry Project\n",
    "AZURE_AI_PROJECT_ENDPOINT=https://your-project.services.ai.azure.com/api/projects/your-project\n",
    "\n",
    "# OpenAI Deployment\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=your-model-deployment-name\n",
    "\n",
    "# Optional: Content capture (development only)\n",
    "OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT=false\n",
    "\n",
    "# Optional: Direct Application Insights (if not using project client)\n",
    "APPLICATION_INSIGHTS_CONNECTION_STRING=InstrumentationKey=...\n",
    "```\n",
    "\n",
    "This completes the comprehensive guide to tracing AI applications using OpenAI SDK with OpenTelemetry and Azure AI Foundry!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
