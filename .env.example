# Azure AI Foundry Workshop Environment Variables
# Copy this file to .env and fill in your actual values

# ===== MINIMUM REQUIRED VARIABLES =====
# These are the minimum required environment variables to run the workshop

# Azure OpenAI Endpoint (REQUIRED)
# This is the AI Foundry resource endpoint from your deployment
AZURE_OPENAI_ENDPOINT=https://your-foundry-resource.cognitiveservices.azure.com/

# Azure OpenAI API Key (REQUIRED for key-based auth)
# Get this from Azure Portal -> Your AI Foundry resource -> Keys and Endpoint
# Use either KEY1 or KEY2. Leave commented if using Entra ID authentication
# AZURE_OPENAI_API_KEY=your-api-key-here

# Model Deployment Name (REQUIRED) 
# This is the name of your deployed model (e.g., gpt-4o)
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o

# API Version (REQUIRED)
# The Azure OpenAI API version to use
AZURE_OPENAI_API_VERSION=2024-10-21

# ===== AUTHENTICATION METHOD =====
# Choose your authentication method:
# 1. For Key-based authentication: Set AZURE_OPENAI_API_KEY above
# 2. For Entra ID authentication (recommended): Keep AZURE_OPENAI_API_KEY commented

# ===== ADDITIONAL AZURE AI FOUNDRY CONFIGURATION =====
# These are helpful for advanced workshop features but not strictly required

# AI Foundry Project Endpoint (for AI Foundry SDK features) 
PROJECT_ENDPOINT=https://your-foundry-resource.services.ai.azure.com/api/projects/your-project-name

# AI Foundry Project Connection String
PROJECT_CONNECTION_STRING=SubscriptionId=your-subscription-id;ResourceGroupName=your-resource-group;ProjectName=your-project-name

# AI Foundry Resource Name
AZURE_AI_FOUNDRY_RESOURCE_NAME=your-foundry-resource

# AI Foundry Project Name
AZURE_AI_FOUNDRY_PROJECT_NAME=your-project-name

# Resource Group Name
AZURE_RESOURCE_GROUP_NAME=your-resource-group

# Subscription ID
AZURE_SUBSCRIPTION_ID=your-subscription-id

# Azure Region
AZURE_REGION=eastus2

# ===== OPTIONAL SETTINGS =====
# These have sensible defaults but can be customized

# Temperature for model responses
DEFAULT_TEMPERATURE=0.7

# Maximum tokens for responses
DEFAULT_MAX_TOKENS=1000

# Workshop data directory
DATA_DIR=./data

# Training data paths for fine-tuning exercise
TRAINING_DATA_PATH=./data/training_set.jsonl
VALIDATION_DATA_PATH=./data/validation_set.jsonl

# ===== TRACING AND MONITORING (OPTIONAL) =====
# Application Insights connection string for tracing
# Get this from Azure AI Foundry portal -> Observability -> Tracing
# Or from Azure deployment outputs after running: cd infrastructure/bicep && ./deploy.sh
# APPLICATION_INSIGHTS_CONNECTION_STRING=InstrumentationKey=your-key;IngestionEndpoint=https://region.in.applicationinsights.azure.com/;LiveEndpoint=https://region.livediagnostics.monitor.azure.com/;ApplicationId=your-app-id

# Enable content recording for tracing (contains sensitive data)
AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED=false

# ===== AZURE STORAGE (OPTIONAL) =====
# Only needed if running evaluations with storage
# AZURE_STORAGE_CONNECTION_STRING=your-storage-connection-string
# AZURE_STORAGE_ACCOUNT_NAME=your-storage-account-name
