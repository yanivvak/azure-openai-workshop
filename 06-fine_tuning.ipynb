{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19f68af",
   "metadata": {},
   "source": [
    "# Azure OpenAI Fine-Tuning Tutorial\n",
    "\n",
    "This notebook provides a comprehensive guide to fine-tuning Azure OpenAI models using the Python SDK. Fine-tuning allows you to customize models to better perform on your specific tasks and datasets.\n",
    "\n",
    "## What is Fine-Tuning?\n",
    "\n",
    "Fine-tuning is a process that customizes a pre-trained model by training it on your specific dataset. This provides several benefits:\n",
    "\n",
    "- **Higher quality results** than prompt engineering alone\n",
    "- **Ability to train on more examples** than can fit in a prompt\n",
    "- **Token savings** due to shorter prompts\n",
    "- **Lower latency** requests\n",
    "\n",
    "Azure OpenAI uses LoRA (Low Rank Adaptation) for efficient fine-tuning, which reduces complexity while maintaining performance.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Azure OpenAI resource with fine-tuning access\n",
    "- Cognitive Services OpenAI Contributor role\n",
    "- Python environment with required packages\n",
    "- Training data in JSONL format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1e0125",
   "metadata": {},
   "source": [
    "## 1. Setup and Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e2835fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Azure CLI authentication\n",
      "Azure OpenAI client initialized successfully with Entra ID authentication!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, AzureDeveloperCliCredential, AzureCliCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Azure credential for Entra ID authentication\n",
    "# This will try multiple authentication methods in order:\n",
    "# 1. Environment variables (service principal)\n",
    "# 2. Managed identity (if running on Azure)\n",
    "# 3. Azure CLI credential (if logged in via az login)\n",
    "# 4. Azure Developer CLI credential (if logged in via azd auth login)\n",
    "try:\n",
    "    # Try Azure CLI first (most common for development)\n",
    "    credential = AzureCliCredential()\n",
    "    print(\"Using Azure CLI authentication\")\n",
    "except Exception:\n",
    "    try:\n",
    "        # Fall back to Azure Developer CLI\n",
    "        credential = AzureDeveloperCliCredential()\n",
    "        print(\"Using Azure Developer CLI authentication\")\n",
    "    except Exception:\n",
    "        # Fall back to DefaultAzureCredential (tries multiple methods)\n",
    "        credential = DefaultAzureCredential()\n",
    "        print(\"Using DefaultAzureCredential authentication\")\n",
    "\n",
    "# Initialize Azure OpenAI client with Entra ID\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_ad_token_provider=lambda: credential.get_token(\"https://cognitiveservices.azure.com/.default\").token,\n",
    "    api_version=\"2024-10-21\"  # Required for fine-tuning features\n",
    ")\n",
    "\n",
    "print(\"Azure OpenAI client initialized successfully with Entra ID authentication!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ae0e02",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "Fine-tuning data must be in JSONL format with conversational structure. Each line contains a `messages` array with `role` and `content` fields.\n",
    "\n",
    "### Required Format:\n",
    "```json\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "```\n",
    "\n",
    "### Best Practices:\n",
    "- Minimum 10 examples (recommended 50+ for good results)\n",
    "- Hundreds or thousands of examples for optimal performance\n",
    "- High-quality, diverse examples\n",
    "- Consistent system messages\n",
    "- UTF-8 encoding with BOM\n",
    "- File size under 512 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6acfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample training data for a sarcastic chatbot\n",
    "training_data = [\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who discovered Antarctica?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}\n",
    "    ]},\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the biggest ocean?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Pacific Ocean. It's not like it's a small pond or anything.\"}\n",
    "    ]},\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the largest planet?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"It's called Jupiter, you might have heard of it...or not.\"}\n",
    "    ]},\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who painted the Mona Lisa?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Oh, some obscure artist named Leonardo da Vinci. Not that he is famous or anything.\"}\n",
    "    ]},\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the boiling point of water?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Exciting fact of the day: it's 100 degrees Celsius. Life-changing, isn't it?\"}\n",
    "    ]},\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who wrote 'The Odyssey'?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Oh, just some poet named Homer. Nothing special, really.\"}\n",
    "    ]},\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the largest mammal?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Blue Whale. Quite a big fish isn't it? Oh wait, it's not a fish!\"}\n",
    "    ]},\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the highest mountain peak?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Everest. Brace yourself, it's not a walk in the park.\"}\n",
    "    ]},\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who invented the telephone?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"A guy named Alexander Graham Bell. Bet you didn't guess that one!\"}\n",
    "    ]},\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the distance from Earth to the Sun?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"About 93 million miles. Just a quick drive, really.\"}\n",
    "    ]}\n",
    "]\n",
    "\n",
    "# Create validation data (smaller subset)\n",
    "validation_data = [\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the capital of France?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}\n",
    "    ]},\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How many continents are there?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Seven. Shocking revelation, I know.\"}\n",
    "    ]}\n",
    "]\n",
    "\n",
    "print(f\"Created {len(training_data)} training examples\")\n",
    "print(f\"Created {len(validation_data)} validation examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e307dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to JSONL files\n",
    "def save_jsonl(data, filename):\n",
    "    \"\"\"Save data to JSONL format with UTF-8 encoding and BOM\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8-sig') as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "    print(f\"Saved {len(data)} examples to {filename}\")\n",
    "\n",
    "# Save training and validation files\n",
    "training_file_name = 'data/training_set_sarcastic.jsonl'\n",
    "validation_file_name = 'data/validation_set_sarcastic.jsonl'\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "save_jsonl(training_data, training_file_name)\n",
    "save_jsonl(validation_data, validation_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aff14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the JSONL format\n",
    "def validate_jsonl(filename):\n",
    "    \"\"\"Validate JSONL file format and structure\"\"\"\n",
    "    print(f\"Validating {filename}...\")\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8-sig') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    print(f\"Total lines: {len(lines)}\")\n",
    "    \n",
    "    for i, line in enumerate(lines[:3]):  # Check first 3 lines\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            print(f\"Line {i+1}: Valid JSON\")\n",
    "            print(f\"  Messages: {len(data.get('messages', []))}\")\n",
    "            print(f\"  Roles: {[msg['role'] for msg in data.get('messages', [])]}\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Line {i+1}: Invalid JSON - {e}\")\n",
    "    \n",
    "    print(\"Validation complete!\\n\")\n",
    "\n",
    "validate_jsonl(training_file_name)\n",
    "validate_jsonl(validation_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa250315",
   "metadata": {},
   "source": [
    "## 3. Upload Training Data\n",
    "\n",
    "Before starting fine-tuning, we need to upload our training and validation data to Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac517ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload training data\n",
    "print(\"Uploading training data...\")\n",
    "training_response = client.files.create(\n",
    "    file=open(training_file_name, \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "print(f\"Training file uploaded: {training_file_id}\")\n",
    "\n",
    "# Upload validation data\n",
    "print(\"Uploading validation data...\")\n",
    "validation_response = client.files.create(\n",
    "    file=open(validation_file_name, \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "print(f\"Validation file uploaded: {validation_file_id}\")\n",
    "\n",
    "print(\"\\nFile upload completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify file upload status\n",
    "def check_file_status(file_id, file_type):\n",
    "    \"\"\"Check the status of an uploaded file\"\"\"\n",
    "    try:\n",
    "        file_info = client.files.retrieve(file_id)\n",
    "        print(f\"{file_type} File Status:\")\n",
    "        print(f\"  ID: {file_info.id}\")\n",
    "        print(f\"  Filename: {file_info.filename}\")\n",
    "        print(f\"  Status: {file_info.status}\")\n",
    "        print(f\"  Size: {file_info.bytes} bytes\")\n",
    "        print(f\"  Purpose: {file_info.purpose}\")\n",
    "        print()\n",
    "        return file_info.status == \"processed\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking {file_type} file: {e}\")\n",
    "        return False\n",
    "\n",
    "# Check both files\n",
    "training_ready = check_file_status(training_file_id, \"Training\")\n",
    "validation_ready = check_file_status(validation_file_id, \"Validation\")\n",
    "\n",
    "if training_ready and validation_ready:\n",
    "    print(\"âœ… Both files are ready for fine-tuning!\")\n",
    "else:\n",
    "    print(\"â³ Files are still processing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597b172e",
   "metadata": {},
   "source": [
    "## 4. Create Fine-Tuning Job\n",
    "\n",
    "Now we'll create a fine-tuning job with our uploaded data. We'll use GPT-4o-mini as the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e49cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fine-tuning job\n",
    "print(\"Creating fine-tuning job...\")\n",
    "selected_model = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "fine_tune_response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=selected_model,\n",
    "    seed=105,  # For reproducibility\n",
    "    suffix=\"sarcastic-bot\",  # Helps identify the model\n",
    "    hyperparameters={\n",
    "        \"n_epochs\": 3,  # Number of training epochs\n",
    "        \"batch_size\": 1,  # Small batch size for small dataset\n",
    "        \"learning_rate_multiplier\": 1.0  # Default learning rate multiplier\n",
    "    }\n",
    ")\n",
    "\n",
    "job_id = fine_tune_response.id\n",
    "print(f\"Fine-tuning job created: {job_id}\")\n",
    "print(f\"Status: {fine_tune_response.status}\")\n",
    "print(f\"Model: {fine_tune_response.model}\")\n",
    "print(f\"Hyperparameters: {fine_tune_response.hyperparameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8c8055",
   "metadata": {},
   "source": [
    "## 5. Monitor Fine-Tuning Progress\n",
    "\n",
    "Fine-tuning can take several minutes to hours depending on the dataset size and model. We'll monitor the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94aa32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_job_status(job_id):\n",
    "    \"\"\"Check the status of a fine-tuning job\"\"\"\n",
    "    try:\n",
    "        job_info = client.fine_tuning.jobs.retrieve(job_id)\n",
    "        return job_info\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking job status: {e}\")\n",
    "        return None\n",
    "\n",
    "def display_job_status(job_info):\n",
    "    \"\"\"Display formatted job status information\"\"\"\n",
    "    if job_info:\n",
    "        print(f\"Job ID: {job_info.id}\")\n",
    "        print(f\"Status: {job_info.status}\")\n",
    "        print(f\"Model: {job_info.model}\")\n",
    "        print(f\"Fine-tuned model: {job_info.fine_tuned_model or 'Not yet available'}\")\n",
    "        print(f\"Created at: {job_info.created_at}\")\n",
    "        if job_info.finished_at:\n",
    "            print(f\"Finished at: {job_info.finished_at}\")\n",
    "        if hasattr(job_info, 'estimated_finish'):\n",
    "            print(f\"Estimated finish: {job_info.estimated_finish}\")\n",
    "        print()\n",
    "\n",
    "# Check initial status\n",
    "job_status = check_job_status(job_id)\n",
    "display_job_status(job_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor job progress (run this cell periodically)\n",
    "def monitor_fine_tuning(job_id, check_interval=60):\n",
    "    \"\"\"Monitor fine-tuning job progress\"\"\"\n",
    "    print(f\"Monitoring fine-tuning job: {job_id}\")\n",
    "    print(f\"Checking every {check_interval} seconds...\\n\")\n",
    "    \n",
    "    while True:\n",
    "        job_info = check_job_status(job_id)\n",
    "        if not job_info:\n",
    "            break\n",
    "            \n",
    "        status = job_info.status\n",
    "        print(f\"Current status: {status}\")\n",
    "        \n",
    "        if status in ['succeeded', 'failed', 'cancelled']:\n",
    "            print(f\"\\nðŸŽ‰ Job completed with status: {status}\")\n",
    "            if status == 'succeeded':\n",
    "                print(f\"Fine-tuned model: {job_info.fine_tuned_model}\")\n",
    "            display_job_status(job_info)\n",
    "            break\n",
    "        \n",
    "        print(f\"Waiting {check_interval} seconds before next check...\")\n",
    "        time.sleep(check_interval)\n",
    "\n",
    "# Start monitoring (comment out the line below to monitor manually)\n",
    "# monitor_fine_tuning(job_id, check_interval=30)\n",
    "\n",
    "# For manual checking, run this instead:\n",
    "job_status = check_job_status(job_id)\n",
    "display_job_status(job_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bff63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View fine-tuning events (detailed progress)\n",
    "def get_fine_tuning_events(job_id, limit=10):\n",
    "    \"\"\"Get recent fine-tuning events\"\"\"\n",
    "    try:\n",
    "        events = client.fine_tuning.jobs.list_events(\n",
    "            fine_tuning_job_id=job_id,\n",
    "            limit=limit\n",
    "        )\n",
    "        \n",
    "        print(f\"Recent fine-tuning events (last {limit}):\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for event in events.data:\n",
    "            timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(event.created_at))\n",
    "            print(f\"[{timestamp}] {event.level}: {event.message}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving events: {e}\")\n",
    "\n",
    "# Get recent events\n",
    "get_fine_tuning_events(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73230b66",
   "metadata": {},
   "source": [
    "## 6. Analyze Training Results\n",
    "\n",
    "Once fine-tuning is complete, we can download and analyze the results to understand model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and analyze results (run after job completion)\n",
    "def download_results(job_id):\n",
    "    \"\"\"Download and analyze fine-tuning results\"\"\"\n",
    "    job_info = check_job_status(job_id)\n",
    "    \n",
    "    if job_info.status != 'succeeded':\n",
    "        print(f\"Job status is {job_info.status}. Results not available yet.\")\n",
    "        return None\n",
    "    \n",
    "    if not job_info.result_files:\n",
    "        print(\"No result files available.\")\n",
    "        return None\n",
    "    \n",
    "    # Download the first result file\n",
    "    result_file_id = job_info.result_files[0]\n",
    "    print(f\"Downloading result file: {result_file_id}\")\n",
    "    \n",
    "    try:\n",
    "        # Get file info\n",
    "        file_info = client.files.retrieve(result_file_id)\n",
    "        filename = f\"results_{job_id}.csv\"\n",
    "        \n",
    "        # Download file content\n",
    "        with open(filename, \"wb\") as file:\n",
    "            result = client.files.content(result_file_id).read()\n",
    "            file.write(result)\n",
    "        \n",
    "        print(f\"Results saved to: {filename}\")\n",
    "        return filename\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading results: {e}\")\n",
    "        return None\n",
    "\n",
    "# Download results (uncomment when job is complete)\n",
    "# results_file = download_results(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdcf538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results with visualization\n",
    "def analyze_results(results_file):\n",
    "    \"\"\"Analyze and visualize fine-tuning results\"\"\"\n",
    "    if not results_file or not os.path.exists(results_file):\n",
    "        print(\"Results file not found. Make sure fine-tuning is complete and results are downloaded.\")\n",
    "        return\n",
    "    \n",
    "    # Read results\n",
    "    df = pd.read_csv(results_file)\n",
    "    print(\"Results Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total training steps: {len(df)}\")\n",
    "    print(f\"Columns: {', '.join(df.columns)}\")\n",
    "    print()\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"Summary Statistics:\")\n",
    "    print(df.describe())\n",
    "    print()\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Fine-Tuning Results Analysis', fontsize=16)\n",
    "    \n",
    "    # Training Loss\n",
    "    if 'train_loss' in df.columns:\n",
    "        axes[0, 0].plot(df['step'], df['train_loss'], label='Training Loss', color='blue')\n",
    "        if 'valid_loss' in df.columns:\n",
    "            axes[0, 0].plot(df['step'], df['valid_loss'], label='Validation Loss', color='red')\n",
    "        axes[0, 0].set_title('Loss Over Time')\n",
    "        axes[0, 0].set_xlabel('Step')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True)\n",
    "    \n",
    "    # Token Accuracy\n",
    "    if 'train_mean_token_accuracy' in df.columns:\n",
    "        axes[0, 1].plot(df['step'], df['train_mean_token_accuracy'], label='Training Accuracy', color='green')\n",
    "        if 'validation_mean_token_accuracy' in df.columns:\n",
    "            axes[0, 1].plot(df['step'], df['validation_mean_token_accuracy'], label='Validation Accuracy', color='orange')\n",
    "        axes[0, 1].set_title('Token Accuracy Over Time')\n",
    "        axes[0, 1].set_xlabel('Step')\n",
    "        axes[0, 1].set_ylabel('Accuracy')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True)\n",
    "    \n",
    "    # Full validation metrics (end of epoch)\n",
    "    if 'full_valid_loss' in df.columns:\n",
    "        epoch_data = df[df['full_valid_loss'].notna()]\n",
    "        if not epoch_data.empty:\n",
    "            axes[1, 0].plot(epoch_data['step'], epoch_data['full_valid_loss'], \n",
    "                           marker='o', label='End-of-Epoch Validation Loss', color='red')\n",
    "            axes[1, 0].set_title('End-of-Epoch Validation Loss')\n",
    "            axes[1, 0].set_xlabel('Step')\n",
    "            axes[1, 0].set_ylabel('Validation Loss')\n",
    "            axes[1, 0].legend()\n",
    "            axes[1, 0].grid(True)\n",
    "    \n",
    "    if 'full_valid_mean_token_accuracy' in df.columns:\n",
    "        epoch_data = df[df['full_valid_mean_token_accuracy'].notna()]\n",
    "        if not epoch_data.empty:\n",
    "            axes[1, 1].plot(epoch_data['step'], epoch_data['full_valid_mean_token_accuracy'], \n",
    "                           marker='o', label='End-of-Epoch Validation Accuracy', color='orange')\n",
    "            axes[1, 1].set_title('End-of-Epoch Validation Accuracy')\n",
    "            axes[1, 1].set_xlabel('Step')\n",
    "            axes[1, 1].set_ylabel('Validation Accuracy')\n",
    "            axes[1, 1].legend()\n",
    "            axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance insights\n",
    "    print(\"\\nPerformance Insights:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    if 'train_loss' in df.columns:\n",
    "        initial_loss = df['train_loss'].iloc[0]\n",
    "        final_loss = df['train_loss'].iloc[-1]\n",
    "        loss_improvement = (initial_loss - final_loss) / initial_loss * 100\n",
    "        print(f\"Training loss improvement: {loss_improvement:.2f}%\")\n",
    "    \n",
    "    if 'train_mean_token_accuracy' in df.columns:\n",
    "        initial_acc = df['train_mean_token_accuracy'].iloc[0]\n",
    "        final_acc = df['train_mean_token_accuracy'].iloc[-1]\n",
    "        acc_improvement = (final_acc - initial_acc) * 100\n",
    "        print(f\"Training accuracy improvement: +{acc_improvement:.2f} percentage points\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    if 'train_loss' in df.columns and 'valid_loss' in df.columns:\n",
    "        final_train_loss = df['train_loss'].iloc[-1]\n",
    "        final_valid_loss = df['valid_loss'].iloc[-1]\n",
    "        \n",
    "        if final_valid_loss > final_train_loss * 1.2:\n",
    "            print(\"âš ï¸  Potential overfitting detected (validation loss >> training loss)\")\n",
    "        else:\n",
    "            print(\"âœ… No significant overfitting detected\")\n",
    "\n",
    "# Analyze results (uncomment when results are available)\n",
    "# analyze_results(results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d98d06",
   "metadata": {},
   "source": [
    "## 7. Deploy Fine-Tuned Model\n",
    "\n",
    "Once fine-tuning is complete, we need to deploy the model to use it for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ac18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fine-tuned model ID\n",
    "def get_fine_tuned_model_id(job_id):\n",
    "    \"\"\"Get the fine-tuned model ID from completed job\"\"\"\n",
    "    job_info = check_job_status(job_id)\n",
    "    \n",
    "    if job_info.status == 'succeeded':\n",
    "        return job_info.fine_tuned_model\n",
    "    else:\n",
    "        print(f\"Job status: {job_info.status}. Model not ready for deployment.\")\n",
    "        return None\n",
    "\n",
    "# Get the model ID (uncomment when job is complete)\n",
    "# fine_tuned_model_id = get_fine_tuned_model_id(job_id)\n",
    "# print(f\"Fine-tuned model ID: {fine_tuned_model_id}\")\n",
    "\n",
    "# For demo purposes, we'll use a placeholder\n",
    "fine_tuned_model_id = \"gpt-4o-mini-2024-07-18.ft-example123.sarcastic-bot\"\n",
    "print(f\"Model ID (example): {fine_tuned_model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the fine-tuned model\n",
    "# Note: This requires management API access and differs from the data plane API\n",
    "\n",
    "def deploy_fine_tuned_model(model_id, deployment_name):\n",
    "    \"\"\"\n",
    "    Deploy a fine-tuned model using Azure Management API\n",
    "    This is a simplified example - in practice, you'll need proper authentication\n",
    "    \"\"\"\n",
    "    print(\"To deploy your fine-tuned model, you have several options:\")\n",
    "    print()\n",
    "    print(\"1. Azure Portal:\")\n",
    "    print(\"   - Go to Azure AI Foundry (https://ai.azure.com)\")\n",
    "    print(\"   - Navigate to Deployments\")\n",
    "    print(\"   - Click 'Deploy model'\")\n",
    "    print(f\"   - Select your fine-tuned model: {model_id}\")\n",
    "    print(f\"   - Give it a deployment name: {deployment_name}\")\n",
    "    print()\n",
    "    print(\"2. Azure CLI:\")\n",
    "    print(f\"   az cognitiveservices account deployment create \\\\\")\n",
    "    print(f\"     --resource-group <your-resource-group> \\\\\")\n",
    "    print(f\"     --account-name <your-openai-resource> \\\\\")\n",
    "    print(f\"     --deployment-name {deployment_name} \\\\\")\n",
    "    print(f\"     --model-name '{model_id}' \\\\\")\n",
    "    print(f\"     --model-version '1' \\\\\")\n",
    "    print(f\"     --model-format OpenAI \\\\\")\n",
    "    print(f\"     --sku-capacity 1 \\\\\")\n",
    "    print(f\"     --sku-name 'Standard'\")\n",
    "    print()\n",
    "    print(\"3. Management REST API (see deployment section in notebook)\")\n",
    "\n",
    "deployment_name = \"sarcastic-chatbot-deployment\"\n",
    "deploy_fine_tuned_model(fine_tuned_model_id, deployment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b746070",
   "metadata": {},
   "source": [
    "## 8. Test Fine-Tuned Model\n",
    "\n",
    "Once deployed, we can test our fine-tuned model to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e38693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cases for Fine-Tuned Model:\n",
      "==================================================\n",
      "\n",
      "Test 1: Geography question\n",
      "User: What's the capital of Italy?\n",
      "Assistant: Oh, just a tiny little place called Rome. Nothing special, really.\n",
      "Assistant: [Response from fine-tuned model would appear here]\n",
      "----------------------------------------\n",
      "\n",
      "Test 2: Basic knowledge question\n",
      "User: How many days are in a week?\n",
      "Assistant: Seven. Not a big number, is it?\n",
      "Assistant: [Response from fine-tuned model would appear here]\n",
      "----------------------------------------\n",
      "\n",
      "Test 3: Historical question\n",
      "User: Who was the first person on the moon?\n",
      "Assistant: Oh, just a little-known guy named Neil Armstrong. Nothing special, really.\n",
      "Assistant: [Response from fine-tuned model would appear here]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model (uncomment when deployed)\n",
    "def test_fine_tuned_model(deployment_name_fine_tuned, test_messages):\n",
    "    \"\"\"\n",
    "    Test the fine-tuned model with sample messages\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name_fine_tuned,\n",
    "            messages=test_messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=150\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "            {\"role\": \"user\", \"content\": \"What's the capital of Italy?\"}\n",
    "        ],\n",
    "        \"description\": \"Geography question\"\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "            {\"role\": \"user\", \"content\": \"How many days are in a week?\"}\n",
    "        ],\n",
    "        \"description\": \"Basic knowledge question\"\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Who was the first person on the moon?\"}\n",
    "        ],\n",
    "        \"description\": \"Historical question\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Test Cases for Fine-Tuned Model:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nTest {i}: {test_case['description']}\")\n",
    "    print(f\"User: {test_case['messages'][1]['content']}\")\n",
    "    \n",
    "    # Uncomment the line below when model is deployed\n",
    "    deployment_name_fine_tuned = \"add here\"\n",
    "    response = test_fine_tuned_model(deployment_name_fine_tuned, test_case['messages'])\n",
    "    print(f\"Assistant: {response}\")\n",
    "    \n",
    "    # Placeholder response for demo\n",
    "    print(f\"Assistant: [Response from fine-tuned model would appear here]\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b342e",
   "metadata": {},
   "source": [
    "## 9. Continuous Fine-Tuning\n",
    "\n",
    "You can further fine-tune an already fine-tuned model with additional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous fine-tuning example\n",
    "def create_continuous_fine_tuning_job(base_fine_tuned_model, new_training_file_id, new_validation_file_id=None):\n",
    "    \"\"\"\n",
    "    Create a fine-tuning job using an already fine-tuned model as the base\n",
    "    \"\"\"\n",
    "    print(f\"Creating continuous fine-tuning job...\")\n",
    "    print(f\"Base model: {base_fine_tuned_model}\")\n",
    "    \n",
    "    try:\n",
    "        response = client.fine_tuning.jobs.create(\n",
    "            training_file=new_training_file_id,\n",
    "            validation_file=new_validation_file_id,\n",
    "            model=base_fine_tuned_model,  # Use the fine-tuned model as base\n",
    "            suffix=\"v2\",  # Version identifier\n",
    "            hyperparameters={\n",
    "                \"n_epochs\": 2,  # Fewer epochs for continuous training\n",
    "                \"learning_rate_multiplier\": 0.1  # Lower learning rate\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"Continuous fine-tuning job created: {response.id}\")\n",
    "        return response.id\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating continuous fine-tuning job: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example of how to use continuous fine-tuning\n",
    "print(\"Continuous Fine-Tuning Process:\")\n",
    "print(\"1. Prepare additional training data\")\n",
    "print(\"2. Upload new training files\")\n",
    "print(\"3. Use the fine-tuned model ID as the base model\")\n",
    "print(\"4. Create new fine-tuning job\")\n",
    "print(\"5. Monitor and deploy the improved model\")\n",
    "print()\n",
    "print(\"Benefits:\")\n",
    "print(\"- Iterative improvement\")\n",
    "print(\"- Incorporate new data/feedback\")\n",
    "print(\"- Refine model behavior\")\n",
    "print(\"- Adapt to changing requirements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fe4f12",
   "metadata": {},
   "source": [
    "## 10. Best Practices and Tips\n",
    "\n",
    "Here are important best practices for successful fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cb1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practices summary\n",
    "best_practices = {\n",
    "    \"Data Quality\": [\n",
    "        \"Use high-quality, diverse examples\",\n",
    "        \"Ensure consistent formatting\",\n",
    "        \"Include edge cases and variations\",\n",
    "        \"Remove low-quality or contradictory examples\",\n",
    "        \"Use the same system message throughout\"\n",
    "    ],\n",
    "    \"Dataset Size\": [\n",
    "        \"Minimum 10 examples (not recommended for production)\",\n",
    "        \"50+ examples for basic fine-tuning\",\n",
    "        \"Hundreds to thousands for best results\",\n",
    "        \"Quality over quantity\",\n",
    "        \"Consider data augmentation for small datasets\"\n",
    "    ],\n",
    "    \"Hyperparameters\": [\n",
    "        \"Start with default settings\",\n",
    "        \"Lower learning rates prevent overfitting\",\n",
    "        \"Larger batch sizes for larger datasets\",\n",
    "        \"Monitor training/validation loss divergence\",\n",
    "        \"Use checkpoints to prevent overfitting\"\n",
    "    ],\n",
    "    \"Monitoring\": [\n",
    "        \"Watch for decreasing loss over time\",\n",
    "        \"Monitor token accuracy improvements\",\n",
    "        \"Check for overfitting (validation >> training loss)\",\n",
    "        \"Use early stopping if needed\",\n",
    "        \"Analyze results.csv file\"\n",
    "    ],\n",
    "    \"Deployment\": [\n",
    "        \"Test with Developer deployment first\",\n",
    "        \"Use same system message as training\",\n",
    "        \"Monitor inference performance\",\n",
    "        \"Consider cost implications\",\n",
    "        \"Plan for model lifecycle management\"\n",
    "    ],\n",
    "    \"Cost Optimization\": [\n",
    "        \"Use Global training tier if no data residency requirements\",\n",
    "        \"Delete inactive deployments (auto-deleted after 15 days)\",\n",
    "        \"Consider model size vs. performance trade-offs\",\n",
    "        \"Monitor training costs\",\n",
    "        \"Use checkpoints to avoid retraining\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"ðŸŽ¯ Fine-Tuning Best Practices\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for category, practices in best_practices.items():\n",
    "    print(f\"\\nðŸ“‹ {category}:\")\n",
    "    for practice in practices:\n",
    "        print(f\"   â€¢ {practice}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Remember: Fine-tuning is iterative. Start simple, measure results, and improve gradually!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9328a3a",
   "metadata": {},
   "source": [
    "## 11. Cleanup and Resource Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c86469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup functions\n",
    "def list_uploaded_files():\n",
    "    \"\"\"List all uploaded files\"\"\"\n",
    "    try:\n",
    "        files = client.files.list()\n",
    "        print(\"Uploaded Files:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for file in files.data:\n",
    "            print(f\"ID: {file.id}\")\n",
    "            print(f\"Name: {file.filename}\")\n",
    "            print(f\"Purpose: {file.purpose}\")\n",
    "            print(f\"Size: {file.bytes} bytes\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error listing files: {e}\")\n",
    "\n",
    "def delete_file(file_id):\n",
    "    \"\"\"Delete an uploaded file\"\"\"\n",
    "    try:\n",
    "        client.files.delete(file_id)\n",
    "        print(f\"Deleted file: {file_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting file {file_id}: {e}\")\n",
    "\n",
    "def list_fine_tuning_jobs():\n",
    "    \"\"\"List all fine-tuning jobs\"\"\"\n",
    "    try:\n",
    "        jobs = client.fine_tuning.jobs.list()\n",
    "        print(\"Fine-tuning Jobs:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for job in jobs.data:\n",
    "            print(f\"ID: {job.id}\")\n",
    "            print(f\"Status: {job.status}\")\n",
    "            print(f\"Model: {job.model}\")\n",
    "            print(f\"Fine-tuned Model: {job.fine_tuned_model or 'N/A'}\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error listing jobs: {e}\")\n",
    "\n",
    "# Resource management info\n",
    "print(\"ðŸ§¹ Resource Management\")\n",
    "print(\"=\" * 30)\n",
    "print()\n",
    "print(\"Important Notes:\")\n",
    "print(\"â€¢ Deployments are auto-deleted after 15 days of inactivity\")\n",
    "print(\"â€¢ Deployed models incur hourly hosting costs\")\n",
    "print(\"â€¢ Training files can be deleted after fine-tuning\")\n",
    "print(\"â€¢ Fine-tuned models can be stored at no cost until deployed\")\n",
    "print()\n",
    "print(\"Use the functions above to manage your resources:\")\n",
    "print(\"â€¢ list_uploaded_files() - See all uploaded files\")\n",
    "print(\"â€¢ delete_file(file_id) - Delete specific files\")\n",
    "print(\"â€¢ list_fine_tuning_jobs() - See all fine-tuning jobs\")\n",
    "\n",
    "# Uncomment to run cleanup functions\n",
    "# list_uploaded_files()\n",
    "# list_fine_tuning_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3734fdf",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered the complete fine-tuning workflow for Azure OpenAI:\n",
    "\n",
    "1. **Setup**: Environment configuration and client initialization\n",
    "2. **Data Preparation**: Creating and formatting training data in JSONL format\n",
    "3. **Upload**: Uploading training and validation files to Azure OpenAI\n",
    "4. **Training**: Creating and monitoring fine-tuning jobs\n",
    "5. **Analysis**: Downloading and analyzing training results\n",
    "6. **Deployment**: Deploying the fine-tuned model for inference\n",
    "7. **Testing**: Validating model performance with test cases\n",
    "8. **Continuous Improvement**: Iterative fine-tuning processes\n",
    "9. **Best Practices**: Guidelines for successful fine-tuning\n",
    "10. **Cleanup**: Resource management and cost optimization\n",
    "\n",
    "### Next Steps:\n",
    "- Prepare your own training data\n",
    "- Experiment with different hyperparameters\n",
    "- Monitor model performance in production\n",
    "- Iterate and improve based on user feedback\n",
    "\n",
    "### Resources:\n",
    "- [Azure OpenAI Fine-tuning Documentation](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/fine-tuning)\n",
    "- [Model Availability and Regional Support](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/models#fine-tuning-models)\n",
    "- [Azure OpenAI Pricing](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/)\n",
    "- [Fine-tuning Best Practices](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/fine-tuning-considerations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-openai-workshop (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
